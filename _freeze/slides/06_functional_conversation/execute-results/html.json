{
  "hash": "027c5f250b94946bb12bea65f99a4609",
  "result": {
    "markdown": "---\ntitle: Conversational agent\ntitle-slide-attributes:\n  data-background-image: ../images/logo.png\n  data-background-size: contain\n  data-background-opacity: \"0.5\"\nlang: en\nsubtitle: Tutorial 5\nauthor: Jan Kirenz\nexecute:\n  eval: false\n  echo: true\nhighlight-style: github\nformat:\n  revealjs: \n    toc: true\n    toc-depth: 1\n    embed-resources: false\n    theme: [dark, ../custom.scss]  \n    incremental: true\n    transition: slide\n    background-transition: fade\n    transition-speed: slow\n    code-copy: true\n    code-line-numbers: true\n    smaller: false\n    scrollable: true\n    slide-number: c\n    preview-links: auto\n    chalkboard: \n      buttons: false\n   # logo: ../images/logo.png\n    footer: Jan Kirenz\n---\n\n# Conversational agent\n\nLet's build a conversational agent\n\n# Setup {.smaller}\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport openai\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) \nopenai.api_key = os.environ['OPENAI_API_KEY']\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport datetime\nimport requests\nimport wikipedia\nfrom pydantic import BaseModel, Field\n\nfrom langchain.tools import tool\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.tools.render import format_tool_to_openai_function\nfrom langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\nfrom langchain.prompts import MessagesPlaceholder\nfrom langchain.agents.format_scratchpad import format_to_openai_functions\nfrom langchain.schema.agent import AgentFinish\nfrom langchain.schema.runnable import RunnablePassthrough\nfrom langchain.agents import AgentExecutor\nfrom langchain.memory import ConversationBufferMemory\n\nimport panel as pn \npn.extension()\nimport panel as pn\nimport param\n```\n:::\n\n\n# Prepare\n\n## Define weather tool {.smaller}\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# Define the input schema\nclass OpenMeteoInput(BaseModel):\n    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n\n@tool(args_schema=OpenMeteoInput)\ndef get_current_temperature(latitude: float, longitude: float) -> dict:\n    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n    \n    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n    \n    # Parameters for the request\n    params = {\n        'latitude': latitude,\n        'longitude': longitude,\n        'hourly': 'temperature_2m',\n        'forecast_days': 1,\n    }\n\n    # Make the request\n    response = requests.get(BASE_URL, params=params)\n    \n    if response.status_code == 200:\n        results = response.json()\n    else:\n        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n\n    current_utc_time = datetime.datetime.utcnow()\n    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n    temperature_list = results['hourly']['temperature_2m']\n    \n    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n    current_temperature = temperature_list[closest_time_index]\n    \n    return f'The current temperature is {current_temperature}°C'\n```\n:::\n\n\n## Define Wikipedia tool {.smaller}\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n@tool\ndef search_wikipedia(query: str) -> str:\n    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n    page_titles = wikipedia.search(query)\n    summaries = []\n    for page_title in page_titles[: 3]:\n        try:\n            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n        except (\n            self.wiki_client.exceptions.PageError,\n            self.wiki_client.exceptions.DisambiguationError,\n        ):\n            pass\n    if not summaries:\n        return \"No good Wikipedia Search Result was found\"\n    return \"\\n\\n\".join(summaries)\n```\n:::\n\n\n## Save list of tools\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ntools = [get_current_temperature, search_wikipedia]\n```\n:::\n\n\n## Set up chain\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nfunctions = [format_tool_to_openai_function(f) for f in tools]\n\nmodel = ChatOpenAI(temperature=0).bind(functions=functions)\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are helpful but sassy assistant\"),\n    (\"user\", \"{input}\"),\n])\n\nchain = prompt | model | OpenAIFunctionsAgentOutputParser()\n```\n:::\n\n\n## Invoke chain {.smaller}\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nresult = chain.invoke({\"input\": \"what is the weather in stuttgart?\"})\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nresult.tool\n```\n:::\n\n\n- 'get_current_temperature'\n\n. . .\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nresult.tool_input\n```\n:::\n\n\n- {'latitude': 48.7758, 'longitude': 9.1829}\n\n\n# Pass back in history\n\n## Modify prompt\n\n- Use MessagesPlaceholder\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are helpful but sassy assistant\"),\n    (\"user\", \"{input}\"),\n    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n])\n```\n:::\n\n\n## Create chain\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nchain = prompt | model | OpenAIFunctionsAgentOutputParser()\n```\n:::\n\n\n## Invoke chain\n\n- We use an empty list because we don't have any input so far\n\n. . .\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nresult1 = chain.invoke({\n    \"input\": \"what is the weather is stuttgart?\",\n    \"agent_scratchpad\": []\n})\n```\n:::\n\n\n## Inspect result1 {.smaller}\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nresult1.tool\n```\n:::\n\n\n- 'get_current_temperature'\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nobservation = get_current_temperature(result1.tool_input)\n```\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nobservation\n```\n:::\n\n\n- 'The current temperature is 10.1°C'\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\ntype(result1)\n```\n:::\n\n\n- langchain.schema.agent.AgentActionMessageLog\n\n## Show log\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nresult1.message_log\n```\n:::\n\n\n- [AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_temperature', 'arguments': '{\\n  \"latitude\": 48.7758,\\n  \"longitude\": 9.1829\\n}'}})]\n\n## Format to OpenAI functions\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nformat_to_openai_functions([(result1, observation), ])\n```\n:::\n\n\n- [AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_temperature', 'arguments': '{\\n  \"latitude\": 48.7758,\\n  \"longitude\": 9.1829\\n}'}}),\n FunctionMessage(content='The current temperature is 10.1°C', name='get_current_temperature')]\n\n## Update chain {.smaller}\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nresult2 = chain.invoke({\n    \"input\": \"what is the weather in stuttgart?\", \n    \"agent_scratchpad\": format_to_openai_functions([(result1, observation)])\n})\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nresult2\n```\n:::\n\n\n- AgentFinish(return_values={'output': 'The current temperature in Stuttgart is 10.1°C.'}, log='The current temperature in Stuttgart is 10.1°C.')\n\n\n# Final function \n\n## Function for agent {.smaller}\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\ndef run_agent(user_input):\n    intermediate_steps = []\n    while True:\n        result = chain.invoke({\n            \"input\": user_input, \n            \"agent_scratchpad\": format_to_openai_functions(intermediate_steps)\n        })\n        if isinstance(result, AgentFinish):\n            return result\n        tool = {\n            \"search_wikipedia\": search_wikipedia, \n            \"get_current_temperature\": get_current_temperature,\n        }[result.tool]\n        observation = tool.run(result.tool_input)\n        intermediate_steps.append((result, observation))\n```\n:::\n\n\n## RunnablePassthrough {.smaller}\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nagent_chain = RunnablePassthrough.assign(\n    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n) | chain\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\ndef run_agent(user_input):\n    intermediate_steps = []\n    while True:\n        result = agent_chain.invoke({\n            \"input\": user_input, \n            \"intermediate_steps\": intermediate_steps\n        })\n        if isinstance(result, AgentFinish):\n            return result\n        tool = {\n            \"search_wikipedia\": search_wikipedia, \n            \"get_current_temperature\": get_current_temperature,\n        }[result.tool]\n        observation = tool.run(result.tool_input)\n        intermediate_steps.append((result, observation))\n```\n:::\n\n\n## Run agent with weather question\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nrun_agent(\"what is the weather in stuttgart?\")\n```\n:::\n\n\n- AgentFinish(return_values={'output': 'The current temperature in Stuttgart is 10.1°C.'}, log='The current temperature in Stuttgart is 10.1°C.')\n\n\n## Run agent with general question {.smaller}\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\nrun_agent(\"what is langchain?\")\n```\n:::\n\n\n- AgentFinish(return_values={'output': 'LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework that can be used for various tasks such as document analysis and summarization, chatbots, and code analysis. LangChain helps developers leverage the power of language models in their applications.'}, log='LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework that can be used for various tasks such as document analysis and summarization, chatbots, and code analysis. LangChain helps developers leverage the power of language models in their applications.')\n\n\n## Just say hi\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nrun_agent(\"hi!\")\n```\n:::\n\n\n- AgentFinish(return_values={'output': 'Hello! How can I assist you today?'}, log='Hello! How can I assist you today?')\n\n\n# Agent Executor\n\n## Define Agent Executor\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\nagent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=True)\n```\n:::\n\n\n## Invoke executor {.smaller}\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\nagent_executor.invoke({\"input\": \"what is langchain?\"})\n```\n:::\n\n\n> Entering new AgentExecutor chain...\n\nInvoking: `search_wikipedia` with `{'query': 'langchain'}`\n\n\nPage: LangChain\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n\nPage: Prompt engineering\nSummary: Prompt engineering is the process of structuring text that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.A prompt for a text-to-text model can be a query such as \"what is Fermat's little theorem?\", a command such as \"write a poem about leaves falling\", a short statement of feedback (for example, \"too verbose\", \"too formal\", \"rephrase again\", \"omit this word\") or a longer statement including context, instructions, and input data. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as \"Act as a native French speaker\". A prompt may include a few examples for a model to learn from, such as \"maison -> house, chat -> cat, chien ->\", an approach called few-shot learning.When communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\n\nPage: Sentence embedding\nSummary: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token prepended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT's sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT's [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. \nOther approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. \nAn alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.\nLangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework that can be used for various tasks such as document analysis and summarization, chatbots, and code analysis. LangChain helps developers leverage the power of language models in their applications.\n\n> Finished chain.\n\n{'input': 'what is langchain?',\n 'output': 'LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework that can be used for various tasks such as document analysis and summarization, chatbots, and code analysis. LangChain helps developers leverage the power of language models in their applications.'}\n\n# Conversation example {.smaller}\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\nagent_executor.invoke({\"input\": \"my name is bob\"})\n```\n:::\n\n\n> Entering new AgentExecutor chain...\nHello Bob! How can I assist you today?\n\n> Finished chain.\n\n\n{'input': 'my name is bob', 'output': 'Hello Bob! How can I assist you today?'}\n\n## Ask a question\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\nagent_executor.invoke({\"input\": \"what is my name\"})\n```\n:::\n\n\n## Add previous messages in prompt\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are helpful but sassy assistant\"),\n    MessagesPlaceholder(variable_name=\"chat_history\"),\n    (\"user\", \"{input}\"),\n    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n])\n```\n:::\n\n\n## Create agent chain\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\nagent_chain = RunnablePassthrough.assign(\n    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n) | prompt | model | OpenAIFunctionsAgentOutputParser()\n```\n:::\n\n\n## Create memory object\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\nmemory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n```\n:::\n\n\n## Agent executor\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\nagent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=True, memory=memory)\n```\n:::\n\n\n## Provide input with name\n\n::: {.cell execution_count=35}\n``` {.python .cell-code}\nagent_executor.invoke({\"input\": \"my name is bob\"})\n```\n:::\n\n\n> Entering new AgentExecutor chain...\nHello Bob! How can I assist you today?\n\n> Finished chain.\n\n{'input': 'my name is bob',\n 'chat_history': [HumanMessage(content='my name is bob'),\n  AIMessage(content='Hello Bob! How can I assist you today?')],\n 'output': 'Hello Bob! How can I assist you today?'}\n\n## Ask about name\n\n::: {.cell execution_count=36}\n``` {.python .cell-code}\nagent_executor.invoke({\"input\": \"whats my name\"})\n```\n:::\n\n\n> Entering new AgentExecutor chain...\nYour name is Bob.\n\n> Finished chain.\n\n{'input': 'whats my name',\n 'chat_history': [HumanMessage(content='my name is bob'),\n  AIMessage(content='Hello Bob! How can I assist you today?'),\n  HumanMessage(content='whats my name'),\n  AIMessage(content='Your name is Bob.')],\n 'output': 'Your name is Bob.'}\n\n\n## Ask about the weather {.smaller}\n\n::: {.cell execution_count=37}\n``` {.python .cell-code}\nagent_executor.invoke({\"input\": \"whats the weather in stuttgart?\"})\n```\n:::\n\n\n> Entering new AgentExecutor chain...\n\nInvoking: `get_current_temperature` with `{'latitude': 48.7758, 'longitude': 9.1829}`\n\n\nThe current temperature is 9.5°CThe current temperature in Stuttgart is 9.5°C.\n\n> Finished chain.\n\n{'input': 'whats the weather in stuttgart?',\n 'chat_history': [HumanMessage(content='my name is bob'),\n  AIMessage(content='Hello Bob! How can I assist you today?'),\n  HumanMessage(content='whats my name'),\n  AIMessage(content='Your name is Bob.'),\n  HumanMessage(content='whats the weather in stuttgart?'),\n  AIMessage(content='The current temperature in Stuttgart is 9.5°C.')],\n 'output': 'The current temperature in Stuttgart is 9.5°C.'}\n\n# Create a chatbot\n\n## Define a custom function\n\n::: {.cell execution_count=38}\n``` {.python .cell-code}\n@tool\ndef create_your_own(query: str) -> str:\n    \"\"\"This function can do whatever you would like once you fill it in \"\"\"\n    print(type(query))\n    return query[::-1]\n```\n:::\n\n\n## Create tool list\n\n::: {.cell execution_count=39}\n``` {.python .cell-code}\ntools = [get_current_temperature, search_wikipedia, create_your_own]\n```\n:::\n\n\n## Define Chatbot function {.smaller}\n\n::: {.cell execution_count=40}\n``` {.python .cell-code}\nclass cbfs(param.Parameterized):\n    \n    def __init__(self, tools, **params):\n        super(cbfs, self).__init__( **params)\n        self.panels = []\n        self.functions = [format_tool_to_openai_function(f) for f in tools]\n        self.model = ChatOpenAI(temperature=0).bind(functions=self.functions)\n        self.memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n        self.prompt = ChatPromptTemplate.from_messages([\n            (\"system\", \"You are helpful but sassy assistant\"),\n            MessagesPlaceholder(variable_name=\"chat_history\"),\n            (\"user\", \"{input}\"),\n            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n        ])\n        self.chain = RunnablePassthrough.assign(\n            agent_scratchpad = lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n        ) | self.prompt | self.model | OpenAIFunctionsAgentOutputParser()\n        self.qa = AgentExecutor(agent=self.chain, tools=tools, verbose=False, memory=self.memory)\n    \n    def convchain(self, query):\n        if not query:\n            return\n        inp.value = ''\n        result = self.qa.invoke({\"input\": query})\n        self.answer = result['output'] \n        self.panels.extend([\n            pn.Row('User:', pn.pane.Markdown(query, width=450)),\n            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=450, styles={'background-color': '#F6F6F6'}))\n        ])\n        return pn.WidgetBox(*self.panels, scroll=True)\n\n\n    def clr_history(self,count=0):\n        self.chat_history = []\n        return \n```\n:::\n\n\n## Panel UI {.smaller}\n\n::: {.cell execution_count=41}\n``` {.python .cell-code}\ncb = cbfs(tools)\n\ninp = pn.widgets.TextInput( placeholder='Enter text here…')\n\nconversation = pn.bind(cb.convchain, inp) \n\ntab1 = pn.Column(\n    pn.Row(inp),\n    pn.layout.Divider(),\n    pn.panel(conversation,  loading_indicator=True, height=400),\n    pn.layout.Divider(),\n)\n\ndashboard = pn.Column(\n    pn.Row(pn.pane.Markdown('# QnA_Bot')),\n    pn.Tabs(('Conversation', tab1))\n)\ndashboard\n```\n:::\n\n\n# Acknowledgments\n\n- This tutorial is mainly based on the excellent course [\"Functions, Tools and Agents with LangChain\"](https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/?) provided by Harrison Chase from LangChain and Andrew Ng from DeepLearning.AI.\n\n\n# What's next? {background-image=\"../images/logo.png\" background-opacity=\"0.5\"}\n\n**Congratulations! You have completed this tutorial** 👍\n\n\n**Next, you may want to go back to the [lab's website](https://kirenz.github.io/lab-langchain-functions/)**\n\n",
    "supporting": [
      "06_functional_conversation_files"
    ],
    "filters": [],
    "includes": {}
  }
}