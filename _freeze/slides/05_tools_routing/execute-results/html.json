{
  "hash": "b32351ef0eb42a976eb8d5d9a41b420a",
  "result": {
    "markdown": "---\ntitle: Tools and Routing\ntitle-slide-attributes:\n  data-background-image: ../images/logo.png\n  data-background-size: contain\n  data-background-opacity: \"0.5\"\nlang: en\nsubtitle: Tutorial 5\nauthor: Jan Kirenz\nexecute:\n  eval: false\n  echo: true\nhighlight-style: github\nformat:\n  revealjs: \n    toc: true\n    toc-depth: 1\n    embed-resources: false\n    theme: [dark, ../custom.scss]  \n    incremental: true\n    transition: slide\n    background-transition: fade\n    transition-speed: slow\n    code-copy: true\n    code-line-numbers: true\n    smaller: false\n    scrollable: true\n    slide-number: c\n    preview-links: auto\n    chalkboard: \n      buttons: false\n   # logo: ../images/logo.png\n    footer: Jan Kirenz\n---\n\n# Tools and Routing\n\n\n## Setup {.smaller}\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport openai\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) \nopenai.api_key = os.environ['OPENAI_API_KEY']\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nfrom langchain.agents import tool\n\nfrom pydantic import BaseModel, Field\n\nimport requests\nfrom pydantic import BaseModel, Field\nimport datetime\n\nfrom langchain.tools.render import format_tool_to_openai_function\n\nimport wikipedia\n\nfrom langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n\nfrom langchain.utilities.openapi import OpenAPISpec\n\nfrom langchain.chat_models import ChatOpenAI\n\nfrom langchain.prompts import ChatPromptTemplate\n\nfrom langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n\nfrom langchain.schema.agent import AgentFinish\n\n```\n:::\n\n\n# Define a tool\n\n## Create tool {.smaller}\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n@tool\ndef search(query: str) -> str:\n    \"\"\"Search for weather online\"\"\"\n    return \"42f\"\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nsearch.name\n```\n:::\n\n\n- 'search'\n\n. . .\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nsearch.description\n```\n:::\n\n\n- 'search(query: str) -> str - Search for weather online'\n. . .\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nsearch.args\n```\n:::\n\n\n- {'query': {'title': 'Query', 'type': 'string'}}\n\n## Add a description\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nclass SearchInput(BaseModel):\n    query: str = Field(description=\"Thing to search for\")\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n@tool(args_schema=SearchInput)\ndef search(query: str) -> str:\n    \"\"\"Search for the weather online.\"\"\"\n    return \"42f\"\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nsearch.args\n```\n:::\n\n\n- {'query': {'title': 'Query',\n  'description': 'Thing to search for',\n  'type': 'string'}}\n\n\n## Call function\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nsearch.run(\"sf\")\n```\n:::\n\n\n- '42f'\n\n# Create weather tool\n\n## Create tool {.smaller}\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n# Define the input schema\nclass OpenMeteoInput(BaseModel):\n    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n\n@tool(args_schema=OpenMeteoInput)\ndef get_current_temperature(latitude: float, longitude: float) -> dict:\n    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n    \n    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n    \n    # Parameters for the request\n    params = {\n        'latitude': latitude,\n        'longitude': longitude,\n        'hourly': 'temperature_2m',\n        'forecast_days': 1,\n    }\n\n    # Make the request\n    response = requests.get(BASE_URL, params=params)\n    \n    if response.status_code == 200:\n        results = response.json()\n    else:\n        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n\n    current_utc_time = datetime.datetime.utcnow()\n    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n    temperature_list = results['hourly']['temperature_2m']\n    \n    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n    current_temperature = temperature_list[closest_time_index]\n    \n    return f'The current temperature is {current_temperature}¬∞C'\n```\n:::\n\n\n## Inspect function\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nget_current_temperature.name\n```\n:::\n\n\n- 'get_current_temperature'\n\n. . .\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nget_current_temperature.description\n```\n:::\n\n\n- 'get_current_temperature'\n\n. . .\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nget_current_temperature.args\n```\n:::\n\n\n- {'latitude': {'title': 'Latitude',\n  'description': 'Latitude of the location to fetch weather data for',\n  'type': 'number'},\n 'longitude': {'title': 'Longitude',\n  'description': 'Longitude of the location to fetch weather data for',\n  'type': 'number'}}\n\n\n## Convert this tool into OpenAI function\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nformat_tool_to_openai_function(get_current_temperature)\n```\n:::\n\n\n- {'name': 'get_current_temperature',\n 'description': 'get_current_temperature(latitude: float, longitude: float) -> dict - Fetch current temperature for given coordinates.',\n 'parameters': {'title': 'OpenMeteoInput',\n  'type': 'object',\n  'properties': {'latitude': {'title': 'Latitude',\n    'description': 'Latitude of the location to fetch weather data for',\n    'type': 'number'},\n   'longitude': {'title': 'Longitude',\n    'description': 'Longitude of the location to fetch weather data for',\n    'type': 'number'}},\n  'required': ['latitude', 'longitude']}}\n\n\n## Use tool\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nget_current_temperature({\"latitude\": 48.741400, \"longitude\": 9.1006302})\n```\n:::\n\n\n- 'The current temperature is 8.2¬∞C'\n\n# Wikikedia tool\n\n## Create tool\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n@tool\ndef search_wikipedia(query: str) -> str:\n    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n    page_titles = wikipedia.search(query)\n    summaries = []\n    for page_title in page_titles[: 3]:\n        try:\n            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n        except (\n            self.wiki_client.exceptions.PageError,\n            self.wiki_client.exceptions.DisambiguationError,\n        ):\n            pass\n    if not summaries:\n        return \"No good Wikipedia Search Result was found\"\n    return \"\\n\\n\".join(summaries)\n```\n:::\n\n\n## Inspect function\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nsearch_wikipedia.name\n```\n:::\n\n\n- 'search_wikipedia'\n\n. . .\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nsearch_wikipedia.description\n```\n:::\n\n\n- {'name': 'search_wikipedia',\n 'description': 'search_wikipedia(query: str) -> str - Run Wikipedia search and get page summaries.',\n 'parameters': {'title': 'search_wikipediaSchemaSchema',\n  'type': 'object',\n  'properties': {'query': {'title': 'Query', 'type': 'string'}},\n  'required': ['query']}}\n\n. . .\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nformat_tool_to_openai_function(search_wikipedia)\n```\n:::\n\n\n- {'name': 'search_wikipedia',\n 'description': 'search_wikipedia(query: str) -> str - Run Wikipedia search and get page summaries.',\n 'parameters': {'title': 'search_wikipediaSchemaSchema',\n  'type': 'object',\n  'properties': {'query': {'title': 'Query', 'type': 'string'}},\n  'required': ['query']}}\n\n\n## Use tool {.smaller}\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nsearch_wikipedia({\"query\": \"Hochschule der Medien Stuttgart\"})\n```\n:::\n\n\n- 'Page: Stuttgart Media University\\nSummary: The Stuttgart Media University or Media University (German: Hochschule der Medien) is a state university of media studies in Stuttgart, Germany, offering nearly 30 accredited bachelor\\'s and master\\'s degree programs within three faculties.\\n\\nPage: Stuttgart\\nSummary: Stuttgart (German: [Àà Ét ät…°a Åt] ; Swabian: Schduagert [Àà íÃädÃ•uaÃØ…°Ãä…õ ïdÃ•]; names in other languages) is the capital and largest city of the German state of Baden-W√ºrttemberg. It is located on the Neckar river in a fertile valley known as the Stuttgarter Kessel (Stuttgart Cauldron) and lies an hour from the Swabian Jura and the Black Forest. Stuttgart has a population of 635,911, making it the sixth largest city in Germany, while over 2.8 million people live in the city\\'s administrative region and nearly 5.5 million people in its metropolitan area, making it the fourth largest metropolitan area in Germany. The city and metropolitan area are consistently ranked among the top 20 European metropolitan areas by GDP; Mercer listed Stuttgart as 21st on its 2015 list of cities by quality of living; innovation agency 2thinknow ranked the city 24th globally out of 442 cities in its Innovation Cities Index; and the Globalization and World Cities Research Network ranked the city as a Beta-status global city in their 2020 survey. Stuttgart was one of the host cities for the official tournaments of the 1974 and 2006 FIFA World Cups.\\nStuttgart is unusual in the scheme of German cities. It is spread across a variety of hills (some of them covered in vineyards), valleys (especially around the Neckar river and the Stuttgart basin) and parks. The city is known as the \"cradle of the automobile\". As such, it is home to famous automobile museums like the Mercedes-Benz Museum and Porsche Museum, as well as numerous auto-enthusiast magazines, which contributes to Stuttgart\\'s status as Germany\\'s \"Autohauptstadt\" (\"car capital city\"). The city\\'s tourism slogan is \"Stuttgart offers more\". Under current plans to improve transport links to the international infrastructure (as part of the Stuttgart 21 project), Stuttgart unveiled a new city logo and slogan in March 2008, describing itself as \"Das neue Herz Europas\" (\"The new Heart of Europe\"). For business, it describes itself as \"Where business meets the future\". In July 2010, the city unveiled a new logo, designed to entice more business people to stay in the city and enjoy breaks in the area.Since the seventh millennium BC, the Stuttgart area has been an important agricultural area and has been host to a number of cultures seeking to utilize the rich soil of the Neckar valley. The Roman Empire conquered the area in AD 83 and built a massive castrum near Bad Cannstatt, making it the most important regional centre for several centuries. Stuttgart\\'s roots were truly laid in the tenth century with its founding by Liudolf, Duke of Swabia, as a stud farm for his warhorses. Initially overshadowed by nearby Bad Cannstatt, the town grew steadily and was granted a charter in 1320. The fortunes of Stuttgart turned with those of the House of W√ºrttemberg, and they made it the capital of their county, duchy, and kingdom from the 15th century to 1918. Stuttgart prospered despite setbacks in the Thirty Years\\' War and devastating air raids by the Allies on the city and its automobile production during World War II. However, by 1952, the city had bounced back and became the major cultural, economic, industrial, financial, tourism and publishing centre it is today.Stuttgart is known for its strong high-tech industry, especially in the automotive sector. It has the highest general standard of prosperity of any German city. In addition to many medium-sized companies, several major corporations are headquartered in Stuttgart, including Porsche, Bosch, and Mercedes-Benz Group. Stuttgart is an important financial center; the Stuttgart Stock Exchange is the second largest in Germany (after Frankfurt), and the Landesbank Baden-W√ºrttemberg (LBBW) is Germany\\'s largest Landesbank. Stuttgart is also a major transport junction; it is among the most congested conurbations of Europe, and its airport is the sixth-busiest in Germany (2019). Stuttgart is a city with a high number of immigrants; according to Dorling Kindersley\\'s Eyewitness Travel Guide to Germany, \"In the city of Stuttgart, every third inhabitant is a foreigner.\" 40% of Stuttgart\\'s residents, and 64% of the population below the age of five, are of immigrant background.\\n\\nPage: Menschenliebe\\nSummary: Menschenliebe is an independent German feature film directed by Alexander Tuschinski. It had its premiere in Stuttgart, Germany in December  2010. It was screened and received numerous awards at international film-festivals, was additionally shown in various cinemas and screening events in Germany, and was officially released online in June 2013. It is the first instalment of Tuschinski\\'s informal Trilogy of Rebellion - three very different feature films connected by the same thoughts, ideas and main characters, although each tells an independent story: Menschenliebe, Timeless and an upcoming project called Revolution!. Additionally, the film Break-Up refers to some events of Menschenliebe.'\n\n\n<!--\n\n# Open API specs\n\n## Example Open API spec {.smaller}\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\ntext = \"\"\"\n{\n  \"openapi\": \"3.0.0\",\n  \"info\": {\n    \"version\": \"1.0.0\",\n    \"title\": \"Swagger Petstore\",\n    \"license\": {\n      \"name\": \"MIT\"\n    }\n  },\n  \"servers\": [\n    {\n      \"url\": \"http://petstore.swagger.io/v1\"\n    }\n  ],\n  \"paths\": {\n    \"/pets\": {\n      \"get\": {\n        \"summary\": \"List all pets\",\n        \"operationId\": \"listPets\",\n        \"tags\": [\n          \"pets\"\n        ],\n        \"parameters\": [\n          {\n            \"name\": \"limit\",\n            \"in\": \"query\",\n            \"description\": \"How many items to return at one time (max 100)\",\n            \"required\": false,\n            \"schema\": {\n              \"type\": \"integer\",\n              \"maximum\": 100,\n              \"format\": \"int32\"\n            }\n          }\n        ],\n        \"responses\": {\n          \"200\": {\n            \"description\": \"A paged array of pets\",\n            \"headers\": {\n              \"x-next\": {\n                \"description\": \"A link to the next page of responses\",\n                \"schema\": {\n                  \"type\": \"string\"\n                }\n              }\n            },\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"$ref\": \"#/components/schemas/Pets\"\n                }\n              }\n            }\n          },\n          \"default\": {\n            \"description\": \"unexpected error\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"$ref\": \"#/components/schemas/Error\"\n                }\n              }\n            }\n          }\n        }\n      },\n      \"post\": {\n        \"summary\": \"Create a pet\",\n        \"operationId\": \"createPets\",\n        \"tags\": [\n          \"pets\"\n        ],\n        \"responses\": {\n          \"201\": {\n            \"description\": \"Null response\"\n          },\n          \"default\": {\n            \"description\": \"unexpected error\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"$ref\": \"#/components/schemas/Error\"\n                }\n              }\n            }\n          }\n        }\n      }\n    },\n    \"/pets/{petId}\": {\n      \"get\": {\n        \"summary\": \"Info for a specific pet\",\n        \"operationId\": \"showPetById\",\n        \"tags\": [\n          \"pets\"\n        ],\n        \"parameters\": [\n          {\n            \"name\": \"petId\",\n            \"in\": \"path\",\n            \"required\": true,\n            \"description\": \"The id of the pet to retrieve\",\n            \"schema\": {\n              \"type\": \"string\"\n            }\n          }\n        ],\n        \"responses\": {\n          \"200\": {\n            \"description\": \"Expected response to a valid request\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"$ref\": \"#/components/schemas/Pet\"\n                }\n              }\n            }\n          },\n          \"default\": {\n            \"description\": \"unexpected error\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"$ref\": \"#/components/schemas/Error\"\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  },\n  \"components\": {\n    \"schemas\": {\n      \"Pet\": {\n        \"type\": \"object\",\n        \"required\": [\n          \"id\",\n          \"name\"\n        ],\n        \"properties\": {\n          \"id\": {\n            \"type\": \"integer\",\n            \"format\": \"int64\"\n          },\n          \"name\": {\n            \"type\": \"string\"\n          },\n          \"tag\": {\n            \"type\": \"string\"\n          }\n        }\n      },\n      \"Pets\": {\n        \"type\": \"array\",\n        \"maxItems\": 100,\n        \"items\": {\n          \"$ref\": \"#/components/schemas/Pet\"\n        }\n      },\n      \"Error\": {\n        \"type\": \"object\",\n        \"required\": [\n          \"code\",\n          \"message\"\n        ],\n        \"properties\": {\n          \"code\": {\n            \"type\": \"integer\",\n            \"format\": \"int32\"\n          },\n          \"message\": {\n            \"type\": \"string\"\n          }\n        }\n      }\n    }\n  }\n}\n\"\"\"\n```\n:::\n\n\n## Load OpenAPI spec\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nspec = OpenAPISpec.from_text(text)\n```\n:::\n\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\npet_openai_functions, pet_callables = openapi_spec_to_openai_fn(spec)\n```\n:::\n\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\npet_openai_functions\n```\n:::\n\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nmodel = ChatOpenAI(temperature=0).bind(functions=pet_openai_functions)\n```\n:::\n\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\nmodel.invoke(\"what are three pets names\")\n```\n:::\n\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\nmodel.invoke(\"tell me about pet with id 42\")\n```\n:::\n\n\n-->\n\n# Routing\n\n\n## Include tools in function\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\nfunctions = [\n    format_tool_to_openai_function(f) for f in [\n        search_wikipedia, get_current_temperature\n    ]\n]\n\nmodel = ChatOpenAI(temperature=0).bind(functions=functions)\n```\n:::\n\n\n## Invoke functions\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\nmodel.invoke(\"what is the weather in stuttgart right now\")\n```\n:::\n\n\n- AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_temperature', 'arguments': '{\\n  \"latitude\": 48.7758,\\n  \"longitude\": 9.1829\\n}'}})\n\n. . .\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\nmodel.invoke(\"what is langchain\")\n```\n:::\n\n\n- AIMessage(content='', additional_kwargs={'function_call': {'name': 'search_wikipedia', 'arguments': '{\\n  \"query\": \"langchain\"\\n}'}})\n\n\n## Create prompt and chain\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are helpful but sassy assistant\"),\n    (\"user\", \"{input}\"),\n])\n\nchain = prompt | model\n```\n:::\n\n\n## Invoke chain\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\nchain.invoke({\"input\": \"what is the weather in stuttgart right now\"})\n```\n:::\n\n\nAIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_temperature', 'arguments': '{\\n  \"latitude\": 48.7758,\\n  \"longitude\": 9.1829\\n}'}})\n\n\n## Use output parser\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\nchain = prompt | model | OpenAIFunctionsAgentOutputParser()\n```\n:::\n\n\n::: {.cell execution_count=35}\n``` {.python .cell-code}\nresult = chain.invoke({\"input\": \"what is the weather in stuttgart right now\"})\n```\n:::\n\n\n::: {.cell execution_count=36}\n``` {.python .cell-code}\ntype(result)\n```\n:::\n\n\n- langchain.schema.agent.AgentActionMessageLog\n\n## Inspect result\n\n::: {.cell execution_count=37}\n``` {.python .cell-code}\nresult.tool\n```\n:::\n\n\n- 'get_current_temperature'\n\n. . .\n\n::: {.cell execution_count=38}\n``` {.python .cell-code}\nresult.tool_input\n```\n:::\n\n\n- {'latitude': 48.7758, 'longitude': 9.1829}\n\n. . .\n\n::: {.cell execution_count=39}\n``` {.python .cell-code}\nget_current_temperature(result.tool_input)\n```\n:::\n\n\n- 'The current temperature is 10.1¬∞C'\n\n## Try a new input \n\n::: {.cell execution_count=40}\n``` {.python .cell-code}\nresult = chain.invoke({\"input\": \"Hi! How are you?\"})\n```\n:::\n\n\n::: {.cell execution_count=41}\n``` {.python .cell-code}\ntype(result)\n```\n:::\n\n\n- langchain.schema.agent.AgentFinish\n\n. . .\n\n::: {.cell execution_count=42}\n``` {.python .cell-code}\nresult.return_values\n```\n:::\n\n\n- {'output': \"Hello! I'm an AI assistant, so I don't have feelings, but I'm here to help you. How can I assist you today?\"}\n\n\n# Define output of function\n\n## Define route function\n\n::: {.cell execution_count=43}\n``` {.python .cell-code}\ndef route(result):\n    if isinstance(result, AgentFinish):\n        return result.return_values['output']\n    else:\n        tools = {\n            \"search_wikipedia\": search_wikipedia, \n            \"get_current_temperature\": get_current_temperature,\n        }\n        return tools[result.tool].run(result.tool_input)\n```\n:::\n\n\n## Create chain\n\n::: {.cell execution_count=44}\n``` {.python .cell-code}\nchain = prompt | model | OpenAIFunctionsAgentOutputParser() | route\n```\n:::\n\n\n## Input a weather quaestion\n\n::: {.cell execution_count=45}\n``` {.python .cell-code}\nresult = chain.invoke({\"input\": \"What is the weather in stuttgart right now?\"})\n```\n:::\n\n\n::: {.cell execution_count=46}\n``` {.python .cell-code}\nresult\n```\n:::\n\n\n- 'The current temperature is 10.1¬∞C'\n\n## Input a general queation {.result}\n\n::: {.cell execution_count=47}\n``` {.python .cell-code}\nresult = chain.invoke({\"input\": \"What is langchain?\"})\n```\n:::\n\n\n::: {.cell execution_count=48}\n``` {.python .cell-code}\nresult\n```\n:::\n\n\n'Page: LangChain\\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\nPage: Prompt engineering\\nSummary: Prompt engineering is the process of structuring text that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.A prompt for a text-to-text model can be a query such as \"what is Fermat\\'s little theorem?\", a command such as \"write a poem about leaves falling\", a short statement of feedback (for example, \"too verbose\", \"too formal\", \"rephrase again\", \"omit this word\") or a longer statement including context, instructions, and input data. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as \"Act as a native French speaker\". A prompt may include a few examples for a model to learn from, such as \"maison -> house, chat -> cat, chien ->\", an approach called few-shot learning.When communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as \"a high-quality photo of an astronaut riding a horse\" or \"Lo-fi slow BPM electro chill with organic samples\". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\\n\\nPage: Sentence embedding\\nSummary: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token prepended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT\\'s sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT\\'s [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. \\nOther approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. \\nAn alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.'\n\n\n## Just say hi\n\n::: {.cell execution_count=49}\n``` {.python .cell-code}\nchain.invoke({\"input\": \"hi!\"})\n```\n:::\n\n\n- 'Hello! How can I assist you today?'\n\n# Acknowledgments\n\n- This tutorial is mainly based on the excellent course [\"Functions, Tools and Agents with LangChain\"](https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/?) provided by Harrison Chase from LangChain and Andrew Ng from DeepLearning.AI.\n\n\n# What's next? {background-image=\"../images/logo.png\" background-opacity=\"0.5\"}\n\n**Congratulations! You have completed this tutorial** üëç\n\n\n**Next, you may want to go back to the [lab's website](https://kirenz.github.io/lab-langchain-functions/)**\n\n",
    "supporting": [
      "05_tools_routing_files"
    ],
    "filters": [],
    "includes": {}
  }
}