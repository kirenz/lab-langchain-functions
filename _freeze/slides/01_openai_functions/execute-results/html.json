{
  "hash": "14d10a7279b1059130f6d99cc8f563b7",
  "result": {
    "markdown": "---\ntitle: OpenAI Function Calling\ntitle-slide-attributes:\n  data-background-image: ../images/logo.png\n  data-background-size: contain\n  data-background-opacity: \"0.5\"\nlang: en\nsubtitle: Tutorial 1\nauthor: Jan Kirenz\nexecute:\n  eval: false\n  echo: true\nhighlight-style: github\nformat:\n  revealjs: \n    toc: true\n    toc-depth: 1\n    embed-resources: false\n    theme: [dark, ../custom.scss]  \n    incremental: true\n    transition: slide\n    background-transition: fade\n    transition-speed: slow\n    code-copy: true\n    code-line-numbers: true\n    smaller: false\n    scrollable: true\n    slide-number: c\n    preview-links: auto\n    chalkboard: \n      buttons: false\n   # logo: ../images/logo.png\n    footer: Jan Kirenz\n---\n\n# OpenAI Function Calling\n\n- Functions count in token usage\n\n# Setup\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport openai\n\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # read local .env file\nopenai.api_key = os.environ['OPENAI_API_KEY']\n```\n:::\n\n\n## Helper function\n\n# Functions\n\n## Weather example\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport json\n\n# Example dummy function hard coded to return the same weather\n# In production, this could be your backend API or an external API\ndef get_current_weather(location, unit=\"celsius\"):\n    \"\"\"Get the current weather in a given location\"\"\"\n    weather_info = {\n        \"location\": location,\n        \"temperature\": \"16\",\n        \"unit\": unit,\n        \"forecast\": [\"sunny\", \"windy\"],\n    }\n    return json.dumps(weather_info)\n```\n:::\n\n\n## Define a function\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# define a function\nfunctions = [\n    {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"string\",\n                    \"description\": \"The city and state, e.g. Stuttgart, BW\",\n                },\n                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n            },\n            \"required\": [\"location\"],\n        },\n    }\n]\n```\n:::\n\n\n## Messages {.smaller}\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"What's the weather like in Stuttgart?\"\n    }\n]\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo-0613\",\n    messages=messages,\n    functions=functions\n)\n```\n:::\n\n\n## Print response {.smaller}\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nprint(response)\n```\n:::\n\n\n{\n  \"id\": \"chatcmpl-8EzjVmo4zPOq7Z70XEV47HcjF3FBb\",\n  \"object\": \"chat.completion\",\n  \"created\": 1698584585,\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": null,\n        \"function_call\": {\n          \"name\": \"get_current_weather\",\n          \"arguments\": \"{\\n  \\\"location\\\": \\\"Stuttgart\\\"\\n}\"\n        }\n      },\n      \"finish_reason\": \"function_call\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 81,\n    \"completion_tokens\": 17,\n    \"total_tokens\": 98\n  }\n}\n## Response message\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nresponse_message = response[\"choices\"][0][\"message\"]\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nresponse_message\n```\n:::\n\n\n<OpenAIObject at 0x120dc2c30> JSON: {\n  \"role\": \"assistant\",\n  \"content\": null,\n  \"function_call\": {\n    \"name\": \"get_current_weather\",\n    \"arguments\": \"{\\n  \\\"location\\\": \\\"Stuttgart\\\"\\n}\"\n  }\n}\n\n## Response message content\n\n- Content is empty\n\n. . .\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\nresponse_message[\"content\"]\n```\n:::\n\n\n- Function call is a dictionary\n\n. . .\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nresponse_message[\"function_call\"]\n```\n:::\n\n\n- <OpenAIObject at 0x120f9dc10> JSON: {\n  \"name\": \"get_current_weather\",\n  \"arguments\": \"{\\n  \\\"location\\\": \\\"Stuttgart\\\"\\n}\"\n}\n\n## Inspect JSON {.smaller}\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\njson.loads(response_message[\"function_call\"][\"arguments\"])\n```\n:::\n\n\n{'location': 'Stuttgart'}\n\n. . .\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nargs = json.loads(response_message[\"function_call\"][\"arguments\"])\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nget_current_weather(args)\n```\n:::\n\n\n- '{\"location\": {\"location\": \"Stuttgart\"}, \"temperature\": \"16\", \"unit\": \"celsius\", \"forecast\": [\"sunny\", \"windy\"]}'\n\n\n## New message\n\n- New message with no relation to weather\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"hi!\",\n    }\n]\n```\n:::\n\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo-0613\",\n    messages=messages,\n    functions=functions,\n)\n```\n:::\n\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nprint(response)\n```\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"hi!\",\n    }\n]\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo-0613\",\n    messages=messages,\n    functions=functions,\n    function_call=\"auto\",\n)\nprint(response)\n```\n:::\n\n\n{\n  \"id\": \"chatcmpl-8Ezl8M209h6uqOXuFrGzVwAoSjXVI\",\n  \"object\": \"chat.completion\",\n  \"created\": 1698584686,\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"Hello! How can I assist you today?\"\n      },\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 75,\n    \"completion_tokens\": 10,\n    \"total_tokens\": 85\n  }\n}\n\n\n## Disable function usage\n\n- Don't use the function\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"hi!\",\n    }\n]\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo-0613\",\n    messages=messages,\n    functions=functions,\n    function_call=\"none\",\n)\nprint(response)\n```\n:::\n\n\n## Force function usage\n\n- force to use the function\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"hi!\",\n    }\n]\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo-0613\",\n    messages=messages,\n    functions=functions,\n    function_call={\"name\": \"get_current_weather\"},\n)\nprint(response)\n```\n:::\n\n\n## Pass the reults back in the LLM\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"What's the weather like in Boston!\",\n    }\n]\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo-0613\",\n    messages=messages,\n    functions=functions,\n    function_call={\"name\": \"get_current_weather\"},\n)\nprint(response)\n```\n:::\n\n\n## Response\n\n{\n  \"id\": \"chatcmpl-8EzqG43iC6CWCOqCQiSWxngMHJNIQ\",\n  \"object\": \"chat.completion\",\n  \"created\": 1698585004,\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": null,\n        \"function_call\": {\n          \"name\": \"get_current_weather\",\n          \"arguments\": \"{\\n  \\\"location\\\": \\\"Boston, MA\\\"\\n}\"\n        }\n      },\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 88,\n    \"completion_tokens\": 11,\n    \"total_tokens\": 99\n  }\n}\n\n## Append message\n\nAppend to list of messages\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nmessages.append(response[\"choices\"][0][\"message\"])\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nargs = json.loads(response[\"choices\"][0][\"message\"]['function_call']['arguments'])\n\nobservation = get_current_weather(args)\n```\n:::\n\n\n. . .\n\n- This is the response of calling a funtion\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nmessages.append(\n        {\n            \"role\": \"function\",\n            \"name\": \"get_current_weather\",\n            \"content\": observation,\n        }\n)\n```\n:::\n\n\n## Response {.smaller}\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo-0613\",\n    messages=messages,\n)\nprint(response)\n```\n:::\n\n\n{\n  \"id\": \"chatcmpl-8EzsXbeQiRTRNHnGV9eCzlfCZrNU2\",\n  \"object\": \"chat.completion\",\n  \"created\": 1698585145,\n  \"model\": \"gpt-3.5-turbo-0613\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"The current temperature in Boston is 16 degrees Celsius. The weather is sunny and windy.\"\n      },\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 77,\n    \"completion_tokens\": 18,\n    \"total_tokens\": 95\n  }\n}\n\n# Acknowledgments\n\n- This tutorial is mainly based on the excellent course [\"Functions, Tools and Agents with LangChain\"](https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/?) provided by Harrison Chase from LangChain and Andrew Ng from DeepLearning.AI.\n\n\n# What's next? {background-image=\"../images/logo.png\" background-opacity=\"0.5\"}\n\n**Congratulations! You have completed this tutorial** 👍\n\n\n**Next, you may want to go back to the [lab's website](https://kirenz.github.io/lab-langchain-functions/)**\n\n",
    "supporting": [
      "01_openai_functions_files"
    ],
    "filters": [],
    "includes": {}
  }
}