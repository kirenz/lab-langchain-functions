{
  "hash": "11b04f9eb759ec681441e3730e15a9fc",
  "result": {
    "markdown": "---\ntitle: Question Answering\ntitle-slide-attributes:\n  data-background-image: ../images/logo.png\n  data-background-size: contain\n  data-background-opacity: \"0.5\"\nlang: en\nsubtitle: LangChain Tutorial 5\nauthor: Jan Kirenz\nexecute:\n  eval: false\n  echo: true\nhighlight-style: github\nformat:\n  revealjs: \n    toc: true\n    toc-depth: 1\n    embed-resources: false\n    theme: [dark, ../custom.scss]  \n    incremental: true\n    transition: slide\n    background-transition: fade\n    transition-speed: slow\n    code-copy: true\n    code-line-numbers: true\n    smaller: false\n    scrollable: true\n    slide-number: c\n    preview-links: auto\n    chalkboard: \n      buttons: false\n   # logo: ../images/logo.png\n    footer: Jan Kirenz\n---\n\n# Question Answering\n\n\n# Setup\n\n## Python\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import RetrievalQA\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.vectorstores import Chroma\nimport datetime\nfrom dotenv import load_dotenv, find_dotenv\nimport os\nimport openai\n# import sys\n# sys.path.append('../..')\n\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nopenai.api_key = os.environ['OPENAI_API_KEY']\n```\n:::\n\n\n# RetrievalQA chain\n\n## Vector Database setup\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\npersist_directory = '../docs/chroma/'\nembedding = OpenAIEmbeddings()\nvectordb = Chroma(persist_directory=persist_directory,\n                  embedding_function=embedding)\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nprint(vectordb._collection.count())\n```\n:::\n\n\n- 209\n\n## Question and similarity search\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nquestion = \"What are major topics for this class?\"\n\ndocs = vectordb.similarity_search(question, k=3)\n\nlen(docs)\n```\n:::\n\n\n- 3\n\n## ChatOpenAI model\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nllm_name = \"gpt-3.5-turbo\"\n\nllm = ChatOpenAI(model_name=llm_name, temperature=0)\n```\n:::\n\n\n## RetrievalQA chain\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever()\n)\n```\n:::\n\n\n## Result\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nresult = qa_chain({\"query\": question})\n```\n:::\n\n\n. . . \n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nresult[\"result\"]\n```\n:::\n\n\n- 'The major topics for this class are machine learning and its various extensions.'\n\n# RetrievalQA chain with Template\n\n## Prompt template\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ntemplate = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n{context}\nQuestion: {question}\nHelpful Answer:\"\"\"\n\nQA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n```\n:::\n\n\n## Question answer chain \n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever(),\n    return_source_documents=True,\n    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n)\n```\n:::\n\n\n## Question and result\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nquestion = \"Is probability a class topic?\"\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\nresult = qa_chain({\"query\": question})\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\nresult[\"result\"]\n```\n:::\n\n\n- 'Yes, probability is a class topic. Thanks for asking!'\n\n## Source documents {.smaller}\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nresult[\"source_documents\"][0]\n```\n:::\n\n\n- Document(page_content=\"of this class will not be very program ming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octa ve. I'll say a bit more about that later.  \\nI also assume familiarity with basic proba bility and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what ra ndom variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basi c linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrix es and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. If you know what an eigenvect or of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not qu ite sure, that's fine, too. We'll go over it in \\nthe review sections.\", metadata={'source': '../docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 4})\n\n# RetrievalQA Chain Types\n\n## Map Reduce\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nqa_chain_mr = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever(),\n    chain_type=\"map_reduce\"\n)\n```\n:::\n\n\n## Result\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nresult = qa_chain_mr({\"query\": question})\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nresult[\"result\"]\n```\n:::\n\n\n- 'There is no mention of probability as a class topic in the provided text.'\n\n# LangChain plus platform\n\n## Basics\n\n- If you wish to experiment on the `LangChain plus platform`:\n  - Go to [langchain plus platform](https://www.langchain.plus/) and sign up\n  - Create an API key from your account's settings\n  - Use this API key in the code below   \n  - uncomment the code  \n\n## Code\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.langchain.plus\"\n# os.environ[\"LANGCHAIN_API_KEY\"] = \"...\"  # replace dots with your api key\n```\n:::\n\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\n# qa_chain_mr = RetrievalQA.from_chain_type(\n#     llm,\n#     retriever=vectordb.as_retriever(),\n#     chain_type=\"map_reduce\"\n# )\n# result = qa_chain_mr({\"query\": question})\n# result[\"result\"]\n```\n:::\n\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n# qa_chain_mr = RetrievalQA.from_chain_type(\n#     llm,\n#     retriever=vectordb.as_retriever(),\n#     chain_type=\"refine\"\n# )\n# result = qa_chain_mr({\"query\": question})\n# result[\"result\"]\n```\n:::\n\n\n# RetrievalQA Limitations\n \n## Conversational history\n\n- QA fails to preserve conversational history.\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever()\n)\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nquestion = \"Is probability a class topic?\"\nresult = qa_chain({\"query\": question})\nresult[\"result\"]\n```\n:::\n\n\n- 'Yes, probability is a topic that will be covered in this class. The instructor assumes familiarity with basic probability and statistics.'\n\n## Conversational history {.smaller}\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nquestion = \"why are those prerequesites needed?\"\nresult = qa_chain({\"query\": question})\nresult[\"result\"]\n```\n:::\n\n\n- 'The prerequisites are needed because they provide the foundational knowledge and skills necessary to understand and apply machine learning algorithms. \\n\\nBasic knowledge of computer science and computer skills is important because machine learning algorithms often involve programming and working with data. Understanding concepts like big-O notation helps in analyzing the efficiency and scalability of algorithms.\\n\\nFamiliarity with probability and statistics is necessary because machine learning involves working with data and making predictions based on statistical models. Understanding concepts like random variables, expectation, and variance is crucial in understanding and evaluating machine learning algorithms.\\n\\nBasic knowledge of linear algebra is important because many machine learning algorithms involve manipulating matrices and vectors. Understanding concepts like matrix multiplication, matrix inverse, and eigenvectors is essential in understanding and implementing these algorithms.\\n\\nOverall, these prerequisites provide the necessary background knowledge and skills to effectively learn and apply machine learning algorithms.'\n\n## Limitations\n\n- Note, The LLM response varies. \n\n- Some responses **do** include a reference to probability which might be gleaned from referenced documents. \n\n- The point is simply that the model does not have access to past questions or answers, this will be covered in the next tutorial (Tutorial 6).\n\n# Acknowledgments\n\n- This tutorial is mainly based on the excellent course [\"LangChain: Chat with Your DataI\"](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/) provided by Harrison Chase from LangChain and Andrew Ng from DeepLearning.AI.\n\n# What's next? {background-image=\"../images/logo.png\" background-opacity=\"0.5\"}\n\n**Congratulations! You have completed this tutorial** üëç\n\n\n**Next, you may want to go back to the [lab's website](https://kirenz.github.io/lab-langchain-rag/)**\n\n",
    "supporting": [
      "05_question_answering_files"
    ],
    "filters": [],
    "includes": {}
  }
}