{
  "hash": "626de7618649eadc2f35882f234f2ceb",
  "result": {
    "markdown": "---\ntitle: LangChain Expression Language (LCEL)\ntitle-slide-attributes:\n  data-background-image: ../images/logo.png\n  data-background-size: contain\n  data-background-opacity: \"0.5\"\nlang: en\nsubtitle: Tutorial 2\nauthor: Jan Kirenz\nexecute:\n  eval: false\n  echo: true\nhighlight-style: github\nformat:\n  revealjs: \n    toc: true\n    toc-depth: 1\n    embed-resources: false\n    theme: [dark, ../custom.scss]  \n    incremental: true\n    transition: slide\n    background-transition: fade\n    transition-speed: slow\n    code-copy: true\n    code-line-numbers: true\n    smaller: false\n    scrollable: true\n    slide-number: c\n    preview-links: auto\n    chalkboard: \n      buttons: false\n   # logo: ../images/logo.png\n    footer: Jan Kirenz\n---\n\n# LangChain Expression Language (LCEL)\n\n# Setup {.smaller}\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport openai\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # read local .env file\nopenai.api_key = os.environ['OPENAI_API_KEY']\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport json\n\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.schema.output_parser import StrOutputParser\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.vectorstores import DocArrayInMemorySearch\nfrom langchain.schema.runnable import RunnableMap\nfrom langchain.llms import OpenAI\n```\n:::\n\n\n# Simple Chain \n\n\n## Create chain{.smaller}\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nprompt = ChatPromptTemplate.from_template(\n    \"tell me a short joke about {topic}\"\n)\n\nmodel = ChatOpenAI()\n\noutput_parser = StrOutputParser()\n```\n:::\n\n\n. . . \n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nchain = prompt | model | output_parser\n```\n:::\n\n\n## Invoke chain\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nchain.invoke({\"topic\": \"a professor at HdM Stuttgar\"})\n```\n:::\n\n\n- ''Why did the professor at HdM Stuttgart always carry a ladder?\\n\\nBecause he wanted to reach new heights in teaching!''\n\n\n# More complex chain\n\n## Create Vector Store and Retriever\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nvectorstore = DocArrayInMemorySearch.from_texts(\n    [\"Yuval Noah Harari is the author of Sapiens\", \"In A Guide to the Good Life, William Irvine offers a refreshing presentation of Stoicism\"],\n    embedding=OpenAIEmbeddings()\n)\n\n# create a retriever\nretriever = vectorstore.as_retriever()\n```\n:::\n\n\n## Retrieve relevant documents {.smaller}\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\nretriever.get_relevant_documents(\"who is the author of Sapiens?\")\n```\n:::\n\n\n- [Document(page_content='Yuval Noah Harari is the author of Sapiens'),\n Document(page_content='In A Guide to the Good Life, William Irvine offers a refreshing presentation of Stoicism')]\n\n. . .\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\nretriever.get_relevant_documents(\"Which book did William Irvine write?\")\n```\n:::\n\n\n- [Document(page_content='In A Guide to the Good Life, William Irvine offers a refreshing presentation of Stoicism'),\n Document(page_content='Yuval Noah Harari is the author of Sapiens')]\n\n\n# RAG pipeline\n\n\n## Create prompt\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\ntemplate = \"\"\"Answer the question based only on the following context:\n{context}\n\nQuestion: {question}\n\"\"\"\n\nprompt = ChatPromptTemplate.from_template(template)\n```\n:::\n\n\n## Runnable Map {.smaller}\n\n- Chain: get user input > fetch relevant context > pass context into prompt > pass into model > pass into output parser to convert into string\n\n- Create dictionary with context and question\n. . .\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\nchain = RunnableMap({\n    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n    \"question\": lambda x: x[\"question\"]\n}) | prompt | model | output_parser\n```\n:::\n\n\n## Invoke chain\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\nchain.invoke({\"question\": \"who is the author of Sapiens?\"})\n```\n:::\n\n\n- 'The author of Sapiens is Yuval Noah Harari.'\n\n## Closer look at the RunnableMap {.smaller}\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\ninputs = RunnableMap({\n    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n    \"question\": lambda x: x[\"question\"]\n})\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\ninputs.invoke({\"question\": \"who is the author of Sapiens?\"})\n```\n:::\n\n\n- {'context': [Document(page_content='Yuval Noah Harari is the author of Sapiens'),\n  Document(page_content='In A Guide to the Good Life, William Irvine offers a refreshing presentation of Stoicism')],\n 'question': 'who is the author of Sapiens?'}\n\n\n# Bind parameters\n\n## Weather function\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\nfunctions = [\n    {\n      \"name\": \"weather_search\",\n      \"description\": \"Search for weather given an airport code\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"airport_code\": {\n            \"type\": \"string\",\n            \"description\": \"The airport code to get the weather for\"\n          },\n        },\n        \"required\": [\"airport_code\"]\n      }\n    }\n  ]\n```\n:::\n\n\n## Bind\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"human\", \"{input}\")\n    ]\n)\nmodel = ChatOpenAI(temperature=0).bind(functions=functions)\n```\n:::\n\n\n## Runnable\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\nrunnable = prompt | model\n```\n:::\n\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\nrunnable.invoke({\"input\": \"what is the weather in sf\"})\n```\n:::\n\n\n- AIMessage(content='', additional_kwargs={'function_call': {'name': 'weather_search', 'arguments': '{\\n  \"airport_code\": \"SFO\"\\n}'}})\n\n## Weather and sports search function {.smaller}\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\nfunctions = [\n    {\n      \"name\": \"weather_search\",\n      \"description\": \"Search for weather given an airport code\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"airport_code\": {\n            \"type\": \"string\",\n            \"description\": \"The airport code to get the weather for\"\n          },\n        },\n        \"required\": [\"airport_code\"]\n      }\n    },\n        {\n      \"name\": \"sports_search\",\n      \"description\": \"Search for news of recent sport events\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"team_name\": {\n            \"type\": \"string\",\n            \"description\": \"The sports team to search for\"\n          },\n        },\n        \"required\": [\"team_name\"]\n      }\n    }\n  ]\n```\n:::\n\n\n## Bind {.smaller}\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\nmodel = model.bind(functions=functions)\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\nrunnable = prompt | model\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\nrunnable.invoke({\"input\": \"how did the patriots do yesterday?\"})\n```\n:::\n\n\n- AIMessage(content='', additional_kwargs={'function_call': {'name': 'sports_search', 'arguments': '{\\n  \"team_name\": \"patriots\"\\n}'}})\n\n# Fallbacks\n\n## Use a simple model\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\nsimple_model = OpenAI(\n    temperature=0, \n    max_tokens=1000, \n    model=\"text-davinci-001\"\n)\nsimple_chain = simple_model | json.loads\n```\n:::\n\n\n## Input\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\nchallenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\"\n```\n:::\n\n\n## Run simple model\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\nsimple_model.invoke(challenge)\n```\n:::\n\n\n- Note: The next line is expected to fail.\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\n# simple_chain.invoke(challenge)\n```\n:::\n\n\n- Output is not JSON\n\n## Use different model\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\nmodel = ChatOpenAI(temperature=0)\n\nchain = model | StrOutputParser() | json.loads\n```\n:::\n\n\n. . .\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\nchain.invoke(challenge)\n```\n:::\n\n\n- {'poem1': {'title': 'Whispers of the Wind',\n  'author': 'Emily Rivers',\n  'first_line': \"Softly it blows, the wind's gentle touch\"},\n 'poem2': {'title': 'Silent Serenade',\n  'author': 'Jacob Stone',\n  'first_line': 'In moonlit night, a song unheard'},\n 'poem3': {'title': 'Dancing Shadows',\n  'author': 'Sophia Reed',\n  'first_line': 'Shadows sway, a graceful ballet'}}\n\n\n## New model with fallbacks\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\nfinal_chain = simple_chain.with_fallbacks([chain])\n```\n:::\n\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\nfinal_chain.invoke(challenge)\n```\n:::\n\n\n- {'poem1': {'title': 'Whispers of the Wind',\n  'author': 'Emily Rivers',\n  'first_line': 'Softly it comes, the whisper of the wind'},\n 'poem2': {'title': 'Silent Serenade',\n  'author': 'Jacob Moore',\n  'first_line': 'In the stillness of night, a silent serenade'},\n 'poem3': {'title': 'Dancing Shadows',\n  'author': 'Sophia Anderson',\n  'first_line': 'Shadows dance upon the walls, a secret ballet'}}\n\n# Interface\n\n## Joke example\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\nprompt = ChatPromptTemplate.from_template(\n    \"Tell me a short joke about {topic}\"\n)\nmodel = ChatOpenAI()\noutput_parser = StrOutputParser()\n\nchain = prompt | model | output_parser\n```\n:::\n\n\n## One input\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\nchain.invoke({\"topic\": \"professors\"})\n```\n:::\n\n\n- 'Why did the professor bring a ladder to the lecture? \\n\\nBecause they wanted to reach new heights of knowledge!'\n\n## Multiple inputs\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\nchain.batch([{\"topic\": \"professors\"}, {\"topic\": \"students\"}])\n```\n:::\n\n\n- ['Why did the professor bring a ladder to class?\\n\\nBecause they heard the lecture was going to be on high-level concepts!',\n 'Why did the student bring a ladder to school?\\n\\nBecause they wanted to reach for the highest grades!']\n\n\n## Stream back responses {.smaller}\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\nfor t in chain.stream({\"topic\": \"professors\"}):\n    print(t)\n```\n:::\n\n\nWhy\n did\n the\n professor\n bring\n a\n ladder\n to\n class\n?\n \n\n\nBecause\n they\n wanted\n to\n reach\n new\n heights\n in\n education\n!\n\n## Async method\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\nresponse = await chain.ainvoke({\"topic\": \"professors\"})\nresponse\n```\n:::\n\n\n- 'Why did the professor bring a ladder to the lecture? \\nBecause they wanted to reach new heights of knowledge!'\n\n\n\n# Acknowledgments\n\n- This tutorial is mainly based on the excellent course [\"Functions, Tools and Agents with LangChain\"](https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/?) provided by Harrison Chase from LangChain and Andrew Ng from DeepLearning.AI.\n\n\n# What's next? {background-image=\"../images/logo.png\" background-opacity=\"0.5\"}\n\n**Congratulations! You have completed this tutorial** üëç\n\n\n**Next, you may want to go back to the [lab's website](https://kirenz.github.io/lab-langchain-functions/)**\n\n",
    "supporting": [
      "02_lcel_files"
    ],
    "filters": [],
    "includes": {}
  }
}