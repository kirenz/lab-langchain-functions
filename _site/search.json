[
  {
    "objectID": "slides/01_document_loading.html#python",
    "href": "slides/01_document_loading.html#python",
    "title": "Document Loading",
    "section": "Python",
    "text": "Python\n\nfrom langchain.document_loaders import NotionDirectoryLoader\nfrom langchain.document_loaders import WebBaseLoader\nimport pandas as pd\nfrom langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\nfrom langchain.document_loaders.parsers import OpenAIWhisperParser\nfrom langchain.document_loaders.generic import GenericLoader\nfrom langchain.document_loaders import PyPDFLoader\nfrom dotenv import load_dotenv, find_dotenv\nimport os\nimport openai\n# import sys\n# sys.path.append('../..')\n\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nopenai.api_key = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "slides/01_document_loading.html#basics",
    "href": "slides/01_document_loading.html#basics",
    "title": "Document Loading",
    "section": "Basics",
    "text": "Basics\n\nIn retrieval augmented generation (RAG), an LLM retrieves contextual documents from an external dataset as part of its execution.\nThis is useful if we want to ask question about specific documents (e.g., our PDFs, a set of videos, etc)."
  },
  {
    "objectID": "slides/01_document_loading.html#example",
    "href": "slides/01_document_loading.html#example",
    "title": "Document Loading",
    "section": "Example",
    "text": "Example\n\nLet‚Äôs load a PDF transcript from one of Andrew Ng‚Äôs courses\nThese documents are the result of automated transcription so words and sentences are sometimes split unexpectedly."
  },
  {
    "objectID": "slides/01_document_loading.html#load-pdf",
    "href": "slides/01_document_loading.html#load-pdf",
    "title": "Document Loading",
    "section": "Load PDF",
    "text": "Load PDF\n\nloader = PyPDFLoader(\"../docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\npages = loader.load()\n\n\nEach page is a Document.\nA Document contains text (page_content) and metadata."
  },
  {
    "objectID": "slides/01_document_loading.html#inspect-data",
    "href": "slides/01_document_loading.html#inspect-data",
    "title": "Document Loading",
    "section": "Inspect data",
    "text": "Inspect data\n\nlen(pages)\n\n\n22\n\n\n\npage = pages[0]\n\n\n\n\npage.metadata\n\n\n{‚Äòsource‚Äô: ‚Äò../docs/cs229_lectures/MachineLearning-Lecture01.pdf‚Äô, ‚Äòpage‚Äô: 0}"
  },
  {
    "objectID": "slides/01_document_loading.html#inspect-content",
    "href": "slides/01_document_loading.html#inspect-content",
    "title": "Document Loading",
    "section": "Inspect content",
    "text": "Inspect content\n\nprint(page.page_content[0:500])\n\n\nMachineLearning-Lecture01\nInstructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine learning class. So what I wanna do today is ju st spend a little time going over the logistics of the class, and then we‚Äôll start to talk a bit about machine learning.\nBy way of introduction, my name‚Äôs Andrew Ng and I‚Äôll be instru ctor for this class. And so I personally work in machine learning, and I‚Äô ve worked on it for about 15 years now, and I actually think that machine learning i"
  },
  {
    "objectID": "slides/01_document_loading.html#prerequisites",
    "href": "slides/01_document_loading.html#prerequisites",
    "title": "Document Loading",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nYou need FFmpeg\nMac: install with Homebrew"
  },
  {
    "objectID": "slides/01_document_loading.html#example-1",
    "href": "slides/01_document_loading.html#example-1",
    "title": "Document Loading",
    "section": "Example",
    "text": "Example\nLet‚Äôs load the ‚ÄúCode Report‚Äù about Vector databases from Fireship"
  },
  {
    "objectID": "slides/01_document_loading.html#load-youtube-video",
    "href": "slides/01_document_loading.html#load-youtube-video",
    "title": "Document Loading",
    "section": "Load YouTube video",
    "text": "Load YouTube video\n\n# link to video\nurl = \"https://www.youtube.com/watch?v=klTvEwg3oJ4\"\n\n# path to directory\nsave_dir = \"../docs/youtube/\"\n\n# load video\nloader = GenericLoader(\n    YoutubeAudioLoader([url], save_dir),\n    OpenAIWhisperParser()\n)\n\ndocs = loader.load()"
  },
  {
    "objectID": "slides/01_document_loading.html#inspect-data-1",
    "href": "slides/01_document_loading.html#inspect-data-1",
    "title": "Document Loading",
    "section": "Inspect data",
    "text": "Inspect data\n\ndocs[0].page_content[0:500]\n\n\n‚ÄúIt is April 7th, 2023, and you‚Äôre watching The Code Report. One month ago, Vector Database Weaviate landed $16 million in Series A funding. Last week, PineconeDB just got a check for $28 million at a $700 million valuation. And yesterday, Chroma, an open source project with only 1.2 GitHub stars, raised $18 million for its Embeddings database. And I just launched my own Vector database this morning. We‚Äôre currently pre-revenue, pre-vision, and pre-code, and valued at $420 million. Leave your cre‚Äù"
  },
  {
    "objectID": "slides/01_document_loading.html#save-as-dataframe",
    "href": "slides/01_document_loading.html#save-as-dataframe",
    "title": "Document Loading",
    "section": "Save as DataFrame",
    "text": "Save as DataFrame\n\ndf = pd.DataFrame(docs, columns=['Text', 'Metadata'])"
  },
  {
    "objectID": "slides/01_document_loading.html#save-as-csv",
    "href": "slides/01_document_loading.html#save-as-csv",
    "title": "Document Loading",
    "section": "Save as CSV",
    "text": "Save as CSV\n\ndf.to_csv('../docs/youtube/codereport.csv')"
  },
  {
    "objectID": "slides/01_document_loading.html#example-2",
    "href": "slides/01_document_loading.html#example-2",
    "title": "Document Loading",
    "section": "Example",
    "text": "Example\n\nLet‚Äôs load a page from ‚ÄúIntroduction to Modern Statistics‚Äù by Mine √áetinkaya-Rundel and Johanna Hardin: https://openintro-ims.netlify.app/data-design\nThe raw file is provided in GutHub under this URL: https://raw.githubusercontent.com/OpenIntroStat/ims/main/02-data-design.qmd"
  },
  {
    "objectID": "slides/01_document_loading.html#load-url",
    "href": "slides/01_document_loading.html#load-url",
    "title": "Document Loading",
    "section": "Load URL",
    "text": "Load URL\n\nloader = WebBaseLoader(\n    \"https://raw.githubusercontent.com/OpenIntroStat/ims/main/02-data-design.qmd\")\n\ndocs = loader.load()"
  },
  {
    "objectID": "slides/01_document_loading.html#inspact-data",
    "href": "slides/01_document_loading.html#inspact-data",
    "title": "Document Loading",
    "section": "Inspact data",
    "text": "Inspact data\n\nprint(docs[0].page_content[400:800])\n\n\nampling. Knowing how the observational units were selected from a larger entity will allow for generalizations back to the population from which the data were randomly selected. Additionally, by understanding the structure of the study, causal relationships can be separated from those relationships which are only associated. A good question to ask oneself before working with the data at all is, ‚ÄúH"
  },
  {
    "objectID": "slides/01_document_loading.html#save-as-dataframe-1",
    "href": "slides/01_document_loading.html#save-as-dataframe-1",
    "title": "Document Loading",
    "section": "Save as DataFrame",
    "text": "Save as DataFrame\n\ndf = pd.DataFrame(docs, columns=['Text', 'Metadata'])"
  },
  {
    "objectID": "slides/01_document_loading.html#save-as-csv-1",
    "href": "slides/01_document_loading.html#save-as-csv-1",
    "title": "Document Loading",
    "section": "Save as CSV",
    "text": "Save as CSV\n\ndf.to_csv('../docs/url/study-design.csv')"
  },
  {
    "objectID": "slides/01_document_loading.html#example-3",
    "href": "slides/01_document_loading.html#example-3",
    "title": "Document Loading",
    "section": "Example",
    "text": "Example\n\nOption 1: Simply use the example data provided in langchain-intro/docs/Notion_DB\nOption 2: Follow the steps here for an example Notion site such as this one\n\nDuplicate the page into your own Notion space and export as Markdown / CSV.\nUnzip it and save it as a folder that contains the markdown file for the Notion page."
  },
  {
    "objectID": "slides/01_document_loading.html#load-notion",
    "href": "slides/01_document_loading.html#load-notion",
    "title": "Document Loading",
    "section": "Load Notion",
    "text": "Load Notion\n\nloader = NotionDirectoryLoader(\"../docs/Notion_DB\")\ndocs = loader.load()"
  },
  {
    "objectID": "slides/01_document_loading.html#inspect-data-2",
    "href": "slides/01_document_loading.html#inspect-data-2",
    "title": "Document Loading",
    "section": "Inspect data",
    "text": "Inspect data\n\nprint(docs[0].page_content[0:200])\n\n# Getting Started\n\nüëã Welcome to Notion!\n\nHere are the basics:\n\n- [ ]  Click anywhere and just start typing\n- [ ]  Hit `/` to see all the types of content you can add - headers, videos, sub pages, etc."
  },
  {
    "objectID": "slides/01_document_loading.html#inspect-data-3",
    "href": "slides/01_document_loading.html#inspect-data-3",
    "title": "Document Loading",
    "section": "Inspect data",
    "text": "Inspect data\n\ndocs[0].metadata\n\n\n{‚Äòsource‚Äô: ‚Äò../docs/Notion_DB/Getting Started 95e5ecbe48c44e408ef09fed850fbd40.md‚Äô}"
  },
  {
    "objectID": "slides/02_document_splitting.html",
    "href": "slides/02_document_splitting.html",
    "title": "Document Splitting",
    "section": "",
    "text": "import os\nimport openai\nimport sys\nsys.path.append('../..')\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # read local .env file\n\nopenai.api_key  = os.environ['OPENAI_API_KEY']\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\nchunk_size =26\nchunk_overlap = 4\nr_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=chunk_size,\n    chunk_overlap=chunk_overlap\n)\nc_splitter = CharacterTextSplitter(\n    chunk_size=chunk_size,\n    chunk_overlap=chunk_overlap\n)\nWhy doesn‚Äôt this split the string below?\ntext1 = 'abcdefghijklmnopqrstuvwxyz'\nr_splitter.split_text(text1)\n\n['abcdefghijklmnopqrstuvwxyz']\ntext2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\nr_splitter.split_text(text2)\n\n['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']\nOk, this splits the string but we have an overlap specified as 5, but it looks like 3? (try an even number)\ntext3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\nr_splitter.split_text(text3)\n\n['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']\nc_splitter.split_text(text3)\n\n['a b c d e f g h i j k l m n o p q r s t u v w x y z']\nc_splitter = CharacterTextSplitter(\n    chunk_size=chunk_size,\n    chunk_overlap=chunk_overlap,\n    separator = ' '\n)\nc_splitter.split_text(text3)\n\n['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']\nTry your own examples!"
  },
  {
    "objectID": "slides/02_document_splitting.html#recursive-splitting-details",
    "href": "slides/02_document_splitting.html#recursive-splitting-details",
    "title": "Document Splitting",
    "section": "Recursive splitting details",
    "text": "Recursive splitting details\nRecursiveCharacterTextSplitter is recommended for generic text.\n\nsome_text = \"\"\"When writing documents, writers will use document structure to group content. \\\nThis can convey to the reader, which idea's are related. For example, closely related ideas \\\nare in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\nParagraphs are often delimited with a carriage return or two carriage returns. \\\nCarriage returns are the \"backslash n\" you see embedded in this string. \\\nSentences have a period at the end, but also, have a space.\\\nand words are separated by space.\"\"\"\n\n\nlen(some_text)\n\n\nc_splitter = CharacterTextSplitter(\n    chunk_size=450,\n    chunk_overlap=0,\n    separator = ' '\n)\nr_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=450,\n    chunk_overlap=0, \n    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n)\n\n\nc_splitter.split_text(some_text)\n\n['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n 'have a space.and words are separated by space.']\n\n\n\nr_splitter.split_text(some_text)\n\n[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']\n\n\nLet‚Äôs reduce the chunk size a bit and add a period to our separators:\n\nr_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=150,\n    chunk_overlap=0,\n    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n)\nr_splitter.split_text(some_text)\n\n[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related\",\n '. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n 'Paragraphs are often delimited with a carriage return or two carriage returns',\n '. Carriage returns are the \"backslash n\" you see embedded in this string',\n '. Sentences have a period at the end, but also, have a space.and words are separated by space.']\n\n\n\nr_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=150,\n    chunk_overlap=0,\n    separators=[\"\\n\\n\", \"\\n\", \"(?&lt;=\\. )\", \" \", \"\"]\n)\nr_splitter.split_text(some_text)\n\n[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related.\",\n 'For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n 'Paragraphs are often delimited with a carriage return or two carriage returns.',\n 'Carriage returns are the \"backslash n\" you see embedded in this string.',\n 'Sentences have a period at the end, but also, have a space.and words are separated by space.']\n\n\n\nfrom langchain.document_loaders import PyPDFLoader\nloader = PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\npages = loader.load()\n\n\nfrom langchain.text_splitter import CharacterTextSplitter\ntext_splitter = CharacterTextSplitter(\n    separator=\"\\n\",\n    chunk_size=1000,\n    chunk_overlap=150,\n    length_function=len\n)\n\n\ndocs = text_splitter.split_documents(pages)\n\n\nlen(docs)\n\n77\n\n\n\nlen(pages)\n\n22\n\n\n\nfrom langchain.document_loaders import NotionDirectoryLoader\nloader = NotionDirectoryLoader(\"docs/Notion_DB\")\nnotion_db = loader.load()\n\n\ndocs = text_splitter.split_documents(notion_db)\n\n\nlen(notion_db)\n\n1\n\n\n\nlen(docs)\n\n2"
  },
  {
    "objectID": "slides/02_document_splitting.html#token-splitting",
    "href": "slides/02_document_splitting.html#token-splitting",
    "title": "Document Splitting",
    "section": "Token splitting",
    "text": "Token splitting\nWe can also split on token count explicity, if we want.\nThis can be useful because LLMs often have context windows designated in tokens.\nTokens are often ~4 characters.\n\nfrom langchain.text_splitter import TokenTextSplitter\n\n\ntext_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)\n\n\ntext1 = \"foo bar bazzyfoo\"\n\n\ntext_splitter.split_text(text1)\n\n['foo', ' bar', ' b', 'az', 'zy', 'foo']\n\n\n\ntext_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)\n\n\ndocs = text_splitter.split_documents(pages)\n\n\ndocs[0]\n\nDocument(page_content='MachineLearning-Lecture01  \\n', metadata={'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 0})\n\n\n\npages[0].metadata\n\n{'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 0}"
  },
  {
    "objectID": "slides/02_document_splitting.html#context-aware-splitting",
    "href": "slides/02_document_splitting.html#context-aware-splitting",
    "title": "Document Splitting",
    "section": "Context aware splitting",
    "text": "Context aware splitting\nChunking aims to keep text with common context together.\nA text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\nWe can use MarkdownHeaderTextSplitter to preserve header metadata in our chunks, as show below.\n\nfrom langchain.document_loaders import NotionDirectoryLoader\nfrom langchain.text_splitter import MarkdownHeaderTextSplitter\n\n\nmarkdown_document = \"\"\"# Title\\n\\n \\\n## Chapter 1\\n\\n \\\nHi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n### Section \\n\\n \\\nHi this is Lance \\n\\n \n## Chapter 2\\n\\n \\\nHi this is Molly\"\"\"\n\n\n\nheaders_to_split_on = [\n    (\"#\", \"Header 1\"),\n    (\"##\", \"Header 2\"),\n    (\"###\", \"Header 3\"),\n]\n\n\nmarkdown_splitter = MarkdownHeaderTextSplitter(\n    headers_to_split_on=headers_to_split_on\n)\nmd_header_splits = markdown_splitter.split_text(markdown_document)\n\n\nmd_header_splits[0]\n\nDocument(page_content='Hi this is Jim  \\nHi this is Joe', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'})\n\n\n\nmd_header_splits[1]\n\nDocument(page_content='Hi this is Lance', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'})\n\n\nTry on a real Markdown file, like a Notion database.\n\nloader = NotionDirectoryLoader(\"docs/Notion_DB\")\ndocs = loader.load()\ntxt = ' '.join([d.page_content for d in docs])\n\n\nheaders_to_split_on = [\n    (\"#\", \"Header 1\"),\n    (\"##\", \"Header 2\"),\n]\nmarkdown_splitter = MarkdownHeaderTextSplitter(\n    headers_to_split_on=headers_to_split_on\n)\n\n\nmd_header_splits = markdown_splitter.split_text(txt)\n\n\nmd_header_splits[0]\n\nDocument(page_content='üëã Welcome to Notion!  \\nHere are the basics:  \\n- [ ]  Click anywhere and just start typing\\n- [ ]  Hit `/` to see all the types of content you can add - headers, videos, sub pages, etc.  \\n[Example sub page](https://www.notion.so/Example-sub-page-92f63253929d456bbf12cd696e21e045?pvs=21)  \\n- [ ]  Highlight any text, and use the menu that pops up to **style** *your* ~~writing~~ `however` [you](https://www.notion.so/product) like\\n- [ ]  See the `‚ãÆ‚ãÆ` to the left of this checkbox on hover? Click and drag to move this line\\n- [ ]  Click the `+ New Page` button at the bottom of your sidebar to add a new page\\n- [ ]  Click `Templates` in your sidebar to get started with pre-built pages\\n- This is a toggle block. Click the little triangle to see more useful tips!\\n- [Template Gallery](https://www.notion.so/181e961aeb5c4ee6915307c0dfd5156d?pvs=21): More templates built by the Notion community\\n- [Help & Support](https://www.notion.so/e040febf70a94950b8620e6f00005004?pvs=21): ****Guides and FAQs for everything in Notion\\n- Stay organized with your sidebar and nested pages:  \\n![Getting%20Started%2095e5ecbe48c44e408ef09fed850fbd40/infinitehierarchynodither.gif](Getting%20Started%2095e5ecbe48c44e408ef09fed850fbd40/infinitehierarchynodither.gif)  \\nSee it in action:  \\n[1 minute](https://youtu.be/TL_N2pmh9O0)  \\n1 minute  \\n[4 minutes](https://youtu.be/FXIrojSK3Jo)  \\n4 minutes  \\n[2 minutes](https://youtu.be/2Pwzff-uffU)  \\n2 minutes  \\n[2 minutes](https://youtu.be/O8qdvSxDYNY)  \\n2 minutes  \\nVisit our [YouTube channel](http://youtube.com/c/notion) to watch 50+ more tutorials  \\nüëâ**Have a question?** Click the `?` at the bottom right for more guides, or to send us a message.', metadata={'Header 1': 'Getting Started'})"
  },
  {
    "objectID": "slides/02_document_splitting.html#python",
    "href": "slides/02_document_splitting.html#python",
    "title": "Document Splitting",
    "section": "Python",
    "text": "Python\n\nfrom langchain.text_splitter import MarkdownHeaderTextSplitter\nfrom langchain.text_splitter import TokenTextSplitter\nfrom langchain.document_loaders import NotionDirectoryLoader\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\nfrom dotenv import load_dotenv, find_dotenv\nimport os\nimport openai\n# import sys\n# sys.path.append('../..')\n\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nopenai.api_key = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "slides/02_document_splitting.html#character-text-splitter",
    "href": "slides/02_document_splitting.html#character-text-splitter",
    "title": "Document Splitting",
    "section": "Character Text Splitter",
    "text": "Character Text Splitter\n\nchunk_size = 26\nchunk_overlap = 4\n\n\n\nr_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=chunk_size,\n    chunk_overlap=chunk_overlap\n)\n\n\n\n\nc_splitter = CharacterTextSplitter(\n    chunk_size=chunk_size,\n    chunk_overlap=chunk_overlap\n)"
  },
  {
    "objectID": "slides/02_document_splitting.html#text-1",
    "href": "slides/02_document_splitting.html#text-1",
    "title": "Document Splitting",
    "section": "Text 1",
    "text": "Text 1\n\nWhy doesn‚Äôt this split the string below?\n\n\ntext1 = 'abcdefghijklmnopqrstuvwxyz'\n\n\n\nr_splitter.split_text(text1)\n\n\n[‚Äòabcdefghijklmnopqrstuvwxyz‚Äô]"
  },
  {
    "objectID": "slides/02_document_splitting.html#text-2",
    "href": "slides/02_document_splitting.html#text-2",
    "title": "Document Splitting",
    "section": "Text 2",
    "text": "Text 2\n\ntext2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n\n\n\nr_splitter.split_text(text2)\n\n\n[‚Äòabcdefghijklmnopqrstuvwxyz‚Äô, ‚Äòwxyzabcdefg‚Äô]"
  },
  {
    "objectID": "slides/02_document_splitting.html#text-3",
    "href": "slides/02_document_splitting.html#text-3",
    "title": "Document Splitting",
    "section": "Text 3",
    "text": "Text 3\n\ntext3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n\n\n\nr_splitter.split_text(text3)\n\n\n[‚Äòa b c d e f g h i j k l m‚Äô, ‚Äòl m n o p q r s t u v w x‚Äô, ‚Äòw x y z‚Äô]\n\n\n\n\nc_splitter.split_text(text3)\n\n\n[‚Äòa b c d e f g h i j k l m n o p q r s t u v w x y z‚Äô]"
  },
  {
    "objectID": "slides/02_document_splitting.html#charactertextsplitter",
    "href": "slides/02_document_splitting.html#charactertextsplitter",
    "title": "Document Splitting",
    "section": "CharacterTextSplitter",
    "text": "CharacterTextSplitter\n\nc_splitter = CharacterTextSplitter(\n    chunk_size=chunk_size,\n    chunk_overlap=chunk_overlap,\n    separator=' '\n)\n\n\nc_splitter.split_text(text3)\n\n\n[‚Äòa b c d e f g h i j k l m‚Äô, ‚Äòl m n o p q r s t u v w x‚Äô, ‚Äòw x y z‚Äô]"
  },
  {
    "objectID": "slides/02_document_splitting.html#recursivecharactertextsplitter",
    "href": "slides/02_document_splitting.html#recursivecharactertextsplitter",
    "title": "Document Splitting",
    "section": "RecursiveCharacterTextSplitter",
    "text": "RecursiveCharacterTextSplitter\n\nRecursiveCharacterTextSplitter is recommended for generic text.\n\n\nsome_text = \"\"\"When writing documents, writers will use document structure to group content. \\\nThis can convey to the reader, which idea's are related. For example, closely related ideas \\\nare in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\nParagraphs are often delimited with a carriage return or two carriage returns. \\\nCarriage returns are the \"backslash n\" you see embedded in this string. \\\nSentences have a period at the end, but also, have a space.\\\nand words are separated by space.\"\"\""
  },
  {
    "objectID": "slides/02_document_splitting.html#define-splitter",
    "href": "slides/02_document_splitting.html#define-splitter",
    "title": "Document Splitting",
    "section": "Define splitter",
    "text": "Define splitter\n\nc_splitter = CharacterTextSplitter(\n    chunk_size=450,\n    chunk_overlap=0,\n    separator=' '\n)\n\n\n\nr_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=450,\n    chunk_overlap=0,\n    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n)"
  },
  {
    "objectID": "slides/02_document_splitting.html#character-splitter-output",
    "href": "slides/02_document_splitting.html#character-splitter-output",
    "title": "Document Splitting",
    "section": "Character Splitter output",
    "text": "Character Splitter output\n\nc_splitter.split_text(some_text)\n\n\n[‚ÄòWhen writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the ‚Äúbackslash n‚Äù you see embedded in this string. Sentences have a period at the end, but also,‚Äô, ‚Äòhave a space.and words are separated by space.‚Äô]"
  },
  {
    "objectID": "slides/02_document_splitting.html#recursive-splitter-output",
    "href": "slides/02_document_splitting.html#recursive-splitter-output",
    "title": "Document Splitting",
    "section": "Recursive Splitter output",
    "text": "Recursive Splitter output\n\nr_splitter.split_text(some_text)\n\n\n[‚ÄúWhen writing documents, writers will use document structure to group content. This can convey to the reader, which idea‚Äôs are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.‚Äù, ‚ÄòParagraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the ‚Äúbackslash n‚Äù you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.‚Äô]"
  },
  {
    "objectID": "slides/02_document_splitting.html#adapt-splitter-1",
    "href": "slides/02_document_splitting.html#adapt-splitter-1",
    "title": "Document Splitting",
    "section": "Adapt splitter 1",
    "text": "Adapt splitter 1\n\nLet‚Äôs reduce the chunk size a bit and add a period to our separators:\n\n\nr_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=150,\n    chunk_overlap=0,\n    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n)\n\n\n\nr_splitter.split_text(some_text)\n\n\n[‚ÄúWhen writing documents, writers will use document structure to group content. This can convey to the reader, which idea‚Äôs are related‚Äù, ‚Äò. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.‚Äô, ‚ÄòParagraphs are often delimited with a carriage return or two carriage returns‚Äô, ‚Äò. Carriage returns are the ‚Äúbackslash n‚Äù you see embedded in this string‚Äô, ‚Äò. Sentences have a period at the end, but also, have a space.and words are separated by space.‚Äô]"
  },
  {
    "objectID": "slides/02_document_splitting.html#adapt-splitter-2",
    "href": "slides/02_document_splitting.html#adapt-splitter-2",
    "title": "Document Splitting",
    "section": "Adapt splitter 2",
    "text": "Adapt splitter 2\n\nr_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=150,\n    chunk_overlap=0,\n    separators=[\"\\n\\n\", \"\\n\", \"(?&lt;=\\. )\", \" \", \"\"]\n)\nr_splitter.split_text(some_text)\n\n\n\nr_splitter.split_text(some_text)\n\n\n[‚ÄúWhen writing documents, writers will use document structure to group content. This can convey to the reader, which idea‚Äôs are related.‚Äù, ‚ÄòFor example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.‚Äô, ‚ÄòParagraphs are often delimited with a carriage return or two carriage returns.‚Äô, ‚ÄòCarriage returns are the ‚Äúbackslash n‚Äù you see embedded in this string.‚Äô, ‚ÄòSentences have a period at the end, but also, have a space.and words are separated by space.‚Äô]"
  },
  {
    "objectID": "slides/02_document_splitting.html#load-pdf",
    "href": "slides/02_document_splitting.html#load-pdf",
    "title": "Document Splitting",
    "section": "Load PDF",
    "text": "Load PDF\n\nloader = PyPDFLoader(\"../docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\npages = loader.load()"
  },
  {
    "objectID": "slides/02_document_splitting.html#define-splitter-1",
    "href": "slides/02_document_splitting.html#define-splitter-1",
    "title": "Document Splitting",
    "section": "Define splitter",
    "text": "Define splitter\n\ntext_splitter = CharacterTextSplitter(\n    separator=\"\\n\",\n    chunk_size=1000,\n    chunk_overlap=150,\n    length_function=len\n)"
  },
  {
    "objectID": "slides/02_document_splitting.html#split-document",
    "href": "slides/02_document_splitting.html#split-document",
    "title": "Document Splitting",
    "section": "Split document",
    "text": "Split document\n\ndocs = text_splitter.split_documents(pages)"
  },
  {
    "objectID": "slides/02_document_splitting.html#inspect-data",
    "href": "slides/02_document_splitting.html#inspect-data",
    "title": "Document Splitting",
    "section": "Inspect data",
    "text": "Inspect data\n\nlen(docs)\n\n\n77\n\n\n\nlen(pages)\n\n\n22"
  },
  {
    "objectID": "slides/02_document_splitting.html#inspect-data-1",
    "href": "slides/02_document_splitting.html#inspect-data-1",
    "title": "Document Splitting",
    "section": "Inspect data",
    "text": "Inspect data\n\nprint(docs[0].page_content[300:800])\n\n\nmy name‚Äôs Andrew Ng and I‚Äôll be instru ctor for this class. And so I personally work in machine learning, and I‚Äô ve worked on it for about 15 years now, and I actually think that machine learning is th e most exciting field of all the computer sciences. So I‚Äôm actually always excited about teaching this class. Sometimes I actually think that machine learning is not only the most exciting thin g in computer science, but the most exciting thing in all of human e ndeavor, so maybe a little b"
  },
  {
    "objectID": "slides/02_document_splitting.html#load-data",
    "href": "slides/02_document_splitting.html#load-data",
    "title": "Document Splitting",
    "section": "Load data",
    "text": "Load data\n\nloader = NotionDirectoryLoader(\"../docs/Notion_DB\")\nnotion_db = loader.load()"
  },
  {
    "objectID": "slides/02_document_splitting.html#define-splitter-2",
    "href": "slides/02_document_splitting.html#define-splitter-2",
    "title": "Document Splitting",
    "section": "Define splitter",
    "text": "Define splitter\n\ntext_splitter = CharacterTextSplitter(\n    separator=\"\\n\",\n    chunk_size=1000,\n    chunk_overlap=150,\n    length_function=len\n)"
  },
  {
    "objectID": "slides/02_document_splitting.html#split-document-1",
    "href": "slides/02_document_splitting.html#split-document-1",
    "title": "Document Splitting",
    "section": "Split document",
    "text": "Split document\n\ndocs = text_splitter.split_documents(notion_db)"
  },
  {
    "objectID": "slides/02_document_splitting.html#inspect-data-2",
    "href": "slides/02_document_splitting.html#inspect-data-2",
    "title": "Document Splitting",
    "section": "Inspect data",
    "text": "Inspect data\n\nlen(notion_db)\n\n\n1\n\n\n\nlen(docs)\n\n\n2"
  },
  {
    "objectID": "slides/02_document_splitting.html#inspect-data-smaller",
    "href": "slides/02_document_splitting.html#inspect-data-smaller",
    "title": "Document Splitting",
    "section": "Inspect data {smaller}",
    "text": "Inspect data {smaller}\n\nprint(docs[0].page_content)\n\n# Getting Started\nüëã Welcome to Notion!\nHere are the basics:\n- [ ]  Click anywhere and just start typing\n- [ ]  Hit `/` to see all the types of content you can add - headers, videos, sub pages, etc.\n    \n    [Example sub page](https://www.notion.so/Example-sub-page-92f63253929d456bbf12cd696e21e045?pvs=21)\n    \n- [ ]  Highlight any text, and use the menu that pops up to **style** *your* ~~writing~~ `however` [you](https://www.notion.so/product) like\n- [ ]  See the `‚ãÆ‚ãÆ` to the left of this checkbox on hover? Click and drag to move this line\n- [ ]  Click the `+ New Page` button at the bottom of your sidebar to add a new page\n- [ ]  Click `Templates` in your sidebar to get started with pre-built pages\n- This is a toggle block. Click the little triangle to see more useful tips!\n    - [Template Gallery](https://www.notion.so/181e961aeb5c4ee6915307c0dfd5156d?pvs=21): More templates built by the Notion community"
  },
  {
    "objectID": "slides/02_document_splitting.html#basics",
    "href": "slides/02_document_splitting.html#basics",
    "title": "Document Splitting",
    "section": "Basics",
    "text": "Basics\n\nWe can also split on token count explicity, if we want\nThis can be useful because LLMs often have context windows designated in tokens\nTokens are often ~4 characters."
  },
  {
    "objectID": "slides/02_document_splitting.html#tokentextsplitter-1",
    "href": "slides/02_document_splitting.html#tokentextsplitter-1",
    "title": "Document Splitting",
    "section": "TokenTextSplitter 1",
    "text": "TokenTextSplitter 1\n\ntext_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)\n\n\n\ntext1 = \"foo bar bazzyfoo\"\n\n\n\n\ntext_splitter.split_text(text1)\n\n\n[‚Äòfoo‚Äô, ‚Äô bar‚Äô, ‚Äô b‚Äô, ‚Äòaz‚Äô, ‚Äòzy‚Äô, ‚Äòfoo‚Äô]"
  },
  {
    "objectID": "slides/02_document_splitting.html#split-text",
    "href": "slides/02_document_splitting.html#split-text",
    "title": "Document Splitting",
    "section": "Split text",
    "text": "Split text\n\nmd_header_splits = markdown_splitter.split_text(markdown_document)\n\n\n\nmd_header_splits[0]\n\n\nDocument(page_content=‚ÄòHi this is Jim this is Joe‚Äô, metadata={‚ÄòHeader 1‚Äô: ‚ÄòTitle‚Äô, ‚ÄòHeader 2‚Äô: ‚ÄòChapter 1‚Äô})\n\n\n\n\nmd_header_splits[1]\n\n\nDocument(page_content=‚ÄòHi this is Lance‚Äô, metadata={‚ÄòHeader 1‚Äô: ‚ÄòTitle‚Äô, ‚ÄòHeader 2‚Äô: ‚ÄòChapter 1‚Äô, ‚ÄòHeader 3‚Äô: ‚ÄòSection‚Äô})"
  },
  {
    "objectID": "slides/02_document_splitting.html#tokentextsplitter-2",
    "href": "slides/02_document_splitting.html#tokentextsplitter-2",
    "title": "Document Splitting",
    "section": "TokenTextSplitter 2",
    "text": "TokenTextSplitter 2\n\ntext_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)\n\n\n\ndocs = text_splitter.split_documents(pages)\n\n\n\n\ndocs[0]\n\n\nDocument(page_content=‚ÄòMachineLearning-Lecture01 ‚Äô, metadata={‚Äòsource‚Äô: ‚Äò../docs/cs229_lectures/MachineLearning-Lecture01.pdf‚Äô, ‚Äòpage‚Äô: 0})\n\n\n\n\npages[0].metadata\n\n\n{‚Äòsource‚Äô: ‚Äò../docs/cs229_lectures/MachineLearning-Lecture01.pdf‚Äô, ‚Äòpage‚Äô: 0}"
  },
  {
    "objectID": "slides/02_document_splitting.html#split-text-1",
    "href": "slides/02_document_splitting.html#split-text-1",
    "title": "Document Splitting",
    "section": "Split text",
    "text": "Split text\n\nmd_header_splits = markdown_splitter.split_text(txt)"
  },
  {
    "objectID": "slides/02_document_splitting.html#basics-1",
    "href": "slides/02_document_splitting.html#basics-1",
    "title": "Document Splitting",
    "section": "Basics",
    "text": "Basics\n\nChunking aims to keep text with common context together.\nA text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\nWe can use MarkdownHeaderTextSplitter to preserve header metadata in our chunks"
  },
  {
    "objectID": "slides/02_document_splitting.html#markdown-example",
    "href": "slides/02_document_splitting.html#markdown-example",
    "title": "Document Splitting",
    "section": "Markdown example",
    "text": "Markdown example\n\nmarkdown_document = \"\"\"# Title\\n\\n \\\n## Chapter 1\\n\\n \\\nHi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n### Section \\n\\n \\\nHi this is Lance \\n\\n \n## Chapter 2\\n\\n \\\nHi this is Molly\"\"\""
  },
  {
    "objectID": "slides/02_document_splitting.html#headers-to-split-on",
    "href": "slides/02_document_splitting.html#headers-to-split-on",
    "title": "Document Splitting",
    "section": "Headers to split on",
    "text": "Headers to split on\n\nheaders_to_split_on = [\n    (\"#\", \"Header 1\"),\n    (\"##\", \"Header 2\"),\n    (\"###\", \"Header 3\"),\n]"
  },
  {
    "objectID": "slides/02_document_splitting.html#markdownheadertextsplitter",
    "href": "slides/02_document_splitting.html#markdownheadertextsplitter",
    "title": "Document Splitting",
    "section": "MarkdownHeaderTextSplitter",
    "text": "MarkdownHeaderTextSplitter\n\nmarkdown_splitter = MarkdownHeaderTextSplitter(\n    headers_to_split_on=headers_to_split_on\n)"
  },
  {
    "objectID": "slides/02_document_splitting.html#split-text-2",
    "href": "slides/02_document_splitting.html#split-text-2",
    "title": "Document Splitting",
    "section": "Split text",
    "text": "Split text\n\nmd_header_splits = markdown_splitter.split_text(markdown_document)\n\n\n\nmd_header_splits[0]\n\n\n\n\n\nDocument(page_content=‚ÄòHi this is Jim this is Joe‚Äô, metadata={‚ÄòHeader 1‚Äô: ‚ÄòTitle‚Äô, ‚ÄòHeader 2‚Äô: ‚ÄòChapter 1‚Äô})\n\n\nmd_header_splits[1]\n\n\n\n\n\nDocument(page_content=‚ÄòHi this is Lance‚Äô, metadata={‚ÄòHeader 1‚Äô: ‚ÄòTitle‚Äô, ‚ÄòHeader 2‚Äô: ‚ÄòChapter 1‚Äô, ‚ÄòHeader 3‚Äô: ‚ÄòSection‚Äô})"
  },
  {
    "objectID": "slides/02_document_splitting.html#splitting-notion-markdown",
    "href": "slides/02_document_splitting.html#splitting-notion-markdown",
    "title": "Document Splitting",
    "section": "Splitting Notion Markdown",
    "text": "Splitting Notion Markdown"
  },
  {
    "objectID": "slides/02_document_splitting.html#load-data-1",
    "href": "slides/02_document_splitting.html#load-data-1",
    "title": "Document Splitting",
    "section": "Load data",
    "text": "Load data\n\nloader = NotionDirectoryLoader(\"../docs/Notion_DB\")\ndocs = loader.load()"
  },
  {
    "objectID": "slides/02_document_splitting.html#join-data",
    "href": "slides/02_document_splitting.html#join-data",
    "title": "Document Splitting",
    "section": "Join data",
    "text": "Join data\n\ntxt = ' '.join([d.page_content for d in docs])\ntxt\n\n\n‚Äò# Getting Startedüëã Welcome to Notion!are the basics:- [ ] Click anywhere and just start typing- [ ] Hit / to see all the types of content you can add - headers, videos, sub pages, etc.(https://www.notion.so/Example-sub-page-92f63253929d456bbf12cd696e21e045?pvs=21)- [ ] Highlight any text, and use the menu that pops up to style your writing however you like- [ ] See the ‚ãÆ‚ãÆ to the left of this checkbox on hover? Click and drag to move this line- [ ] Click the + New Page button at the bottom of your sidebar to add a new page- [ ] Click Templates in your sidebar to get started with pre-built pages- This is a toggle block. Click the little triangle to see more useful tips!- Template Gallery: More templates built by the Notion community- Help & Support: ****Guides and FAQs for everything in Notion- Stay organized with your sidebar and nested pages:it in action:(https://youtu.be/TL_N2pmh9O0) minute(https://youtu.be/FXIrojSK3Jo) minutes(https://youtu.be/2Pwzff-uffU) minutes(https://youtu.be/O8qdvSxDYNY) minutesour YouTube channel to watch 50+ more tutorialsüëâHave a question? Click the ? at the bottom right for more guides, or to send us a message.‚Äô"
  },
  {
    "objectID": "slides/02_document_splitting.html#define-splitter-3",
    "href": "slides/02_document_splitting.html#define-splitter-3",
    "title": "Document Splitting",
    "section": "Define Splitter",
    "text": "Define Splitter\n\nheaders_to_split_on = [\n    (\"#\", \"Header 1\"),\n    (\"##\", \"Header 2\"),\n]\n\n\n\nmarkdown_splitter = MarkdownHeaderTextSplitter(\n    headers_to_split_on=headers_to_split_on\n)"
  },
  {
    "objectID": "slides/02_document_splitting.html#split-text-3",
    "href": "slides/02_document_splitting.html#split-text-3",
    "title": "Document Splitting",
    "section": "Split text",
    "text": "Split text\n\nmd_header_splits = markdown_splitter.split_text(txt)"
  },
  {
    "objectID": "slides/02_document_splitting.html#output",
    "href": "slides/02_document_splitting.html#output",
    "title": "Document Splitting",
    "section": "Output",
    "text": "Output\n\nmd_header_splits[0]\n\n\nDocument(page_content=‚Äòüëã Welcome to Notion! are the basics: - [ ] Click anywhere and just start typing- [ ] Hit / to see all the types of content you can add - headers, videos, sub pages, etc. (https://www.notion.so/Example-sub-page-92f63253929d456bbf12cd696e21e045?pvs=21) - [ ] Highlight any text, and use the menu that pops up to style your writing however you like- [ ] See the ‚ãÆ‚ãÆ to the left of this checkbox on hover? Click and drag to move this line- [ ] Click the + New Page button at the bottom of your sidebar to add a new page- [ ] Click Templates in your sidebar to get started with pre-built pages- This is a toggle block. Click the little triangle to see more useful tips!- Template Gallery: More templates built by the Notion community- Help & Support: ****Guides and FAQs for everything in Notion- Stay organized with your sidebar and nested pages:  it in action: (https://youtu.be/TL_N2pmh9O0) minute (https://youtu.be/FXIrojSK3Jo) minutes (https://youtu.be/2Pwzff-uffU) minutes (https://youtu.be/O8qdvSxDYNY) minutes our YouTube channel to watch 50+ more tutorials üëâHave a question? Click the ? at the bottom right for more guides, or to send us a message.‚Äô, metadata={‚ÄòHeader 1‚Äô: ‚ÄòGetting Started‚Äô})"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#python",
    "href": "slides/03_vectorstores_and_embeddings.html#python",
    "title": "Vectorstores and Embeddings",
    "section": "Python",
    "text": "Python\n\nimport os\nimport numpy as np\nimport openai\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.vectorstores import Chroma\n\n\n#import sys\n#sys.path.append('../..')\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # read local .env file\n\nopenai.api_key  = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#load-data",
    "href": "slides/03_vectorstores_and_embeddings.html#load-data",
    "title": "Vectorstores and Embeddings",
    "section": "Load data",
    "text": "Load data\n\n# Load PDF\nloaders = [\n    # Duplicate documents on purpose - messy data\n    PyPDFLoader(\"../docs/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n    PyPDFLoader(\"../docs/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n    PyPDFLoader(\"../docs/cs229_lectures/MachineLearning-Lecture02.pdf\"),\n    PyPDFLoader(\"../docs/cs229_lectures/MachineLearning-Lecture03.pdf\")\n]\n\ndocs = []\nfor loader in loaders:\n    docs.extend(loader.load())"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#define-splitter",
    "href": "slides/03_vectorstores_and_embeddings.html#define-splitter",
    "title": "Vectorstores and Embeddings",
    "section": "Define splitter",
    "text": "Define splitter\n\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size = 1500,\n    chunk_overlap = 150\n)"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#split-data",
    "href": "slides/03_vectorstores_and_embeddings.html#split-data",
    "title": "Vectorstores and Embeddings",
    "section": "Split data",
    "text": "Split data\n\nsplits = text_splitter.split_documents(docs)\n\n\n\nlen(splits)\n\n\n209"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#openaiembeddings",
    "href": "slides/03_vectorstores_and_embeddings.html#openaiembeddings",
    "title": "Vectorstores and Embeddings",
    "section": "OpenAIEmbeddings",
    "text": "OpenAIEmbeddings\n\nLet‚Äôs take our splits and embed them.\n\n\n\nembedding = OpenAIEmbeddings()"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#examples",
    "href": "slides/03_vectorstores_and_embeddings.html#examples",
    "title": "Vectorstores and Embeddings",
    "section": "Examples",
    "text": "Examples\n\nsentence1 = \"i like dogs\"\nsentence2 = \"i like canines\"\nsentence3 = \"the weather is ugly outside\"\n\n\n\nembedding1 = embedding.embed_query(sentence1)\nembedding2 = embedding.embed_query(sentence2)\nembedding3 = embedding.embed_query(sentence3)"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#compare-similarity",
    "href": "slides/03_vectorstores_and_embeddings.html#compare-similarity",
    "title": "Vectorstores and Embeddings",
    "section": "Compare similarity",
    "text": "Compare similarity\n\nnp.dot(embedding1, embedding2)\n\n\n0.9631851837941705\n\n\n\nnp.dot(embedding1, embedding3)\n\n\n0.7710851013557284\n\n\n\n\nnp.dot(embedding2, embedding3)\n\n\n0.7596334120325541"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#setup-1",
    "href": "slides/03_vectorstores_and_embeddings.html#setup-1",
    "title": "Vectorstores and Embeddings",
    "section": "Setup",
    "text": "Setup\n\npersist_directory = '../docs/chroma/'\n\n\n\n!rm -rf ../docs/chroma  # remove old database files if any"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#store-data",
    "href": "slides/03_vectorstores_and_embeddings.html#store-data",
    "title": "Vectorstores and Embeddings",
    "section": "Store data",
    "text": "Store data\n\nvectordb = Chroma.from_documents(\n    documents=splits,\n    embedding=embedding,\n    persist_directory=persist_directory\n)"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#inspect-data",
    "href": "slides/03_vectorstores_and_embeddings.html#inspect-data",
    "title": "Vectorstores and Embeddings",
    "section": "Inspect data",
    "text": "Inspect data\n\nprint(vectordb._collection.count())\n\n\n209"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#search-vectorstore-for-email",
    "href": "slides/03_vectorstores_and_embeddings.html#search-vectorstore-for-email",
    "title": "Vectorstores and Embeddings",
    "section": "Search vectorstore for email",
    "text": "Search vectorstore for email\n\nquestion = \"is there an email i can ask for help\"\n\n\n\ndocs = vectordb.similarity_search(question,k=3)\n\n\n\n\nlen(docs)\n\n\n3"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#inspect-data-1",
    "href": "slides/03_vectorstores_and_embeddings.html#inspect-data-1",
    "title": "Vectorstores and Embeddings",
    "section": "Inspect data",
    "text": "Inspect data\n\ndocs[0].page_content\n\n\n‚Äúcs229-qa@cs.stanford.edu. This goes to an acc ount that‚Äôs read by all the TAs and me. So than sending us email individually, if you send email to this account, it will let us get back to you maximally quickly with answers to your questions. you‚Äôre asking questions about homework probl ems, please say in the subject line which and which question the email refers to, since that will also help us to route question to the appropriate TA or to me appropriately and get the response back to quickly. ‚Äòs see. Skipping ahead ‚Äî let‚Äôs see ‚Äî for homework, one midterm, one open and term . Notice on the honor code. So one thi ng that I think will help you to succeed and well in this class and even help you to enjoy this cla ss more is if you form a study . start looking around where you‚Äô re sitting now or at the end of class today, mingle a bit and get to know your classmates. I strongly encourage you to form study groups sort of have a group of people to study with and have a group of your fellow students talk over these concepts with. You can also post on the class news group if you want to that to try to form a study group. some of the problems sets in this cla ss are reasonably difficult. People that have the class before may tell you they were very difficult. And just I bet it would be fun for you, and you‚Äôd probably have a be tter learning experience if you form a‚Äù"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#persist-data",
    "href": "slides/03_vectorstores_and_embeddings.html#persist-data",
    "title": "Vectorstores and Embeddings",
    "section": "Persist data",
    "text": "Persist data\n\nLet‚Äôs save this so we can use it later!\n\n\n\nvectordb.persist()"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#basics",
    "href": "slides/03_vectorstores_and_embeddings.html#basics",
    "title": "Vectorstores and Embeddings",
    "section": "Basics",
    "text": "Basics\n\nThis seems great, and basic similarity search will get you 80% of the way there very easily.\nBut there are some failure modes that can creep up.\nHere are some edge cases that can arise"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#search-vectorstore-for-matlab",
    "href": "slides/03_vectorstores_and_embeddings.html#search-vectorstore-for-matlab",
    "title": "Vectorstores and Embeddings",
    "section": "Search vectorstore for matlab",
    "text": "Search vectorstore for matlab\n\nquestion = \"what did they say about matlab?\"\n\n\n\ndocs = vectordb.similarity_search(question,k=5)"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#inspect-data-2",
    "href": "slides/03_vectorstores_and_embeddings.html#inspect-data-2",
    "title": "Vectorstores and Embeddings",
    "section": "Inspect data",
    "text": "Inspect data\n\ndocs[0]\n\n\nDocument(page_content=‚Äòthose homeworks will be done in either MATLA B or in Octave, which is sort of ‚Äî I some people call it a free ve rsion of MATLAB, which it sort of is, sort of isn't. I guess for those of you that haven't s een MATLAB before, and I know most of you , MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to data. And it's sort of an extremely easy to learn tool to use for implementing a lot of algorithms. in case some of you want to work on your own home computer or something if you 't have a MATLAB license, for the purposes of this class, there's also ‚Äî [inaudible] that down [inaudible] MATLAB ‚Äî there' s also a software package called Octave you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of this class, it will work for just about . actually I, well, so yeah, just a side comment for those of you that haven't seen before I guess, once a colleague of mine at a different university, not at , actually teaches another machine l earning course. He's taught it for many years. one day, he was in his office, and an old student of his from, lik e, ten years ago came his office and he said, ‚ÄúOh, professo r, professor, thank you so much for your‚Äô, metadata={‚Äòsource‚Äô: ‚Äò../docs/cs229_lectures/MachineLearning-Lecture01.pdf‚Äô, ‚Äòpage‚Äô: 8})\n\n\ndocs[1]\n\n\nDocument(page_content=‚Äòthose homeworks will be done in either MATLA B or in Octave, which is sort of ‚Äî I some people call it a free ve rsion of MATLAB, which it sort of is, sort of isn't. I guess for those of you that haven't s een MATLAB before, and I know most of you , MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to data. And it's sort of an extremely easy to learn tool to use for implementing a lot of algorithms. in case some of you want to work on your own home computer or something if you 't have a MATLAB license, for the purposes of this class, there's also ‚Äî [inaudible] that down [inaudible] MATLAB ‚Äî there' s also a software package called Octave you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of this class, it will work for just about . actually I, well, so yeah, just a side comment for those of you that haven't seen before I guess, once a colleague of mine at a different university, not at , actually teaches another machine l earning course. He's taught it for many years. one day, he was in his office, and an old student of his from, lik e, ten years ago came his office and he said, ‚ÄúOh, professo r, professor, thank you so much for your‚Äô, metadata={‚Äòsource‚Äô: ‚Äò../docs/cs229_lectures/MachineLearning-Lecture01.pdf‚Äô, ‚Äòpage‚Äô: 8})"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#insights",
    "href": "slides/03_vectorstores_and_embeddings.html#insights",
    "title": "Vectorstores and Embeddings",
    "section": "Insights",
    "text": "Insights\n\nNotice that we‚Äôre getting duplicate chunks (because of the duplicate MachineLearning-Lecture01.pdf in the index).\nSemantic search fetches all similar documents, but does not enforce diversity.\ndocs[0] and docs[1] are indentical."
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#search-vectorstore-for-third-lecture",
    "href": "slides/03_vectorstores_and_embeddings.html#search-vectorstore-for-third-lecture",
    "title": "Vectorstores and Embeddings",
    "section": "Search vectorstore for third lecture",
    "text": "Search vectorstore for third lecture\n\nquestion = \"what did they say about regression in the third lecture?\"\n\n\n\ndocs = vectordb.similarity_search(question,k=5)"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#inspect-data-3",
    "href": "slides/03_vectorstores_and_embeddings.html#inspect-data-3",
    "title": "Vectorstores and Embeddings",
    "section": "Inspect data",
    "text": "Inspect data\n\nfor doc in docs:\n    print(doc.metadata)\n\n\n\n{'source': '../docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 0}\n{'source': '../docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 14}\n{'source': '../docs/cs229_lectures/MachineLearning-Lecture02.pdf', 'page': 0}\n{'source': '../docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 6}\n{'source': '../docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 8}\n\n\nThe question was about the third lecture, but includes results from other lectures as well.\nWe discuss approaches to handle these problems in the next tutorial"
  },
  {
    "objectID": "slides/04_retrieval.html#python",
    "href": "slides/04_retrieval.html#python",
    "title": "Vectorstore Retrieval",
    "section": "Python",
    "text": "Python\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.retrievers import TFIDFRetriever\nfrom langchain.retrievers import SVMRetriever\nfrom langchain.retrievers.document_compressors import LLMChainExtractor\nfrom langchain.retrievers import ContextualCompressionRetriever\nfrom langchain.chains.query_constructor.base import AttributeInfo\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain.llms import OpenAI\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom dotenv import load_dotenv, find_dotenv\nimport os\nimport openai\n# import sys\n# sys.path.append('../..')\n\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nopenai.api_key = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "slides/04_retrieval.html#setup-1",
    "href": "slides/04_retrieval.html#setup-1",
    "title": "Vectorstore Retrieval",
    "section": "Setup",
    "text": "Setup\nLet‚Äôs get our vectorDB from Tutorial 3.\n\npersist_directory = '../docs/chroma/'\n\n\n\nembedding = OpenAIEmbeddings()\n\n\n\n\nvectordb = Chroma(\n    persist_directory=persist_directory,\n    embedding_function=embedding\n)\n\n\n\n\nprint(vectordb._collection.count())\n\n\n209"
  },
  {
    "objectID": "slides/04_retrieval.html#text",
    "href": "slides/04_retrieval.html#text",
    "title": "Vectorstore Retrieval",
    "section": "Text",
    "text": "Text\n\ntexts = [\n    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n]"
  },
  {
    "objectID": "slides/04_retrieval.html#embedding",
    "href": "slides/04_retrieval.html#embedding",
    "title": "Vectorstore Retrieval",
    "section": "Embedding",
    "text": "Embedding\n\nsmalldb = Chroma.from_texts(texts, embedding=embedding)"
  },
  {
    "objectID": "slides/04_retrieval.html#question",
    "href": "slides/04_retrieval.html#question",
    "title": "Vectorstore Retrieval",
    "section": "Question",
    "text": "Question\n\nquestion = \"what did they say about matlab?\"\n\n\nRetriever\n\n\n\ncompressed_docs = compression_retriever.get_relevant_documents(question)"
  },
  {
    "objectID": "slides/04_retrieval.html#result-1",
    "href": "slides/04_retrieval.html#result-1",
    "title": "Vectorstore Retrieval",
    "section": "Result 1",
    "text": "Result 1\n\nsmalldb.similarity_search(question, k=2)\n\n\n[Document(page_content=‚ÄòA mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.‚Äô, metadata={}), Document(page_content=‚ÄòThe Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).‚Äô, metadata={})]"
  },
  {
    "objectID": "slides/04_retrieval.html#result-2",
    "href": "slides/04_retrieval.html#result-2",
    "title": "Vectorstore Retrieval",
    "section": "Result 2",
    "text": "Result 2\n\nsmalldb.max_marginal_relevance_search(question, k=2, fetch_k=3)\n\n\n[Document(page_content=‚ÄòA mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.‚Äô, metadata={}), Document(page_content=‚ÄòA. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.‚Äô, metadata={})]"
  },
  {
    "objectID": "slides/04_retrieval.html#basics",
    "href": "slides/04_retrieval.html#basics",
    "title": "Vectorstore Retrieval",
    "section": "Basics",
    "text": "Basics\n\nAddressing Diversity: Maximum marginal relevance (MMR)\nIn Tutorial 3 we introduced one problem: how to enforce diversity in the search results.\nMaximum marginal relevance strives to achieve both relevance to the query and diversity among the results."
  },
  {
    "objectID": "slides/04_retrieval.html#question-about-matlab",
    "href": "slides/04_retrieval.html#question-about-matlab",
    "title": "Vectorstore Retrieval",
    "section": "Question about matlab",
    "text": "Question about matlab\n\nquestion = \"what did they say about matlab?\"\n\n\nSimilarity search\n\n\n\ndocs_ss = vectordb.similarity_search(question, k=3)"
  },
  {
    "objectID": "slides/04_retrieval.html#similarity-search",
    "href": "slides/04_retrieval.html#similarity-search",
    "title": "Vectorstore Retrieval",
    "section": "Similarity search",
    "text": "Similarity search\n\ndocs_ss = vectordb.similarity_search(question, k=3)"
  },
  {
    "objectID": "slides/04_retrieval.html#results",
    "href": "slides/04_retrieval.html#results",
    "title": "Vectorstore Retrieval",
    "section": "Results",
    "text": "Results\n\ndocs_ss[0].page_content[:100]\n\n\n‚Äòthose homeworks will be done in either MATLA B or in Octave, which is sort of ‚Äî I some people‚Äô\n\n\n\ndocs_ss[1].page_content[:100]\n\n\n‚Äòthose homeworks will be done in either MATLA B or in Octave, which is sort of ‚Äî I some people‚Äô"
  },
  {
    "objectID": "slides/04_retrieval.html#mmr",
    "href": "slides/04_retrieval.html#mmr",
    "title": "Vectorstore Retrieval",
    "section": "MMR",
    "text": "MMR\n\ndocs_mmr = vectordb.max_marginal_relevance_search(question, k=3)\n\n\nNote the difference in results with MMR.\n\n\n\ndocs_mmr[0].page_content[:100]\n\n\n‚Äòthose homeworks will be done in either MATLA B or in Octave, which is sort of ‚Äî I some people‚Äô\n\n\n\n\ndocs_mmr[1].page_content[:100]\n\n\n‚Äúmathematical work, he feels like he‚Äôs disc overing truth and beauty in the universe. And says it‚Äù"
  },
  {
    "objectID": "slides/04_retrieval.html#mmr-results",
    "href": "slides/04_retrieval.html#mmr-results",
    "title": "Vectorstore Retrieval",
    "section": "MMR results",
    "text": "MMR results\n\nNote the difference in results with MMR.\n\n\ndocs_mmr[0].page_content[:100]\n\n\n‚Äòthose homeworks will be done in either MATLA B or in Octave, which is sort of ‚Äî I some people‚Äô\n\n\n\ndocs_mmr[1].page_content[:100]\n\n\n‚Äúmathematical work, he feels like he‚Äôs disc overing truth and beauty in the universe. And says it‚Äù"
  },
  {
    "objectID": "slides/04_retrieval.html#basics-1",
    "href": "slides/04_retrieval.html#basics-1",
    "title": "Vectorstore Retrieval",
    "section": "Basics",
    "text": "Basics\n\nAddressing Specificity: working with metadata\nIn Tutorial 3, we showed that a question about the third lecture can include results from other lectures as well.\nTo address this, many vectorstores support operations on metadata.\nmetadata provides context for each embedded chunk."
  },
  {
    "objectID": "slides/04_retrieval.html#question-about-third-lecture",
    "href": "slides/04_retrieval.html#question-about-third-lecture",
    "title": "Vectorstore Retrieval",
    "section": "Question about third lecture",
    "text": "Question about third lecture\n\nquestion = \"what did they say about regression in the third lecture?\"\n\n\nSimilarity search\n\n\n\ndocs = vectordb.similarity_search(\n    question,\n    k=3,\n    filter={\"source\": \"../docs/cs229_lectures/MachineLearning-Lecture03.pdf\"}\n)"
  },
  {
    "objectID": "slides/04_retrieval.html#similarity-search-1",
    "href": "slides/04_retrieval.html#similarity-search-1",
    "title": "Vectorstore Retrieval",
    "section": "Similarity search",
    "text": "Similarity search\n\ndocs = vectordb.similarity_search(\n    question,\n    k=3,\n    filter={\"source\": \"../docs/cs229_lectures/MachineLearning-Lecture03.pdf\"}\n)"
  },
  {
    "objectID": "slides/04_retrieval.html#result",
    "href": "slides/04_retrieval.html#result",
    "title": "Vectorstore Retrieval",
    "section": "Result",
    "text": "Result\n\nfor d in docs:\n    print(d.metadata)\n\n\n{‚Äòsource‚Äô: ‚Äò../docs/cs229_lectures/MachineLearning-Lecture03.pdf‚Äô, ‚Äòpage‚Äô: 0}\n{‚Äòsource‚Äô: ‚Äò../docs/cs229_lectures/MachineLearning-Lecture03.pdf‚Äô, ‚Äòpage‚Äô: 14}\n{‚Äòsource‚Äô: ‚Äò../docs/cs229_lectures/MachineLearning-Lecture03.pdf‚Äô, ‚Äòpage‚Äô: 4}"
  },
  {
    "objectID": "slides/04_retrieval.html#basics-2",
    "href": "slides/04_retrieval.html#basics-2",
    "title": "Vectorstore Retrieval",
    "section": "Basics",
    "text": "Basics\n\nAddressing Specificity: working with metadata using self-query retriever\nBut we have an interesting challenge: we often want to infer the metadata from the query itself.\nTo address this, we can use SelfQueryRetriever, which uses an LLM to extract:\n\n\nThe query string to use for vector search\nA metadata filter to pass in as well\n\n\nMost vector databases support metadata filters, so this doesn‚Äôt require any new databases or indexes."
  },
  {
    "objectID": "slides/04_retrieval.html#metadata_field_info",
    "href": "slides/04_retrieval.html#metadata_field_info",
    "title": "Vectorstore Retrieval",
    "section": "metadata_field_info",
    "text": "metadata_field_info\n\nmetadata_field_info = [\n    AttributeInfo(\n        name=\"source\",\n        description=\"The lecture the chunk is from, should be one of `../docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `../docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `../docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n        type=\"string\",\n    ),\n    AttributeInfo(\n        name=\"page\",\n        description=\"The page from the lecture\",\n        type=\"integer\",\n    ),\n]"
  },
  {
    "objectID": "slides/04_retrieval.html#document_content_description",
    "href": "slides/04_retrieval.html#document_content_description",
    "title": "Vectorstore Retrieval",
    "section": "document_content_description",
    "text": "document_content_description\n\ndocument_content_description = \"Lecture notes\"\nllm = OpenAI(temperature=0)\nretriever = SelfQueryRetriever.from_llm(\n    llm,\n    vectordb,\n    document_content_description,\n    metadata_field_info,\n    verbose=True\n)"
  },
  {
    "objectID": "slides/04_retrieval.html#question-about-third-lecture-1",
    "href": "slides/04_retrieval.html#question-about-third-lecture-1",
    "title": "Vectorstore Retrieval",
    "section": "Question about third lecture",
    "text": "Question about third lecture\n\nquestion = \"what did they say about regression in the third lecture?\"\n\n\nRetriever\n\n\n\ndocs = retriever.get_relevant_documents(question)\n\n\nYou will receive a warning about predict_and_parse being deprecated the first time you executing the next line. This can be safely ignored."
  },
  {
    "objectID": "slides/04_retrieval.html#retriever",
    "href": "slides/04_retrieval.html#retriever",
    "title": "Vectorstore Retrieval",
    "section": "Retriever",
    "text": "Retriever\n\ndocs = retriever.get_relevant_documents(question)\n\n\nYou will receive a warning about predict_and_parse being deprecated the first time you executing the next line. This can be safely ignored."
  },
  {
    "objectID": "slides/04_retrieval.html#result-3",
    "href": "slides/04_retrieval.html#result-3",
    "title": "Vectorstore Retrieval",
    "section": "Result",
    "text": "Result\n\nfor doc in docs:\n    print(doc.metadata)\n\n{'source': '../docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 14}\n{'source': '../docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 0}\n{'source': '../docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 10}\n{'source': '../docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 10}"
  },
  {
    "objectID": "slides/04_retrieval.html#basics-3",
    "href": "slides/04_retrieval.html#basics-3",
    "title": "Vectorstore Retrieval",
    "section": "Basics",
    "text": "Basics\n\nAnother approach for improving the quality of retrieved docs is compression.\nInformation most relevant to a query may be buried in a document with a lot of irrelevant text.\nPassing that full document through your application can lead to more expensive LLM calls and poorer responses.\nContextual compression is meant to fix this."
  },
  {
    "objectID": "slides/04_retrieval.html#helper-function-pretty-print",
    "href": "slides/04_retrieval.html#helper-function-pretty-print",
    "title": "Vectorstore Retrieval",
    "section": "Helper function: pretty print",
    "text": "Helper function: pretty print\n\ndef pretty_print_docs(docs):\n    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" +\n          d.page_content for i, d in enumerate(docs)]))"
  },
  {
    "objectID": "slides/04_retrieval.html#load-llm",
    "href": "slides/04_retrieval.html#load-llm",
    "title": "Vectorstore Retrieval",
    "section": "Load LLM",
    "text": "Load LLM\n\n# Wrap our vectorstore\nllm = OpenAI(temperature=0)\ncompressor = LLMChainExtractor.from_llm(llm)"
  },
  {
    "objectID": "slides/04_retrieval.html#contextualcompressionretriever",
    "href": "slides/04_retrieval.html#contextualcompressionretriever",
    "title": "Vectorstore Retrieval",
    "section": "ContextualCompressionRetriever",
    "text": "ContextualCompressionRetriever\n\ncompression_retriever = ContextualCompressionRetriever(\n    base_compressor=compressor,\n    base_retriever=vectordb.as_retriever()\n)"
  },
  {
    "objectID": "slides/04_retrieval.html#question-about-matlab-1",
    "href": "slides/04_retrieval.html#question-about-matlab-1",
    "title": "Vectorstore Retrieval",
    "section": "Question about matlab",
    "text": "Question about matlab\n\nquestion = \"what did they say about matlab?\"\n\n\nRetriever\n\n\n\ncompressed_docs = compression_retriever.get_relevant_documents(question)"
  },
  {
    "objectID": "slides/04_retrieval.html#retriever-1",
    "href": "slides/04_retrieval.html#retriever-1",
    "title": "Vectorstore Retrieval",
    "section": "Retriever",
    "text": "Retriever\n\ncompressed_docs = compression_retriever.get_relevant_documents(question)"
  },
  {
    "objectID": "slides/04_retrieval.html#result-4",
    "href": "slides/04_retrieval.html#result-4",
    "title": "Vectorstore Retrieval",
    "section": "Result",
    "text": "Result\n\npretty_print_docs(compressed_docs)\n\nDocument 1:\n\n\"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.\"\n----------------------------------------------------------------------------------------------------\nDocument 2:\n\n\"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.\"\n----------------------------------------------------------------------------------------------------\nDocument 3:\n\n\"And the student said, \"Oh, it was the MATLAB.\" So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, and we'll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don't know it.\"\n----------------------------------------------------------------------------------------------------\nDocument 4:\n\n\"And the student said, \"Oh, it was the MATLAB.\" So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, and we'll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don't know it.\""
  },
  {
    "objectID": "slides/04_retrieval.html#matlab-is-i-guess-part-of-the-programming-language-that-makes-it-very-easy-to-write-codes-using-matrices-to-write-code-for-numerical-routines-to-move-data-around-to-plot-data.-and-its-sort-of-an-extremely-easy-to-learn-tool-to-use-for-implementing-a-lot-of-learning-algorithms.",
    "href": "slides/04_retrieval.html#matlab-is-i-guess-part-of-the-programming-language-that-makes-it-very-easy-to-write-codes-using-matrices-to-write-code-for-numerical-routines-to-move-data-around-to-plot-data.-and-its-sort-of-an-extremely-easy-to-learn-tool-to-use-for-implementing-a-lot-of-learning-algorithms.",
    "title": "Vectorstore Retrieval",
    "section": "‚ÄúMATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it‚Äôs sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.‚Äù",
    "text": "‚ÄúMATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it‚Äôs sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.‚Äù\nDocument 2:"
  },
  {
    "objectID": "slides/04_retrieval.html#matlab-is-i-guess-part-of-the-programming-language-that-makes-it-very-easy-to-write-codes-using-matrices-to-write-code-for-numerical-routines-to-move-data-around-to-plot-data.-and-its-sort-of-an-extremely-easy-to-learn-tool-to-use-for-implementing-a-lot-of-learning-algorithms.-1",
    "href": "slides/04_retrieval.html#matlab-is-i-guess-part-of-the-programming-language-that-makes-it-very-easy-to-write-codes-using-matrices-to-write-code-for-numerical-routines-to-move-data-around-to-plot-data.-and-its-sort-of-an-extremely-easy-to-learn-tool-to-use-for-implementing-a-lot-of-learning-algorithms.-1",
    "title": "Vectorstore Retrieval",
    "section": "‚ÄúMATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it‚Äôs sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.‚Äù",
    "text": "‚ÄúMATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it‚Äôs sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.‚Äù\nDocument 3:"
  },
  {
    "objectID": "slides/04_retrieval.html#and-the-student-saidoh-it-was-the-matlab.-so-for-those-of-you-that-dont-know-matlab-yet-i-hope-you-do-learn-it.-its-not-hard-and-well-actually-have-a-short-matlab-tutorial-in-one-of-the-discussion-sections-for-those-of-you-that-dont-know-it.",
    "href": "slides/04_retrieval.html#and-the-student-saidoh-it-was-the-matlab.-so-for-those-of-you-that-dont-know-matlab-yet-i-hope-you-do-learn-it.-its-not-hard-and-well-actually-have-a-short-matlab-tutorial-in-one-of-the-discussion-sections-for-those-of-you-that-dont-know-it.",
    "title": "Vectorstore Retrieval",
    "section": "‚ÄúAnd the student said,‚ÄùOh, it was the MATLAB.‚Äù So for those of you that don‚Äôt know MATLAB yet, I hope you do learn it. It‚Äôs not hard, and we‚Äôll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don‚Äôt know it.‚Äù",
    "text": "‚ÄúAnd the student said,‚ÄùOh, it was the MATLAB.‚Äù So for those of you that don‚Äôt know MATLAB yet, I hope you do learn it. It‚Äôs not hard, and we‚Äôll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don‚Äôt know it.‚Äù\nDocument 4:\n‚ÄúAnd the student said,‚ÄùOh, it was the MATLAB.‚Äù So for those of you that don‚Äôt know MATLAB yet, I hope you do learn it. It‚Äôs not hard, and we‚Äôll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don‚Äôt know it.‚Äù"
  },
  {
    "objectID": "slides/04_retrieval.html#contextualcompressionretriever-with-mmr",
    "href": "slides/04_retrieval.html#contextualcompressionretriever-with-mmr",
    "title": "Vectorstore Retrieval",
    "section": "ContextualCompressionRetriever with MMR",
    "text": "ContextualCompressionRetriever with MMR\n\ncompression_retriever = ContextualCompressionRetriever(\n    base_compressor=compressor,\n    base_retriever=vectordb.as_retriever(search_type=\"mmr\")\n)"
  },
  {
    "objectID": "slides/04_retrieval.html#question-1",
    "href": "slides/04_retrieval.html#question-1",
    "title": "Vectorstore Retrieval",
    "section": "Question",
    "text": "Question\n\nquestion = \"what did they say about matlab?\""
  },
  {
    "objectID": "slides/04_retrieval.html#retriever-2",
    "href": "slides/04_retrieval.html#retriever-2",
    "title": "Vectorstore Retrieval",
    "section": "Retriever",
    "text": "Retriever\n\ncompressed_docs = compression_retriever.get_relevant_documents(question)"
  },
  {
    "objectID": "slides/04_retrieval.html#result-5",
    "href": "slides/04_retrieval.html#result-5",
    "title": "Vectorstore Retrieval",
    "section": "Result",
    "text": "Result\n\npretty_print_docs(compressed_docs)\n\n\nDocument 1:\n\n\"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.\"\n----------------------------------------------------------------------------------------------------\nDocument 2:\n\n\"And the student said, \"Oh, it was the MATLAB.\" So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, and we'll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don't know it.\""
  },
  {
    "objectID": "slides/04_retrieval.html#matlab-is-i-guess-part-of-the-programming-language-that-makes-it-very-easy-to-write-codes-using-matrices-to-write-code-for-numerical-routines-to-move-data-around-to-plot-data.-and-its-sort-of-an-extremely-easy-to-learn-tool-to-use-for-implementing-a-lot-of-learning-algorithms.-2",
    "href": "slides/04_retrieval.html#matlab-is-i-guess-part-of-the-programming-language-that-makes-it-very-easy-to-write-codes-using-matrices-to-write-code-for-numerical-routines-to-move-data-around-to-plot-data.-and-its-sort-of-an-extremely-easy-to-learn-tool-to-use-for-implementing-a-lot-of-learning-algorithms.-2",
    "title": "Vectorstore Retrieval",
    "section": "‚ÄúMATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it‚Äôs sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.‚Äù",
    "text": "‚ÄúMATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it‚Äôs sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.‚Äù\nDocument 2:\n‚ÄúAnd the student said,‚ÄùOh, it was the MATLAB.‚Äù So for those of you that don‚Äôt know MATLAB yet, I hope you do learn it. It‚Äôs not hard, and we‚Äôll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don‚Äôt know it.‚Äù"
  },
  {
    "objectID": "slides/04_retrieval.html#basics-4",
    "href": "slides/04_retrieval.html#basics-4",
    "title": "Vectorstore Retrieval",
    "section": "Basics",
    "text": "Basics\n\nIt‚Äôs worth noting that vectordb as not the only kind of tool to retrieve documents.\nThe LangChain retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
  },
  {
    "objectID": "slides/04_retrieval.html#load",
    "href": "slides/04_retrieval.html#load",
    "title": "Vectorstore Retrieval",
    "section": "Load",
    "text": "Load\n\n# Load PDF\nloader = PyPDFLoader(\"../docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n\npages = loader.load()\n\nall_page_text = [p.page_content for p in pages]\n\njoined_page_text = \" \".join(all_page_text)"
  },
  {
    "objectID": "slides/04_retrieval.html#split",
    "href": "slides/04_retrieval.html#split",
    "title": "Vectorstore Retrieval",
    "section": "Split",
    "text": "Split\n\n# Split\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1500, chunk_overlap=150)\n\nsplits = text_splitter.split_text(joined_page_text)"
  },
  {
    "objectID": "slides/04_retrieval.html#retrieve-with-svm-and-tf-idf",
    "href": "slides/04_retrieval.html#retrieve-with-svm-and-tf-idf",
    "title": "Vectorstore Retrieval",
    "section": "Retrieve with SVM and TF-IDF",
    "text": "Retrieve with SVM and TF-IDF\n\nSupport vector machine (SVMs) retriever\n\n\n\n# Retrieve\nsvm_retriever = SVMRetriever.from_texts(splits, embedding)\n\n\nTF-IDF: term-frequency times inverse document-frequency retriever\n\n\n\n\ntfidf_retriever = TFIDFRetriever.from_texts(splits)"
  },
  {
    "objectID": "slides/04_retrieval.html#question-2",
    "href": "slides/04_retrieval.html#question-2",
    "title": "Vectorstore Retrieval",
    "section": "Question",
    "text": "Question"
  },
  {
    "objectID": "slides/04_retrieval.html#svm-retriever",
    "href": "slides/04_retrieval.html#svm-retriever",
    "title": "Vectorstore Retrieval",
    "section": "SVM retriever",
    "text": "SVM retriever\n\nquestion = \"What are major topics for this class?\"\n\ndocs_svm = svm_retriever.get_relevant_documents(question)\ndocs_svm[0]\n\n\nDocument(page_content=‚Äòdon't have a MATLAB license, for the purposes of this class, there's also ‚Äî [inaudible] that down [inaudible] MATLAB ‚Äî there' s also a software package called Octave you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of this class, it will work for just about . actually I, well, so yeah, just a side comment for those of you that haven't seen before I guess, once a colleague of mine at a different university, not at , actually teaches another machine l earning course. He's taught it for many years. one day, he was in his office, and an old student of his from, lik e, ten years ago came his office and he said, ‚ÄúOh, professo r, professor, thank you so much for your learning class. I learned so much from it. There's this stuff that I learned in your , and I now use every day. And it's help ed me make lots of money, and here's a of my big house.‚Äù my friend was very excited. He said, ‚ÄúW ow. That's great. I'm glad to hear this learning stuff was actually useful. So what was it that you learned? Was it regression? Was it the PCA? Was it the data ne tworks? What was it that you that was so helpful?‚Äù And the student said, ‚ÄúOh, it was the MATLAB.‚Äù for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard,‚Äô, metadata={})"
  },
  {
    "objectID": "slides/04_retrieval.html#tfidf-retriever",
    "href": "slides/04_retrieval.html#tfidf-retriever",
    "title": "Vectorstore Retrieval",
    "section": "TFIDF retriever",
    "text": "TFIDF retriever\n\nquestion = \"what did they say about matlab?\"\n\ndocs_tfidf = tfidf_retriever.get_relevant_documents(question)\n\ndocs_tfidf[0]\n\n\nDocument(page_content=‚ÄúSaxena and Min Sun here did, wh ich is given an image like this, right? This is actually a taken of the Stanford campus. You can apply that sort of cl ustering algorithm and the picture into regions. Let me actually blow that up so that you can see it more . Okay. So in the middle, you see the lines sort of groupi ng the image together, the image into [inaudible] regions. what Ashutosh and Min did was they then applied the learning algorithm to say can take this clustering and us e it to build a 3D model of the world? And so using the , they then had a lear ning algorithm try to learn what the 3D structure of the looks like so that they could come up with a 3D model that you can sort of fly , okay? Although many people used to th ink it‚Äôs not possible to take a single and build a 3D model, but using a lear ning algorithm and that sort of clustering is the first step. They were able to. ‚Äôll just show you one more example. I like this because it‚Äôs a picture of Stanford with our Stanford campus. So again, taking th e same sort of clustering algorithms, taking same sort of unsupervised learning algor ithm, you can group the pixels into different . And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture. You can sort of walk into the ceiling, look‚Äù, metadata={})"
  },
  {
    "objectID": "slides/05_question_answering.html#python",
    "href": "slides/05_question_answering.html#python",
    "title": "Question Answering",
    "section": "Python",
    "text": "Python\n\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chains import RetrievalQA\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.vectorstores import Chroma\nimport datetime\nfrom dotenv import load_dotenv, find_dotenv\nimport os\nimport openai\n# import sys\n# sys.path.append('../..')\n\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nopenai.api_key = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "slides/05_question_answering.html#vector-database-setup",
    "href": "slides/05_question_answering.html#vector-database-setup",
    "title": "Question Answering",
    "section": "Vector Database setup",
    "text": "Vector Database setup\n\npersist_directory = '../docs/chroma/'\nembedding = OpenAIEmbeddings()\nvectordb = Chroma(persist_directory=persist_directory,\n                  embedding_function=embedding)\n\n\nprint(vectordb._collection.count())\n\n\n209"
  },
  {
    "objectID": "slides/05_question_answering.html#question-and-similarity-search",
    "href": "slides/05_question_answering.html#question-and-similarity-search",
    "title": "Question Answering",
    "section": "Question and similarity search",
    "text": "Question and similarity search\n\nquestion = \"What are major topics for this class?\"\n\ndocs = vectordb.similarity_search(question, k=3)\n\nlen(docs)\n\n\n3"
  },
  {
    "objectID": "slides/05_question_answering.html#chatopenai-model",
    "href": "slides/05_question_answering.html#chatopenai-model",
    "title": "Question Answering",
    "section": "ChatOpenAI model",
    "text": "ChatOpenAI model\n\nllm_name = \"gpt-3.5-turbo\"\n\nllm = ChatOpenAI(model_name=llm_name, temperature=0)"
  },
  {
    "objectID": "slides/05_question_answering.html#retrievalqa-chain-1",
    "href": "slides/05_question_answering.html#retrievalqa-chain-1",
    "title": "Question Answering",
    "section": "RetrievalQA chain",
    "text": "RetrievalQA chain\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever()\n)"
  },
  {
    "objectID": "slides/05_question_answering.html#result",
    "href": "slides/05_question_answering.html#result",
    "title": "Question Answering",
    "section": "Result",
    "text": "Result\n\nresult = qa_chain({\"query\": question})\n\n\n\nresult[\"result\"]\n\n\n‚ÄòThe major topics for this class are machine learning and its various extensions.‚Äô"
  },
  {
    "objectID": "slides/05_question_answering.html#prompt-template",
    "href": "slides/05_question_answering.html#prompt-template",
    "title": "Question Answering",
    "section": "Prompt template",
    "text": "Prompt template\n\ntemplate = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n{context}\nQuestion: {question}\nHelpful Answer:\"\"\"\n\nQA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
  },
  {
    "objectID": "slides/05_question_answering.html#question-answer-chain",
    "href": "slides/05_question_answering.html#question-answer-chain",
    "title": "Question Answering",
    "section": "Question answer chain",
    "text": "Question answer chain\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever(),\n    return_source_documents=True,\n    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n)"
  },
  {
    "objectID": "slides/05_question_answering.html#question-and-result",
    "href": "slides/05_question_answering.html#question-and-result",
    "title": "Question Answering",
    "section": "Question and result",
    "text": "Question and result\n\nquestion = \"Is probability a class topic?\"\n\n\n\nresult = qa_chain({\"query\": question})\n\n\n\n\nresult[\"result\"]\n\n\n‚ÄòYes, probability is a class topic. Thanks for asking!‚Äô"
  },
  {
    "objectID": "slides/05_question_answering.html#source-documents",
    "href": "slides/05_question_answering.html#source-documents",
    "title": "Question Answering",
    "section": "Source documents",
    "text": "Source documents\n\nresult[\"source_documents\"][0]\n\n\nDocument(page_content=‚Äúof this class will not be very program ming intensive, although we will do some , mostly in either MATLAB or Octa ve. I‚Äôll say a bit more about that later. also assume familiarity with basic proba bility and statistics. So most undergraduate class, like Stat 116 taught here at Stanford, will be more than enough. I‚Äôm gonna all of you know what ra ndom variables are, that all of you know what expectation , what a variance or a random variable is. And in case of some of you, it‚Äôs been a while you‚Äôve seen some of this material. At some of the discussion sections, we‚Äôll actually over some of the prerequisites, sort of as a refresher course under prerequisite class. ‚Äòll say a bit more about that later as well. , I also assume familiarity with basi c linear algebra. And again, most undergraduate algebra courses are more than enough. So if you‚Äôve taken courses like Math 51, , Math 113 or CS205 at Stanford, that would be more than enough. Basically, I‚Äôm assume that all of you know what matrix es and vectors are, that you know how to matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. If you know what an eigenvect or of a matrix is, that‚Äôd be even better. if you don‚Äôt quite know or if you‚Äôre not qu ite sure, that‚Äôs fine, too. We‚Äôll go over it in review sections.‚Äù, metadata={‚Äôsource‚Äô: ‚Äò../docs/cs229_lectures/MachineLearning-Lecture01.pdf‚Äô, ‚Äòpage‚Äô: 4})"
  },
  {
    "objectID": "slides/05_question_answering.html#map-reduce",
    "href": "slides/05_question_answering.html#map-reduce",
    "title": "Question Answering",
    "section": "Map Reduce",
    "text": "Map Reduce\n\nqa_chain_mr = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever(),\n    chain_type=\"map_reduce\"\n)"
  },
  {
    "objectID": "slides/05_question_answering.html#result-1",
    "href": "slides/05_question_answering.html#result-1",
    "title": "Question Answering",
    "section": "Result",
    "text": "Result\n\nresult = qa_chain_mr({\"query\": question})\n\n\n\nresult[\"result\"]\n\n\n‚ÄòThere is no mention of probability as a class topic in the provided text.‚Äô"
  },
  {
    "objectID": "slides/05_question_answering.html#basics",
    "href": "slides/05_question_answering.html#basics",
    "title": "Question Answering",
    "section": "Basics",
    "text": "Basics\n\nIf you wish to experiment on the LangChain plus platform:\n\nGo to langchain plus platform and sign up\nCreate an API key from your account‚Äôs settings\nUse this API key in the code below\n\nuncomment the code"
  },
  {
    "objectID": "slides/05_question_answering.html#code",
    "href": "slides/05_question_answering.html#code",
    "title": "Question Answering",
    "section": "Code",
    "text": "Code\n\n# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.langchain.plus\"\n# os.environ[\"LANGCHAIN_API_KEY\"] = \"...\"  # replace dots with your api key\n\n\n# qa_chain_mr = RetrievalQA.from_chain_type(\n#     llm,\n#     retriever=vectordb.as_retriever(),\n#     chain_type=\"map_reduce\"\n# )\n# result = qa_chain_mr({\"query\": question})\n# result[\"result\"]\n\n\n# qa_chain_mr = RetrievalQA.from_chain_type(\n#     llm,\n#     retriever=vectordb.as_retriever(),\n#     chain_type=\"refine\"\n# )\n# result = qa_chain_mr({\"query\": question})\n# result[\"result\"]"
  },
  {
    "objectID": "slides/05_question_answering.html#conversational-history",
    "href": "slides/05_question_answering.html#conversational-history",
    "title": "Question Answering",
    "section": "Conversational history",
    "text": "Conversational history\n\nQA fails to preserve conversational history.\n\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever()\n)\n\n\n\nquestion = \"Is probability a class topic?\"\nresult = qa_chain({\"query\": question})\nresult[\"result\"]\n\n\n‚ÄòYes, probability is a topic that will be covered in this class. The instructor assumes familiarity with basic probability and statistics.‚Äô"
  },
  {
    "objectID": "slides/05_question_answering.html#limitations",
    "href": "slides/05_question_answering.html#limitations",
    "title": "Question Answering",
    "section": "Limitations",
    "text": "Limitations\n\nNote, The LLM response varies.\nSome responses do include a reference to probability which might be gleaned from referenced documents.\nThe point is simply that the model does not have access to past questions or answers, this will be covered in the next tutorial (Tutorial 6)."
  },
  {
    "objectID": "slides/06_chat.html#python",
    "href": "slides/06_chat.html#python",
    "title": "Chat",
    "section": "Python",
    "text": "Python\n\nimport param\nimport panel as pn\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.chains import RetrievalQA,  ConversationalRetrievalChain\nfrom langchain.document_loaders import TextLoader\nfrom langchain.vectorstores import DocArrayInMemorySearch\nfrom langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\nfrom langchain.chains import ConversationalRetrievalChain\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.chains import RetrievalQA\nfrom langchain.prompts import PromptTemplate\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.vectorstores import Chroma\nimport datetime\nfrom dotenv import load_dotenv, find_dotenv\nimport panel as pn  # GUI\nimport os\nimport openai\n\n# import sys\n# sys.path.append('../..')\n\npn.extension()\n\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nopenai.api_key = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "slides/06_chat.html#langchain-plus-platform",
    "href": "slides/06_chat.html#langchain-plus-platform",
    "title": "Chat",
    "section": "LangChain plus platform",
    "text": "LangChain plus platform\n\nIf you wish to experiment on LangChain plus platform:\n\nGo to langchain plus platform and sign up\nCreate an api key from your account‚Äôs settings\nUse this api key in the code below\n\n\n\n\n# import os\n# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.langchain.plus\"\n# os.environ[\"LANGCHAIN_API_KEY\"] = \"...\""
  },
  {
    "objectID": "slides/06_chat.html#vector-database",
    "href": "slides/06_chat.html#vector-database",
    "title": "Chat",
    "section": "Vector Database",
    "text": "Vector Database\n\npersist_directory = '../docs/chroma/'\nembedding = OpenAIEmbeddings()\nvectordb = Chroma(persist_directory=persist_directory,\n                  embedding_function=embedding)"
  },
  {
    "objectID": "slides/06_chat.html#question-and-similarity-search",
    "href": "slides/06_chat.html#question-and-similarity-search",
    "title": "Chat",
    "section": "Question and similarity search",
    "text": "Question and similarity search\n\nquestion = \"What are major topics for this class?\"\ndocs = vectordb.similarity_search(question, k=3)\nlen(docs)\n\n\n3"
  },
  {
    "objectID": "slides/06_chat.html#openai-model",
    "href": "slides/06_chat.html#openai-model",
    "title": "Chat",
    "section": "OpenAI model",
    "text": "OpenAI model\n\nllm_name = \"gpt-3.5-turbo\"\n\nllm = ChatOpenAI(model_name=llm_name, temperature=0)\n\n\nllm.predict(\"Hello world!\")\n\n\n‚ÄòHello! How can I assist you today?‚Äô"
  },
  {
    "objectID": "slides/06_chat.html#prompt-template",
    "href": "slides/06_chat.html#prompt-template",
    "title": "Chat",
    "section": "Prompt template",
    "text": "Prompt template\n\ntemplate = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n{context}\nQuestion: {question}\nHelpful Answer:\"\"\"\nQA_CHAIN_PROMPT = PromptTemplate(\n    input_variables=[\"context\", \"question\"], template=template,)"
  },
  {
    "objectID": "slides/06_chat.html#run-chain",
    "href": "slides/06_chat.html#run-chain",
    "title": "Chat",
    "section": "Run chain",
    "text": "Run chain\n\nquestion = \"Is probability a class topic?\"\n\nqa_chain = RetrievalQA.from_chain_type(llm,\n                                       retriever=vectordb.as_retriever(),\n                                       return_source_documents=True,\n                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n\n\nresult = qa_chain({\"query\": question})\n\nresult[\"result\"]\n\n\n‚ÄòYes, probability is a class topic. Thanks for asking!‚Äô"
  },
  {
    "objectID": "slides/06_chat.html#conversationbuffermemory",
    "href": "slides/06_chat.html#conversationbuffermemory",
    "title": "Chat",
    "section": "ConversationBufferMemory",
    "text": "ConversationBufferMemory\n\nmemory = ConversationBufferMemory(\n    memory_key=\"chat_history\",\n    return_messages=True\n)"
  },
  {
    "objectID": "slides/06_chat.html#conversationalretrievalchain",
    "href": "slides/06_chat.html#conversationalretrievalchain",
    "title": "Chat",
    "section": "ConversationalRetrievalChain",
    "text": "ConversationalRetrievalChain\n\nretriever = vectordb.as_retriever()\n\n\n\nqa = ConversationalRetrievalChain.from_llm(\n    llm,\n    retriever=retriever,\n    memory=memory\n)"
  },
  {
    "objectID": "slides/06_chat.html#question-and-result",
    "href": "slides/06_chat.html#question-and-result",
    "title": "Chat",
    "section": "Question and result",
    "text": "Question and result\n\nquestion = \"Is probability a class topic?\"\nresult = qa({\"question\": question})\n\n\n\nresult['answer']\n\n\n‚ÄòYes, probability is a topic that will be covered in this class. The instructor assumes familiarity with basic probability and statistics.‚Äô"
  },
  {
    "objectID": "slides/06_chat.html#second-question",
    "href": "slides/06_chat.html#second-question",
    "title": "Chat",
    "section": "Second question",
    "text": "Second question\n\nquestion = \"why are those prerequesites needed?\"\nresult = qa({\"question\": question})\n\n\nresult['answer']\n\n\n‚ÄòFamiliarity with basic probability and statistics is needed as prerequisites because the course will involve concepts and techniques from these fields. The instructor assumes that students already know what random variables, expectation, variance, and probability distributions are. This knowledge is necessary to understand and apply the machine learning algorithms and models that will be taught in the course. Additionally, some of the material covered in the course may require a refresher on probability and statistics, so the discussion sections will provide an opportunity to review these concepts.‚Äô"
  },
  {
    "objectID": "slides/06_chat.html#helper-function-load_db",
    "href": "slides/06_chat.html#helper-function-load_db",
    "title": "Chat",
    "section": "Helper function: load_db",
    "text": "Helper function: load_db\n\ndef load_db(file, chain_type, k):\n    # load documents\n    loader = PyPDFLoader(file)\n    documents = loader.load()\n    # split documents\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000, chunk_overlap=150)\n    docs = text_splitter.split_documents(documents)\n    # define embedding\n    embeddings = OpenAIEmbeddings()\n    # create vector database from data\n    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n    # define retriever\n    retriever = db.as_retriever(\n        search_type=\"similarity\", search_kwargs={\"k\": k})\n    # create a chatbot chain. Memory is managed externally.\n    qa = ConversationalRetrievalChain.from_llm(\n        llm=ChatOpenAI(model_name=llm_name, temperature=0),\n        chain_type=chain_type,\n        retriever=retriever,\n        return_source_documents=True,\n        return_generated_question=True,\n    )\n    return qa"
  },
  {
    "objectID": "slides/06_chat.html#helper-function-cbfs",
    "href": "slides/06_chat.html#helper-function-cbfs",
    "title": "Chat",
    "section": "Helper function: cbfs",
    "text": "Helper function: cbfs\n\nclass cbfs(param.Parameterized):\n    chat_history = param.List([])\n    answer = param.String(\"\")\n    db_query = param.String(\"\")\n    db_response = param.List([])\n\n    def __init__(self,  **params):\n        super(cbfs, self).__init__(**params)\n        self.panels = []\n        self.loaded_file = \"../docs/cs229_lectures/MachineLearning-Lecture01.pdf\"\n        self.qa = load_db(self.loaded_file, \"stuff\", 4)\n\n    def call_load_db(self, count):\n        if count == 0 or file_input.value is None:  # init or no file specified :\n            return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n        else:\n            file_input.save(\"temp.pdf\")  # local copy\n            self.loaded_file = file_input.filename\n            button_load.button_style = \"outline\"\n            self.qa = load_db(\"temp.pdf\", \"stuff\", 4)\n            button_load.button_style = \"solid\"\n        self.clr_history()\n        return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n\n    def convchain(self, query):\n        if not query:\n            return pn.WidgetBox(pn.Row('User:', pn.pane.Markdown(\"\", width=600)), scroll=True)\n        result = self.qa(\n            {\"question\": query, \"chat_history\": self.chat_history})\n        self.chat_history.extend([(query, result[\"answer\"])])\n        self.db_query = result[\"generated_question\"]\n        self.db_response = result[\"source_documents\"]\n        self.answer = result['answer']\n        self.panels.extend([\n            pn.Row('User:', pn.pane.Markdown(query, width=600)),\n            pn.Row('ChatBot:', pn.pane.Markdown(self.answer,\n                   width=600, style={'background-color': '#F6F6F6'}))\n        ])\n        inp.value = ''  # clears loading indicator when cleared\n        return pn.WidgetBox(*self.panels, scroll=True)\n\n    @param.depends('db_query ', )\n    def get_lquest(self):\n        if not self.db_query:\n            return pn.Column(\n                pn.Row(pn.pane.Markdown(f\"Last question to DB:\",\n                       styles={'background-color': '#F6F6F6'})),\n                pn.Row(pn.pane.Str(\"no DB accesses so far\"))\n            )\n        return pn.Column(\n            pn.Row(pn.pane.Markdown(f\"DB query:\", styles={\n                   'background-color': '#F6F6F6'})),\n            pn.pane.Str(self.db_query)\n        )\n\n    @param.depends('db_response', )\n    def get_sources(self):\n        if not self.db_response:\n            return\n        rlist = [pn.Row(pn.pane.Markdown(f\"Result of DB lookup:\",\n                        styles={'background-color': '#F6F6F6'}))]\n        for doc in self.db_response:\n            rlist.append(pn.Row(pn.pane.Str(doc)))\n        return pn.WidgetBox(*rlist, width=600, scroll=True)\n\n    @param.depends('convchain', 'clr_history')\n    def get_chats(self):\n        if not self.chat_history:\n            return pn.WidgetBox(pn.Row(pn.pane.Str(\"No History Yet\")), width=600, scroll=True)\n        rlist = [pn.Row(pn.pane.Markdown(\n            f\"Current Chat History variable\", styles={'background-color': '#F6F6F6'}))]\n        for exchange in self.chat_history:\n            rlist.append(pn.Row(pn.pane.Str(exchange)))\n        return pn.WidgetBox(*rlist, width=600, scroll=True)\n\n    def clr_history(self, count=0):\n        self.chat_history = []\n        return"
  },
  {
    "objectID": "slides/06_chat.html#create-chatbot",
    "href": "slides/06_chat.html#create-chatbot",
    "title": "Chat",
    "section": "Create Chatbot",
    "text": "Create Chatbot\n\ncb = cbfs()\n\nfile_input = pn.widgets.FileInput(accept='.pdf')\nbutton_load = pn.widgets.Button(name=\"Load DB\", button_type='primary')\nbutton_clearhistory = pn.widgets.Button(\n    name=\"Clear History\", button_type='warning')\nbutton_clearhistory.on_click(cb.clr_history)\ninp = pn.widgets.TextInput(placeholder='Enter text here‚Ä¶')\n\nbound_button_load = pn.bind(cb.call_load_db, button_load.param.clicks)\nconversation = pn.bind(cb.convchain, inp)\n\njpg_pane = pn.pane.Image('../imges/convchain.png')\n\ntab1 = pn.Column(\n    pn.Row(inp),\n    pn.layout.Divider(),\n    pn.panel(conversation,  loading_indicator=True, height=300),\n    pn.layout.Divider(),\n)\ntab2 = pn.Column(\n    pn.panel(cb.get_lquest),\n    pn.layout.Divider(),\n    pn.panel(cb.get_sources),\n)\ntab3 = pn.Column(\n    pn.panel(cb.get_chats),\n    pn.layout.Divider(),\n)\ntab4 = pn.Column(\n    pn.Row(file_input, button_load, bound_button_load),\n    pn.Row(button_clearhistory, pn.pane.Markdown(\n        \"Clears chat history. Can use to start a new topic\")),\n    pn.layout.Divider(),\n    pn.Row(jpg_pane.clone(width=400))\n)\ndashboard = pn.Column(\n    pn.Row(pn.pane.Markdown('# ChatWithYourData_Bot')),\n    pn.Tabs(('Conversation', tab1), ('Database', tab2),\n            ('Chat History', tab3), ('Configure', tab4))\n)\ndashboard"
  },
  {
    "objectID": "slides/06_chat.html#adapt-the-code",
    "href": "slides/06_chat.html#adapt-the-code",
    "title": "Chat",
    "section": "Adapt the code",
    "text": "Adapt the code\n\nFeel free to copy this code and modify it to add your own features.\nYou can try alternate memory and retriever models by changing the configuration in load_db function and the convchain method. Panel and Param have many useful features and widgets you can use to extend the GUI."
  },
  {
    "objectID": "slides/06_chat.html#panel-user-interface",
    "href": "slides/06_chat.html#panel-user-interface",
    "title": "Chat",
    "section": "Panel user interface",
    "text": "Panel user interface"
  },
  {
    "objectID": "slides/06_chat.html#panel-user-interface-1",
    "href": "slides/06_chat.html#panel-user-interface-1",
    "title": "Chat",
    "section": "Panel user interface",
    "text": "Panel user interface"
  },
  {
    "objectID": "slides/06_chat.html#panel-user-interface-2",
    "href": "slides/06_chat.html#panel-user-interface-2",
    "title": "Chat",
    "section": "Panel user interface",
    "text": "Panel user interface"
  },
  {
    "objectID": "slides/06_chat.html#panel-user-interface-3",
    "href": "slides/06_chat.html#panel-user-interface-3",
    "title": "Chat",
    "section": "Panel user interface",
    "text": "Panel user interface"
  },
  {
    "objectID": "slides/06_chat.html#panel-user-interface-4",
    "href": "slides/06_chat.html#panel-user-interface-4",
    "title": "Chat",
    "section": "Panel user interface",
    "text": "Panel user interface"
  },
  {
    "objectID": "slides/06_chat.html#question",
    "href": "slides/06_chat.html#question",
    "title": "Chat",
    "section": "Question",
    "text": "Question"
  },
  {
    "objectID": "slides/06_chat.html#databse",
    "href": "slides/06_chat.html#databse",
    "title": "Chat",
    "section": "Databse",
    "text": "Databse"
  },
  {
    "objectID": "slides/06_chat.html#chat-history",
    "href": "slides/06_chat.html#chat-history",
    "title": "Chat",
    "section": "Chat history",
    "text": "Chat history"
  },
  {
    "objectID": "slides/06_chat.html#configurations",
    "href": "slides/06_chat.html#configurations",
    "title": "Chat",
    "section": "Configurations",
    "text": "Configurations"
  },
  {
    "objectID": "slides/01_document_loading.html#save-data",
    "href": "slides/01_document_loading.html#save-data",
    "title": "Document Loading",
    "section": "Save data",
    "text": "Save data\n\ndf = pd.DataFrame(docs, columns=['Text', 'Metadata'])\n\n\n\ndf.to_csv('../docs/youtube/codereport.csv')"
  },
  {
    "objectID": "slides/01_document_loading.html#save-data-1",
    "href": "slides/01_document_loading.html#save-data-1",
    "title": "Document Loading",
    "section": "Save data",
    "text": "Save data\n\ndf = pd.DataFrame(docs, columns=['Text', 'Metadata'])\n\n\n\ndf.to_csv('../docs/url/study-design.csv')"
  },
  {
    "objectID": "slides/04_retrieval.html#example",
    "href": "slides/04_retrieval.html#example",
    "title": "Vectorstore Retrieval",
    "section": "Example",
    "text": "Example\n\ntexts = [\n    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n]\n\n\n\nsmalldb = Chroma.from_texts(texts, embedding=embedding)\n\n\n\n\nquestion = \"Tell me about all-white mushrooms with large fruiting bodies\""
  },
  {
    "objectID": "slides/05_question_answering.html#conversational-history-1",
    "href": "slides/05_question_answering.html#conversational-history-1",
    "title": "Question Answering",
    "section": "Conversational history",
    "text": "Conversational history\n\nquestion = \"why are those prerequesites needed?\"\nresult = qa_chain({\"query\": question})\nresult[\"result\"]\n\n\n‚ÄòThe prerequisites are needed because they provide the foundational knowledge and skills necessary to understand and apply machine learning algorithms. knowledge of computer science and computer skills is important because machine learning algorithms often involve programming and working with data. Understanding concepts like big-O notation helps in analyzing the efficiency and scalability of algorithms.with probability and statistics is necessary because machine learning involves working with data and making predictions based on statistical models. Understanding concepts like random variables, expectation, and variance is crucial in understanding and evaluating machine learning algorithms.knowledge of linear algebra is important because many machine learning algorithms involve manipulating matrices and vectors. Understanding concepts like matrix multiplication, matrix inverse, and eigenvectors is essential in understanding and implementing these algorithms., these prerequisites provide the necessary background knowledge and skills to effectively learn and apply machine learning algorithms.‚Äô"
  },
  {
    "objectID": "slides/05_tools_routing.html#setup",
    "href": "slides/05_tools_routing.html#setup",
    "title": "Tools and Routing",
    "section": "Setup",
    "text": "Setup\n\nimport os\nimport openai\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) \nopenai.api_key = os.environ['OPENAI_API_KEY']\n\n\nfrom langchain.agents import tool\n\nfrom pydantic import BaseModel, Field\n\nimport requests\nfrom pydantic import BaseModel, Field\nimport datetime\n\nfrom langchain.tools.render import format_tool_to_openai_function\n\nimport wikipedia\n\nfrom langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n\nfrom langchain.utilities.openapi import OpenAPISpec\n\nfrom langchain.chat_models import ChatOpenAI\n\nfrom langchain.prompts import ChatPromptTemplate\n\nfrom langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n\nfrom langchain.schema.agent import AgentFinish"
  },
  {
    "objectID": "slides/05_tools_routing.html#create-tool",
    "href": "slides/05_tools_routing.html#create-tool",
    "title": "Tools and Routing",
    "section": "Create tool",
    "text": "Create tool\n\n@tool\ndef search(query: str) -&gt; str:\n    \"\"\"Search for weather online\"\"\"\n    return \"42f\"\n\n\n\nsearch.name\n\n\n‚Äòsearch‚Äô\n\n\n\n\nsearch.description\n\n\n‚Äòsearch(query: str) -&gt; str - Search for weather online‚Äô . . .\n\n\nsearch.args\n\n\n{‚Äòquery‚Äô: {‚Äòtitle‚Äô: ‚ÄòQuery‚Äô, ‚Äòtype‚Äô: ‚Äòstring‚Äô}}"
  },
  {
    "objectID": "slides/05_tools_routing.html#add-a-description",
    "href": "slides/05_tools_routing.html#add-a-description",
    "title": "Tools and Routing",
    "section": "Add a description",
    "text": "Add a description\n\nclass SearchInput(BaseModel):\n    query: str = Field(description=\"Thing to search for\")\n\n\n\n@tool(args_schema=SearchInput)\ndef search(query: str) -&gt; str:\n    \"\"\"Search for the weather online.\"\"\"\n    return \"42f\"\n\n\n\n\nsearch.args\n\n\n{‚Äòquery‚Äô: {‚Äòtitle‚Äô: ‚ÄòQuery‚Äô, ‚Äòdescription‚Äô: ‚ÄòThing to search for‚Äô, ‚Äòtype‚Äô: ‚Äòstring‚Äô}}"
  },
  {
    "objectID": "slides/05_tools_routing.html#call-function",
    "href": "slides/05_tools_routing.html#call-function",
    "title": "Tools and Routing",
    "section": "Call function",
    "text": "Call function\n\nsearch.run(\"sf\")\n\n\n‚Äò42f‚Äô"
  },
  {
    "objectID": "slides/05_tools_routing.html#create-tool-1",
    "href": "slides/05_tools_routing.html#create-tool-1",
    "title": "Tools and Routing",
    "section": "Create tool",
    "text": "Create tool\n\n# Define the input schema\nclass OpenMeteoInput(BaseModel):\n    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n\n@tool(args_schema=OpenMeteoInput)\ndef get_current_temperature(latitude: float, longitude: float) -&gt; dict:\n    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n    \n    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n    \n    # Parameters for the request\n    params = {\n        'latitude': latitude,\n        'longitude': longitude,\n        'hourly': 'temperature_2m',\n        'forecast_days': 1,\n    }\n\n    # Make the request\n    response = requests.get(BASE_URL, params=params)\n    \n    if response.status_code == 200:\n        results = response.json()\n    else:\n        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n\n    current_utc_time = datetime.datetime.utcnow()\n    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n    temperature_list = results['hourly']['temperature_2m']\n    \n    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n    current_temperature = temperature_list[closest_time_index]\n    \n    return f'The current temperature is {current_temperature}¬∞C'"
  },
  {
    "objectID": "slides/05_tools_routing.html#inspect-function",
    "href": "slides/05_tools_routing.html#inspect-function",
    "title": "Tools and Routing",
    "section": "Inspect function",
    "text": "Inspect function\n\nget_current_temperature.name\n\n\n‚Äòget_current_temperature‚Äô\n\n\n\nget_current_temperature.description\n\n\n‚Äòget_current_temperature‚Äô\n\n\n\n\nget_current_temperature.args\n\n\n{‚Äòlatitude‚Äô: {‚Äòtitle‚Äô: ‚ÄòLatitude‚Äô, ‚Äòdescription‚Äô: ‚ÄòLatitude of the location to fetch weather data for‚Äô, ‚Äòtype‚Äô: ‚Äònumber‚Äô}, ‚Äòlongitude‚Äô: {‚Äòtitle‚Äô: ‚ÄòLongitude‚Äô, ‚Äòdescription‚Äô: ‚ÄòLongitude of the location to fetch weather data for‚Äô, ‚Äòtype‚Äô: ‚Äònumber‚Äô}}"
  },
  {
    "objectID": "slides/05_tools_routing.html#convert-this-tool-into-openai-function",
    "href": "slides/05_tools_routing.html#convert-this-tool-into-openai-function",
    "title": "Tools and Routing",
    "section": "Convert this tool into OpenAI function",
    "text": "Convert this tool into OpenAI function\n\nformat_tool_to_openai_function(get_current_temperature)\n\n\n{‚Äòname‚Äô: ‚Äòget_current_temperature‚Äô, ‚Äòdescription‚Äô: ‚Äòget_current_temperature(latitude: float, longitude: float) -&gt; dict - Fetch current temperature for given coordinates.‚Äô, ‚Äòparameters‚Äô: {‚Äòtitle‚Äô: ‚ÄòOpenMeteoInput‚Äô, ‚Äòtype‚Äô: ‚Äòobject‚Äô, ‚Äòproperties‚Äô: {‚Äòlatitude‚Äô: {‚Äòtitle‚Äô: ‚ÄòLatitude‚Äô, ‚Äòdescription‚Äô: ‚ÄòLatitude of the location to fetch weather data for‚Äô, ‚Äòtype‚Äô: ‚Äònumber‚Äô}, ‚Äòlongitude‚Äô: {‚Äòtitle‚Äô: ‚ÄòLongitude‚Äô, ‚Äòdescription‚Äô: ‚ÄòLongitude of the location to fetch weather data for‚Äô, ‚Äòtype‚Äô: ‚Äònumber‚Äô}}, ‚Äòrequired‚Äô: [‚Äòlatitude‚Äô, ‚Äòlongitude‚Äô]}}"
  },
  {
    "objectID": "slides/05_tools_routing.html#use-tool",
    "href": "slides/05_tools_routing.html#use-tool",
    "title": "Tools and Routing",
    "section": "Use tool",
    "text": "Use tool\n\nget_current_temperature({\"latitude\": 48.741400, \"longitude\": 9.1006302})\n\n\n‚ÄòThe current temperature is 8.2¬∞C‚Äô"
  },
  {
    "objectID": "slides/05_tools_routing.html#create-tool-2",
    "href": "slides/05_tools_routing.html#create-tool-2",
    "title": "Tools and Routing",
    "section": "Create tool",
    "text": "Create tool\n\n@tool\ndef search_wikipedia(query: str) -&gt; str:\n    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n    page_titles = wikipedia.search(query)\n    summaries = []\n    for page_title in page_titles[: 3]:\n        try:\n            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n        except (\n            self.wiki_client.exceptions.PageError,\n            self.wiki_client.exceptions.DisambiguationError,\n        ):\n            pass\n    if not summaries:\n        return \"No good Wikipedia Search Result was found\"\n    return \"\\n\\n\".join(summaries)"
  },
  {
    "objectID": "slides/05_tools_routing.html#inspect-function-1",
    "href": "slides/05_tools_routing.html#inspect-function-1",
    "title": "Tools and Routing",
    "section": "Inspect function",
    "text": "Inspect function\n\nsearch_wikipedia.name\n\n\n‚Äòsearch_wikipedia‚Äô\n\n\n\nsearch_wikipedia.description\n\n\n{‚Äòname‚Äô: ‚Äòsearch_wikipedia‚Äô, ‚Äòdescription‚Äô: ‚Äòsearch_wikipedia(query: str) -&gt; str - Run Wikipedia search and get page summaries.‚Äô, ‚Äòparameters‚Äô: {‚Äòtitle‚Äô: ‚Äòsearch_wikipediaSchemaSchema‚Äô, ‚Äòtype‚Äô: ‚Äòobject‚Äô, ‚Äòproperties‚Äô: {‚Äòquery‚Äô: {‚Äòtitle‚Äô: ‚ÄòQuery‚Äô, ‚Äòtype‚Äô: ‚Äòstring‚Äô}}, ‚Äòrequired‚Äô: [‚Äòquery‚Äô]}}\n\n\n\n\nformat_tool_to_openai_function(search_wikipedia)\n\n\n{‚Äòname‚Äô: ‚Äòsearch_wikipedia‚Äô, ‚Äòdescription‚Äô: ‚Äòsearch_wikipedia(query: str) -&gt; str - Run Wikipedia search and get page summaries.‚Äô, ‚Äòparameters‚Äô: {‚Äòtitle‚Äô: ‚Äòsearch_wikipediaSchemaSchema‚Äô, ‚Äòtype‚Äô: ‚Äòobject‚Äô, ‚Äòproperties‚Äô: {‚Äòquery‚Äô: {‚Äòtitle‚Äô: ‚ÄòQuery‚Äô, ‚Äòtype‚Äô: ‚Äòstring‚Äô}}, ‚Äòrequired‚Äô: [‚Äòquery‚Äô]}}"
  },
  {
    "objectID": "slides/05_tools_routing.html#use-tool-1",
    "href": "slides/05_tools_routing.html#use-tool-1",
    "title": "Tools and Routing",
    "section": "Use tool",
    "text": "Use tool\n\nsearch_wikipedia({\"query\": \"Hochschule der Medien Stuttgart\"})\n\n\n‚ÄòPage: Stuttgart Media University: The Stuttgart Media University or Media University (German: Hochschule der Medien) is a state university of media studies in Stuttgart, Germany, offering nearly 30 accredited bachelor's and master's degree programs within three faculties.: Stuttgart: Stuttgart (German: [Àà Ét ät…°a Åt] ; Swabian: Schduagert [Àà íÃädÃ•uaÃØ…°Ãä…õ ïdÃ•]; names in other languages) is the capital and largest city of the German state of Baden-W√ºrttemberg. It is located on the Neckar river in a fertile valley known as the Stuttgarter Kessel (Stuttgart Cauldron) and lies an hour from the Swabian Jura and the Black Forest. Stuttgart has a population of 635,911, making it the sixth largest city in Germany, while over 2.8 million people live in the city's administrative region and nearly 5.5 million people in its metropolitan area, making it the fourth largest metropolitan area in Germany. The city and metropolitan area are consistently ranked among the top 20 European metropolitan areas by GDP; Mercer listed Stuttgart as 21st on its 2015 list of cities by quality of living; innovation agency 2thinknow ranked the city 24th globally out of 442 cities in its Innovation Cities Index; and the Globalization and World Cities Research Network ranked the city as a Beta-status global city in their 2020 survey. Stuttgart was one of the host cities for the official tournaments of the 1974 and 2006 FIFA World Cups.is unusual in the scheme of German cities. It is spread across a variety of hills (some of them covered in vineyards), valleys (especially around the Neckar river and the Stuttgart basin) and parks. The city is known as the ‚Äúcradle of the automobile‚Äù. As such, it is home to famous automobile museums like the Mercedes-Benz Museum and Porsche Museum, as well as numerous auto-enthusiast magazines, which contributes to Stuttgart's status as Germany's ‚ÄúAutohauptstadt‚Äù (‚Äúcar capital city‚Äù). The city's tourism slogan is ‚ÄúStuttgart offers more‚Äù. Under current plans to improve transport links to the international infrastructure (as part of the Stuttgart 21 project), Stuttgart unveiled a new city logo and slogan in March 2008, describing itself as ‚ÄúDas neue Herz Europas‚Äù (‚ÄúThe new Heart of Europe‚Äù). For business, it describes itself as ‚ÄúWhere business meets the future‚Äù. In July 2010, the city unveiled a new logo, designed to entice more business people to stay in the city and enjoy breaks in the area.Since the seventh millennium BC, the Stuttgart area has been an important agricultural area and has been host to a number of cultures seeking to utilize the rich soil of the Neckar valley. The Roman Empire conquered the area in AD 83 and built a massive castrum near Bad Cannstatt, making it the most important regional centre for several centuries. Stuttgart's roots were truly laid in the tenth century with its founding by Liudolf, Duke of Swabia, as a stud farm for his warhorses. Initially overshadowed by nearby Bad Cannstatt, the town grew steadily and was granted a charter in 1320. The fortunes of Stuttgart turned with those of the House of W√ºrttemberg, and they made it the capital of their county, duchy, and kingdom from the 15th century to 1918. Stuttgart prospered despite setbacks in the Thirty Years' War and devastating air raids by the Allies on the city and its automobile production during World War II. However, by 1952, the city had bounced back and became the major cultural, economic, industrial, financial, tourism and publishing centre it is today.Stuttgart is known for its strong high-tech industry, especially in the automotive sector. It has the highest general standard of prosperity of any German city. In addition to many medium-sized companies, several major corporations are headquartered in Stuttgart, including Porsche, Bosch, and Mercedes-Benz Group. Stuttgart is an important financial center; the Stuttgart Stock Exchange is the second largest in Germany (after Frankfurt), and the Landesbank Baden-W√ºrttemberg (LBBW) is Germany's largest Landesbank. Stuttgart is also a major transport junction; it is among the most congested conurbations of Europe, and its airport is the sixth-busiest in Germany (2019). Stuttgart is a city with a high number of immigrants; according to Dorling Kindersley's Eyewitness Travel Guide to Germany, ‚ÄúIn the city of Stuttgart, every third inhabitant is a foreigner.‚Äù 40% of Stuttgart's residents, and 64% of the population below the age of five, are of immigrant background.: Menschenliebe: Menschenliebe is an independent German feature film directed by Alexander Tuschinski. It had its premiere in Stuttgart, Germany in December 2010. It was screened and received numerous awards at international film-festivals, was additionally shown in various cinemas and screening events in Germany, and was officially released online in June 2013. It is the first instalment of Tuschinski's informal Trilogy of Rebellion - three very different feature films connected by the same thoughts, ideas and main characters, although each tells an independent story: Menschenliebe, Timeless and an upcoming project called Revolution!. Additionally, the film Break-Up refers to some events of Menschenliebe.‚Äô"
  },
  {
    "objectID": "slides/05_tools_routing.html#include-tools-in-function",
    "href": "slides/05_tools_routing.html#include-tools-in-function",
    "title": "Tools and Routing",
    "section": "Include tools in function",
    "text": "Include tools in function\n\nfunctions = [\n    format_tool_to_openai_function(f) for f in [\n        search_wikipedia, get_current_temperature\n    ]\n]\n\nmodel = ChatOpenAI(temperature=0).bind(functions=functions)"
  },
  {
    "objectID": "slides/05_tools_routing.html#invoke-functions",
    "href": "slides/05_tools_routing.html#invoke-functions",
    "title": "Tools and Routing",
    "section": "Invoke functions",
    "text": "Invoke functions\n\nmodel.invoke(\"what is the weather in stuttgart right now\")\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚Äòget_current_temperature‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúlatitude‚Äù: 48.7758,‚Äúlongitude‚Äù: 9.1829}‚Äô}})\n\n\n\nmodel.invoke(\"what is langchain\")\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚Äòsearch_wikipedia‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúquery‚Äù: ‚Äúlangchain‚Äù}‚Äô}})"
  },
  {
    "objectID": "slides/05_tools_routing.html#create-prompt-and-chain",
    "href": "slides/05_tools_routing.html#create-prompt-and-chain",
    "title": "Tools and Routing",
    "section": "Create prompt and chain",
    "text": "Create prompt and chain\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are helpful but sassy assistant\"),\n    (\"user\", \"{input}\"),\n])\n\nchain = prompt | model"
  },
  {
    "objectID": "slides/05_tools_routing.html#invoke-chain",
    "href": "slides/05_tools_routing.html#invoke-chain",
    "title": "Tools and Routing",
    "section": "Invoke chain",
    "text": "Invoke chain\n\nchain.invoke({\"input\": \"what is the weather in stuttgart right now\"})\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚Äòget_current_temperature‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúlatitude‚Äù: 48.7758,‚Äúlongitude‚Äù: 9.1829}‚Äô}})"
  },
  {
    "objectID": "slides/05_tools_routing.html#use-output-parser",
    "href": "slides/05_tools_routing.html#use-output-parser",
    "title": "Tools and Routing",
    "section": "Use output parser",
    "text": "Use output parser\n\nchain = prompt | model | OpenAIFunctionsAgentOutputParser()\n\n\nresult = chain.invoke({\"input\": \"what is the weather in stuttgart right now\"})\n\n\ntype(result)\n\n\nlangchain.schema.agent.AgentActionMessageLog"
  },
  {
    "objectID": "slides/05_tools_routing.html#inspect-result",
    "href": "slides/05_tools_routing.html#inspect-result",
    "title": "Tools and Routing",
    "section": "Inspect result",
    "text": "Inspect result\n\nresult.tool\n\n\n‚Äòget_current_temperature‚Äô\n\n\n\nresult.tool_input\n\n\n{‚Äòlatitude‚Äô: 48.7758, ‚Äòlongitude‚Äô: 9.1829}\n\n\n\n\nget_current_temperature(result.tool_input)\n\n\n‚ÄòThe current temperature is 10.1¬∞C‚Äô"
  },
  {
    "objectID": "slides/05_tools_routing.html#try-a-new-input",
    "href": "slides/05_tools_routing.html#try-a-new-input",
    "title": "Tools and Routing",
    "section": "Try a new input",
    "text": "Try a new input\n\nresult = chain.invoke({\"input\": \"Hi! How are you?\"})\n\n\ntype(result)\n\n\nlangchain.schema.agent.AgentFinish\n\n\n\nresult.return_values\n\n\n{‚Äòoutput‚Äô: ‚ÄúHello! I‚Äôm an AI assistant, so I don‚Äôt have feelings, but I‚Äôm here to help you. How can I assist you today?‚Äù}"
  },
  {
    "objectID": "slides/05_tools_routing.html#define-route-function",
    "href": "slides/05_tools_routing.html#define-route-function",
    "title": "Tools and Routing",
    "section": "Define route function",
    "text": "Define route function\n\ndef route(result):\n    if isinstance(result, AgentFinish):\n        return result.return_values['output']\n    else:\n        tools = {\n            \"search_wikipedia\": search_wikipedia, \n            \"get_current_temperature\": get_current_temperature,\n        }\n        return tools[result.tool].run(result.tool_input)"
  },
  {
    "objectID": "slides/05_tools_routing.html#create-chain",
    "href": "slides/05_tools_routing.html#create-chain",
    "title": "Tools and Routing",
    "section": "Create chain",
    "text": "Create chain\n\nchain = prompt | model | OpenAIFunctionsAgentOutputParser() | route"
  },
  {
    "objectID": "slides/05_tools_routing.html#input-a-weather-quaestion",
    "href": "slides/05_tools_routing.html#input-a-weather-quaestion",
    "title": "Tools and Routing",
    "section": "Input a weather quaestion",
    "text": "Input a weather quaestion\n\nresult = chain.invoke({\"input\": \"What is the weather in stuttgart right now?\"})\n\n\nresult\n\n\n‚ÄòThe current temperature is 10.1¬∞C‚Äô"
  },
  {
    "objectID": "slides/05_tools_routing.html#input-a-general-queation",
    "href": "slides/05_tools_routing.html#input-a-general-queation",
    "title": "Tools and Routing",
    "section": "Input a general queation",
    "text": "Input a general queation\n\nresult = chain.invoke({\"input\": \"What is langchain?\"})\n\n\nresult\n\n‚ÄòPage: LangChain: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.: Prompt engineering: Prompt engineering is the process of structuring text that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.A prompt for a text-to-text model can be a query such as ‚Äúwhat is Fermat's little theorem?‚Äù, a command such as ‚Äúwrite a poem about leaves falling‚Äù, a short statement of feedback (for example, ‚Äútoo verbose‚Äù, ‚Äútoo formal‚Äù, ‚Äúrephrase again‚Äù, ‚Äúomit this word‚Äù) or a longer statement including context, instructions, and input data. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as ‚ÄúAct as a native French speaker‚Äù. A prompt may include a few examples for a model to learn from, such as ‚Äúmaison -&gt; house, chat -&gt; cat, chien -&gt;‚Äù, an approach called few-shot learning.When communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as ‚Äúa high-quality photo of an astronaut riding a horse‚Äù or ‚ÄúLo-fi slow BPM electro chill with organic samples‚Äù. Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.: Sentence embedding: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token prepended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT's sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT's [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.‚Äô"
  },
  {
    "objectID": "slides/05_tools_routing.html#just-say-hi",
    "href": "slides/05_tools_routing.html#just-say-hi",
    "title": "Tools and Routing",
    "section": "Just say hi",
    "text": "Just say hi\n\nchain.invoke({\"input\": \"hi!\"})\n\n\n‚ÄòHello! How can I assist you today?‚Äô"
  },
  {
    "objectID": "slides/02_lcel.html#langchain",
    "href": "slides/02_lcel.html#langchain",
    "title": "LangChain Expression Language (LCEL)",
    "section": "LangChain",
    "text": "LangChain\n\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.schema.output_parser import StrOutputParser\n\n\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.vectorstores import DocArrayInMemorySearch\n\n\nfrom langchain.schema.runnable import RunnableMap\n\n\nfrom langchain.llms import OpenAI\nimport json"
  },
  {
    "objectID": "slides/02_lcel.html#create-chain",
    "href": "slides/02_lcel.html#create-chain",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Create chain",
    "text": "Create chain\n\nprompt = ChatPromptTemplate.from_template(\n    \"tell me a short joke about {topic}\"\n)\n\nmodel = ChatOpenAI()\n\noutput_parser = StrOutputParser()\n\n\n\nchain = prompt | model | output_parser"
  },
  {
    "objectID": "slides/02_lcel.html#invoke-chain",
    "href": "slides/02_lcel.html#invoke-chain",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Invoke chain",
    "text": "Invoke chain\n\nchain.invoke({\"topic\": \"a professor at HdM Stuttgar\"})\n\n\n‚Äò‚ÄôWhy did the professor at HdM Stuttgart always carry a ladder?he wanted to reach new heights in teaching!‚Äô‚Äô"
  },
  {
    "objectID": "slides/02_lcel.html#create-vector-store-and-retriever",
    "href": "slides/02_lcel.html#create-vector-store-and-retriever",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Create Vector Store and Retriever",
    "text": "Create Vector Store and Retriever\n\nvectorstore = DocArrayInMemorySearch.from_texts(\n    [\"Yuval Noah Harari is the author of Sapiens\", \"In A Guide to the Good Life, William Irvine offers a refreshing presentation of Stoicism\"],\n    embedding=OpenAIEmbeddings()\n)\n\n# create a retriever\nretriever = vectorstore.as_retriever()"
  },
  {
    "objectID": "slides/02_lcel.html#retrieve-relevant-documents",
    "href": "slides/02_lcel.html#retrieve-relevant-documents",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Retrieve relevant documents",
    "text": "Retrieve relevant documents\n\nretriever.get_relevant_documents(\"who is the author of Sapiens?\")\n\n\n[Document(page_content=‚ÄòYuval Noah Harari is the author of Sapiens‚Äô), Document(page_content=‚ÄòIn A Guide to the Good Life, William Irvine offers a refreshing presentation of Stoicism‚Äô)]\n\n\n\nretriever.get_relevant_documents(\"Which book did William Irvine write?\")\n\n\n[Document(page_content=‚ÄòIn A Guide to the Good Life, William Irvine offers a refreshing presentation of Stoicism‚Äô), Document(page_content=‚ÄòYuval Noah Harari is the author of Sapiens‚Äô)]"
  },
  {
    "objectID": "slides/02_lcel.html#create-prompt",
    "href": "slides/02_lcel.html#create-prompt",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Create prompt",
    "text": "Create prompt\n\ntemplate = \"\"\"Answer the question based only on the following context:\n{context}\n\nQuestion: {question}\n\"\"\"\n\nprompt = ChatPromptTemplate.from_template(template)"
  },
  {
    "objectID": "slides/02_lcel.html#runnable-map",
    "href": "slides/02_lcel.html#runnable-map",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Runnable Map",
    "text": "Runnable Map\n\nChain: get user input &gt; fetch relevant context &gt; pass context into prompt &gt; pass into model &gt; pass into output parser to convert into string\nCreate dictionary with context and question . . .\n\n\nchain = RunnableMap({\n    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n    \"question\": lambda x: x[\"question\"]\n}) | prompt | model | output_parser"
  },
  {
    "objectID": "slides/02_lcel.html#invoke-chain-1",
    "href": "slides/02_lcel.html#invoke-chain-1",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Invoke chain",
    "text": "Invoke chain\n\nchain.invoke({\"question\": \"who is the author of Sapiens?\"})\n\n\n‚ÄòThe author of Sapiens is Yuval Noah Harari.‚Äô"
  },
  {
    "objectID": "slides/02_lcel.html#closer-look-at-the-runnablemap",
    "href": "slides/02_lcel.html#closer-look-at-the-runnablemap",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Closer look at the RunnableMap",
    "text": "Closer look at the RunnableMap\n\n\n\n\ninputs = RunnableMap({\n    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n    \"question\": lambda x: x[\"question\"]\n})\n\n\n\ninputs.invoke({\"question\": \"who is the author of Sapiens?\"})\n\n\n{‚Äòcontext‚Äô: [Document(page_content=‚ÄòYuval Noah Harari is the author of Sapiens‚Äô), Document(page_content=‚ÄòIn A Guide to the Good Life, William Irvine offers a refreshing presentation of Stoicism‚Äô)], ‚Äòquestion‚Äô: ‚Äòwho is the author of Sapiens?‚Äô}"
  },
  {
    "objectID": "slides/02_lcel.html#weather-function",
    "href": "slides/02_lcel.html#weather-function",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Weather function",
    "text": "Weather function\n\nfunctions = [\n    {\n      \"name\": \"weather_search\",\n      \"description\": \"Search for weather given an airport code\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"airport_code\": {\n            \"type\": \"string\",\n            \"description\": \"The airport code to get the weather for\"\n          },\n        },\n        \"required\": [\"airport_code\"]\n      }\n    }\n  ]"
  },
  {
    "objectID": "slides/02_lcel.html#bind",
    "href": "slides/02_lcel.html#bind",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Bind",
    "text": "Bind\n\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"human\", \"{input}\")\n    ]\n)\nmodel = ChatOpenAI(temperature=0).bind(functions=functions)"
  },
  {
    "objectID": "slides/02_lcel.html#runnable",
    "href": "slides/02_lcel.html#runnable",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Runnable",
    "text": "Runnable\n\nrunnable = prompt | model\n\n\nrunnable.invoke({\"input\": \"what is the weather in sf\"})\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚Äòweather_search‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúairport_code‚Äù: ‚ÄúSFO‚Äù}‚Äô}})"
  },
  {
    "objectID": "slides/02_lcel.html#weather-and-sports-search-function",
    "href": "slides/02_lcel.html#weather-and-sports-search-function",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Weather and sports search function",
    "text": "Weather and sports search function\n\nfunctions = [\n    {\n      \"name\": \"weather_search\",\n      \"description\": \"Search for weather given an airport code\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"airport_code\": {\n            \"type\": \"string\",\n            \"description\": \"The airport code to get the weather for\"\n          },\n        },\n        \"required\": [\"airport_code\"]\n      }\n    },\n        {\n      \"name\": \"sports_search\",\n      \"description\": \"Search for news of recent sport events\",\n      \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"team_name\": {\n            \"type\": \"string\",\n            \"description\": \"The sports team to search for\"\n          },\n        },\n        \"required\": [\"team_name\"]\n      }\n    }\n  ]"
  },
  {
    "objectID": "slides/02_lcel.html#bind-1",
    "href": "slides/02_lcel.html#bind-1",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Bind",
    "text": "Bind\n\nmodel = model.bind(functions=functions)\n\n\n\nrunnable = prompt | model\n\n\n\n\nrunnable.invoke({\"input\": \"how did the patriots do yesterday?\"})\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚Äòsports_search‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúteam_name‚Äù: ‚Äúpatriots‚Äù}‚Äô}})"
  },
  {
    "objectID": "slides/02_lcel.html#create-json-output",
    "href": "slides/02_lcel.html#create-json-output",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Create JSON output",
    "text": "Create JSON output\n\nWe use a simple model\n\n\n\nsimple_model = OpenAI(\n    temperature=0, \n    max_tokens=1000, \n    model=\"text-davinci-001\"\n)\nsimple_chain = simple_model | json.loads"
  },
  {
    "objectID": "slides/02_lcel.html#input-challenge",
    "href": "slides/02_lcel.html#input-challenge",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Input challenge",
    "text": "Input challenge\n\nchallenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\""
  },
  {
    "objectID": "slides/02_lcel.html#run-simple-model",
    "href": "slides/02_lcel.html#run-simple-model",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Run simple model",
    "text": "Run simple model\n\nsimple_model.invoke(challenge)\n\n\nNote: The next line is expected to fail.\n\n\n# simple_chain.invoke(challenge)\n\n\nOutput is not JSON"
  },
  {
    "objectID": "slides/02_lcel.html#new-model",
    "href": "slides/02_lcel.html#new-model",
    "title": "LangChain Expression Language (LCEL)",
    "section": "New model",
    "text": "New model\n\nmodel = ChatOpenAI(temperature=0)\n\nchain = model | StrOutputParser() | json.loads\n\n\n\nchain.invoke(challenge)\n\n\n{‚Äòpoem1‚Äô: {‚Äòtitle‚Äô: ‚ÄòWhispers of the Wind‚Äô, ‚Äòauthor‚Äô: ‚ÄòEmily Rivers‚Äô, ‚Äòfirst_line‚Äô: ‚ÄúSoftly it blows, the wind‚Äôs gentle touch‚Äù}, ‚Äòpoem2‚Äô: {‚Äòtitle‚Äô: ‚ÄòSilent Serenade‚Äô, ‚Äòauthor‚Äô: ‚ÄòJacob Stone‚Äô, ‚Äòfirst_line‚Äô: ‚ÄòIn moonlit night, a song unheard‚Äô}, ‚Äòpoem3‚Äô: {‚Äòtitle‚Äô: ‚ÄòDancing Shadows‚Äô, ‚Äòauthor‚Äô: ‚ÄòSophia Reed‚Äô, ‚Äòfirst_line‚Äô: ‚ÄòShadows sway, a graceful ballet‚Äô}}"
  },
  {
    "objectID": "slides/02_lcel.html#new-model-with-fallbacks",
    "href": "slides/02_lcel.html#new-model-with-fallbacks",
    "title": "LangChain Expression Language (LCEL)",
    "section": "New model with fallbacks",
    "text": "New model with fallbacks\n\nfinal_chain = simple_chain.with_fallbacks([chain])\n\n\nfinal_chain.invoke(challenge)\n\n\n{‚Äòpoem1‚Äô: {‚Äòtitle‚Äô: ‚ÄòWhispers of the Wind‚Äô, ‚Äòauthor‚Äô: ‚ÄòEmily Rivers‚Äô, ‚Äòfirst_line‚Äô: ‚ÄòSoftly it comes, the whisper of the wind‚Äô}, ‚Äòpoem2‚Äô: {‚Äòtitle‚Äô: ‚ÄòSilent Serenade‚Äô, ‚Äòauthor‚Äô: ‚ÄòJacob Moore‚Äô, ‚Äòfirst_line‚Äô: ‚ÄòIn the stillness of night, a silent serenade‚Äô}, ‚Äòpoem3‚Äô: {‚Äòtitle‚Äô: ‚ÄòDancing Shadows‚Äô, ‚Äòauthor‚Äô: ‚ÄòSophia Anderson‚Äô, ‚Äòfirst_line‚Äô: ‚ÄòShadows dance upon the walls, a secret ballet‚Äô}}"
  },
  {
    "objectID": "slides/02_lcel.html#joke-example",
    "href": "slides/02_lcel.html#joke-example",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Joke example",
    "text": "Joke example\n\nprompt = ChatPromptTemplate.from_template(\n    \"Tell me a short joke about {topic}\"\n)\nmodel = ChatOpenAI()\noutput_parser = StrOutputParser()\n\nchain = prompt | model | output_parser"
  },
  {
    "objectID": "slides/02_lcel.html#one-input",
    "href": "slides/02_lcel.html#one-input",
    "title": "LangChain Expression Language (LCEL)",
    "section": "One input",
    "text": "One input\n\nchain.invoke({\"topic\": \"professors\"})\n\n\n‚ÄòWhy did the professor bring a ladder to the lecture? they wanted to reach new heights of knowledge!‚Äô"
  },
  {
    "objectID": "slides/02_lcel.html#multiple-inputs",
    "href": "slides/02_lcel.html#multiple-inputs",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Multiple inputs",
    "text": "Multiple inputs\n\nchain.batch([{\"topic\": \"professors\"}, {\"topic\": \"students\"}])\n\n\n[‚ÄòWhy did the professor bring a ladder to class?they heard the lecture was going to be on high-level concepts!‚Äô, ‚ÄòWhy did the student bring a ladder to school?they wanted to reach for the highest grades!‚Äô]"
  },
  {
    "objectID": "slides/02_lcel.html#stream-back-responses",
    "href": "slides/02_lcel.html#stream-back-responses",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Stream back responses",
    "text": "Stream back responses\n\nfor t in chain.stream({\"topic\": \"professors\"}):\n    print(t)\n\nWhy did the professor bring a ladder to class ?\nBecause they wanted to reach new heights in education !"
  },
  {
    "objectID": "slides/02_lcel.html#async-method",
    "href": "slides/02_lcel.html#async-method",
    "title": "LangChain Expression Language (LCEL)",
    "section": "Async method",
    "text": "Async method\n\nresponse = await chain.ainvoke({\"topic\": \"professors\"})\nresponse\n\n\n‚ÄòWhy did the professor bring a ladder to the lecture? they wanted to reach new heights of knowledge!‚Äô"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#create-tagging-class",
    "href": "slides/04_tagging_extraction.html#create-tagging-class",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Create tagging class",
    "text": "Create tagging class\n\nclass Tagging(BaseModel):\n    \"\"\"Tag the piece of text with particular info.\"\"\"\n    sentiment: str = Field(description=\"sentiment of text, should be `pos`, `neg`, or `neutral`\")\n    language: str = Field(description=\"language of text (should be ISO 639-1 code)\")"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#take-a-look-at-the-class",
    "href": "slides/04_tagging_extraction.html#take-a-look-at-the-class",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Take a look at the class",
    "text": "Take a look at the class\n\nconvert_pydantic_to_openai_function(Tagging)\n\n{‚Äòname‚Äô: ‚ÄòTagging‚Äô, ‚Äòdescription‚Äô: ‚ÄòTag the piece of text with particular info.‚Äô, ‚Äòparameters‚Äô: {‚Äòtitle‚Äô: ‚ÄòTagging‚Äô, ‚Äòdescription‚Äô: ‚ÄòTag the piece of text with particular info.‚Äô, ‚Äòtype‚Äô: ‚Äòobject‚Äô, ‚Äòproperties‚Äô: {‚Äòsentiment‚Äô: {‚Äòtitle‚Äô: ‚ÄòSentiment‚Äô, ‚Äòdescription‚Äô: ‚Äòsentiment of text, should be pos, neg, or neutral‚Äô, ‚Äòtype‚Äô: ‚Äòstring‚Äô}, ‚Äòlanguage‚Äô: {‚Äòtitle‚Äô: ‚ÄòLanguage‚Äô, ‚Äòdescription‚Äô: ‚Äòlanguage of text (should be ISO 639-1 code)‚Äô, ‚Äòtype‚Äô: ‚Äòstring‚Äô}}, ‚Äòrequired‚Äô: [‚Äòsentiment‚Äô, ‚Äòlanguage‚Äô]}}"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#create-model-tagging-function-and-prompt",
    "href": "slides/04_tagging_extraction.html#create-model-tagging-function-and-prompt",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Create model, tagging function and prompt",
    "text": "Create model, tagging function and prompt\n\nmodel = ChatOpenAI(temperature=0)\n\n\n\ntagging_functions = [convert_pydantic_to_openai_function(Tagging)]\n\n\n\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"Think carefully, and then tag the text as instructed\"),\n    (\"user\", \"{input}\")\n])"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#bind-model-to-tagging-function-and-create-chain",
    "href": "slides/04_tagging_extraction.html#bind-model-to-tagging-function-and-create-chain",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Bind model to tagging function and create chain",
    "text": "Bind model to tagging function and create chain\nWe force the model to use the tagging functions\n\nmodel_with_functions = model.bind(\n    functions=tagging_functions,\n    function_call={\"name\": \"Tagging\"}\n)\n\n\n\ntagging_chain = prompt | model_with_functions"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#call-the-function",
    "href": "slides/04_tagging_extraction.html#call-the-function",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Call the function",
    "text": "Call the function\n\ntagging_chain.invoke({\"input\": \"I like the book Sapiens\"})\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚ÄòTagging‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúsentiment‚Äù: ‚Äúpos‚Äù,‚Äúlanguage‚Äù: ‚Äúen‚Äù}‚Äô}})\n\n\n\ntagging_chain.invoke({\"input\": \"Das 'Buch Eine Anleitung zum guten Leben: Wie Sie die alte Kunst des Stoizismus' ist sehr lesenswert\"})\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚ÄòTagging‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúsentiment‚Äù: ‚Äúpos‚Äù,‚Äúlanguage‚Äù: ‚Äúde‚Äù}‚Äô}})"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#use-output-parser",
    "href": "slides/04_tagging_extraction.html#use-output-parser",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Use output parser",
    "text": "Use output parser\n\nObtain a cleaner result with JsonOutputFunctionsParser()\n\n\n\ntagging_chain = prompt | model_with_functions | JsonOutputFunctionsParser()\n\n\n\n\ntagging_chain.invoke({\"input\": \"Das 'Buch Eine Anleitung zum guten Leben: Wie Sie die alte Kunst des Stoizismus' ist sehr lesenswert\"})\n\n\n{‚Äòsentiment‚Äô: ‚Äòpos‚Äô, ‚Äòlanguage‚Äô: ‚Äòde‚Äô}"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#define-class",
    "href": "slides/04_tagging_extraction.html#define-class",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Define class",
    "text": "Define class\n\nclass Person(BaseModel):\n    \"\"\"Information about a person.\"\"\"\n    name: str = Field(description=\"person's name\")\n    age: Optional[int] = Field(description=\"person's age\")\n\n\n\nclass Information(BaseModel):\n    \"\"\"Information to extract.\"\"\"\n    people: List[Person] = Field(description=\"List of info about people\")"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#convert-pydantic-to-openai-function",
    "href": "slides/04_tagging_extraction.html#convert-pydantic-to-openai-function",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Convert Pydantic to OpenAI function",
    "text": "Convert Pydantic to OpenAI function\n\nconvert_pydantic_to_openai_function(Information)\n\n{‚Äòname‚Äô: ‚ÄòInformation‚Äô, ‚Äòdescription‚Äô: ‚ÄòInformation to extract.‚Äô, ‚Äòparameters‚Äô: {‚Äòtitle‚Äô: ‚ÄòInformation‚Äô, ‚Äòdescription‚Äô: ‚ÄòInformation to extract.‚Äô, ‚Äòtype‚Äô: ‚Äòobject‚Äô, ‚Äòproperties‚Äô: {‚Äòpeople‚Äô: {‚Äòtitle‚Äô: ‚ÄòPeople‚Äô, ‚Äòdescription‚Äô: ‚ÄòList of info about people‚Äô, ‚Äòtype‚Äô: ‚Äòarray‚Äô, ‚Äòitems‚Äô: {‚Äòtitle‚Äô: ‚ÄòPerson‚Äô, ‚Äòdescription‚Äô: ‚ÄòInformation about a person.‚Äô, ‚Äòtype‚Äô: ‚Äòobject‚Äô, ‚Äòproperties‚Äô: {‚Äòname‚Äô: {‚Äòtitle‚Äô: ‚ÄòName‚Äô, ‚Äòdescription‚Äô: ‚Äúperson‚Äôs name‚Äù, ‚Äòtype‚Äô: ‚Äòstring‚Äô}, ‚Äòage‚Äô: {‚Äòtitle‚Äô: ‚ÄòAge‚Äô, ‚Äòdescription‚Äô: ‚Äúperson‚Äôs age‚Äù, ‚Äòtype‚Äô: ‚Äòinteger‚Äô}}, ‚Äòrequired‚Äô: [‚Äòname‚Äô]}}}, ‚Äòrequired‚Äô: [‚Äòpeople‚Äô]}}"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#set-up-model",
    "href": "slides/04_tagging_extraction.html#set-up-model",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Set up model",
    "text": "Set up model\n\nextraction_functions = [convert_pydantic_to_openai_function(Information)]\n\nextraction_model = model.bind(functions=extraction_functions, function_call={\"name\": \"Information\"})"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#test-model",
    "href": "slides/04_tagging_extraction.html#test-model",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Test model",
    "text": "Test model\n\nextraction_model.invoke(\"Joe is 30, his mom is Martha\")\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚ÄòInformation‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúpeople‚Äù: [,]}‚Äô}})\nModel inputs age 0 if age isn‚Äôt provided"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#update-prompt",
    "href": "slides/04_tagging_extraction.html#update-prompt",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Update prompt",
    "text": "Update prompt\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n    (\"human\", \"{input}\")\n])\n\n\n\nextraction_chain = prompt | extraction_model\n\n\n\n\nextraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚ÄòInformation‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúpeople‚Äù: [,]}‚Äô}})"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#parse-output",
    "href": "slides/04_tagging_extraction.html#parse-output",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Parse output",
    "text": "Parse output\n\nextraction_chain = prompt | extraction_model | JsonOutputFunctionsParser()\n\n\n\nextraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})\n\n\n{‚Äòpeople‚Äô: [{‚Äòname‚Äô: ‚ÄòJoe‚Äô, ‚Äòage‚Äô: 30}, {‚Äòname‚Äô: ‚ÄòMartha‚Äô}]}"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#use-different-output-parser",
    "href": "slides/04_tagging_extraction.html#use-different-output-parser",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Use different output parser",
    "text": "Use different output parser\n\nUse JsonKeyOutputFunctionsParser()to only extract relevant info\n\n\n\nextraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"people\")\n\n\n\n\nextraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})\n\n\n[{‚Äòname‚Äô: ‚ÄòJoe‚Äô, ‚Äòage‚Äô: 30}, {‚Äòname‚Äô: ‚ÄòMartha‚Äô}]"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#load-document",
    "href": "slides/04_tagging_extraction.html#load-document",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Load document",
    "text": "Load document\n\nloader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n\ndocuments = loader.load()\n\n\n\ndoc = documents[0]"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#inspect-content",
    "href": "slides/04_tagging_extraction.html#inspect-content",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Inspect content",
    "text": "Inspect content\n\npage_content = doc.page_content[:10000]\n\n\n\nprint(page_content[:1000])\n\n\n\nLLM Powered Autonomous Agents | Lil'Log\n\nLil'Log\n\nPosts\n\nArchive\n\nSearch\n\nTags\n\nFAQ\n\nemojisearch.app\n\n      LLM Powered Autonomous Agents\n    \nJune 23, 2023 ¬∑ 31 min ¬∑ Lilian Weng\n\nTable of Contents\nAgent System Overview\nComponent One: Planning\nTask Decomposition\nSelf-Reflection\nComponent Two: Memory\nTypes of Memory\nMaximum Inner Product Search (MIPS)\nComponent Three: Tool Use\nCase Studies\nScientific Discovery Agent\nGenerative Agents Simulation\nProof-of-Concept Examples\nChallenges\nCitation\nReferences\n\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\nAgent System Overview#\nIn"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#create-class-to-create-article-overview-and-tags",
    "href": "slides/04_tagging_extraction.html#create-class-to-create-article-overview-and-tags",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Create class to create article overview and tags",
    "text": "Create class to create article overview and tags\n\nclass Overview(BaseModel):\n    \"\"\"Overview of a section of text.\"\"\"\n    summary: str = Field(description=\"Provide a concise summary of the content.\")\n    language: str = Field(description=\"Provide the language that the content is written in.\")\n    keywords: str = Field(description=\"Provide keywords related to the content.\")"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#setup-the-chain",
    "href": "slides/04_tagging_extraction.html#setup-the-chain",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Setup the chain",
    "text": "Setup the chain\n\noverview_tagging_function = [\n    convert_pydantic_to_openai_function(Overview)\n]\n\ntagging_model = model.bind(\n    functions=overview_tagging_function,\n    function_call={\"name\":\"Overview\"}\n)\n\ntagging_chain = prompt | tagging_model | JsonOutputFunctionsParser()"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#invoke-chain",
    "href": "slides/04_tagging_extraction.html#invoke-chain",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Invoke chain",
    "text": "Invoke chain\n\ntagging_chain.invoke({\"input\": page_content})\n\n\n{‚Äòsummary‚Äô: ‚ÄòThis article discusses the concept of building autonomous agents powered by LLM (large language model) as their core controller. It explores the key components of such agents, including planning, memory, and tool use. It also covers various techniques for task decomposition and self-reflection in autonomous agents.‚Äô, ‚Äòlanguage‚Äô: ‚ÄòEnglish‚Äô, ‚Äòkeywords‚Äô: ‚ÄòLLM, autonomous agents, planning, memory, tool use, task decomposition, self-reflection‚Äô}"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#define-class-to-extract-papers",
    "href": "slides/04_tagging_extraction.html#define-class-to-extract-papers",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Define class to extract papers",
    "text": "Define class to extract papers\n\nclass Paper(BaseModel):\n    \"\"\"Information about papers mentioned.\"\"\"\n    title: str\n    author: Optional[str]\n\n\nclass Info(BaseModel):\n    \"\"\"Information to extract\"\"\"\n    papers: List[Paper]"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#setup-extraction-chain",
    "href": "slides/04_tagging_extraction.html#setup-extraction-chain",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Setup extraction chain",
    "text": "Setup extraction chain\n\npaper_extraction_function = [\n    convert_pydantic_to_openai_function(Info)\n]\n\nextraction_model = model.bind(\n    functions=paper_extraction_function, \n    function_call={\"name\":\"Info\"}\n)\n\nextraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#invoke-chain-1",
    "href": "slides/04_tagging_extraction.html#invoke-chain-1",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Invoke chain",
    "text": "Invoke chain\n\nextraction_chain.invoke({\"input\": page_content})\n\n\n[{‚Äòtitle‚Äô: ‚ÄòLLM Powered Autonomous Agents‚Äô, ‚Äòauthor‚Äô: ‚ÄòLilian Weng‚Äô}]"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#update-sytem-message",
    "href": "slides/04_tagging_extraction.html#update-sytem-message",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Update sytem message",
    "text": "Update sytem message\n\ntemplate = \"\"\"A article will be passed to you. Extract from it all papers that are mentioned by this article. \n\nDo not extract the name of the article itself. If no papers are mentioned that's fine - you don't need to extract any! Just return an empty list.\n\nDo not make up or guess ANY extra information. Only extract what exactly is in the text.\"\"\"\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", template),\n    (\"human\", \"{input}\")\n])\n\n\n\nextraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#invoke-chain-2",
    "href": "slides/04_tagging_extraction.html#invoke-chain-2",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Invoke chain",
    "text": "Invoke chain\n\nextraction_chain.invoke({\"input\": page_content})\n\n\n[{‚Äòtitle‚Äô: ‚ÄòChain of thought (CoT; Wei et al.¬†2022)‚Äô, ‚Äòauthor‚Äô: ‚ÄòWei et al.‚Äô}, {‚Äòtitle‚Äô: ‚ÄòTree of Thoughts (Yao et al.¬†2023)‚Äô, ‚Äòauthor‚Äô: ‚ÄòYao et al.‚Äô}, {‚Äòtitle‚Äô: ‚ÄòLLM+P (Liu et al.¬†2023)‚Äô, ‚Äòauthor‚Äô: ‚ÄòLiu et al.‚Äô}, {‚Äòtitle‚Äô: ‚ÄòReAct (Yao et al.¬†2023)‚Äô, ‚Äòauthor‚Äô: ‚ÄòYao et al.‚Äô}, {‚Äòtitle‚Äô: ‚ÄòReflexion (Shinn & Labash 2023)‚Äô, ‚Äòauthor‚Äô: ‚ÄòShinn & Labash‚Äô}, {‚Äòtitle‚Äô: ‚ÄòChain of Hindsight (CoH; Liu et al.¬†2023)‚Äô, ‚Äòauthor‚Äô: ‚ÄòLiu et al.‚Äô}, {‚Äòtitle‚Äô: ‚ÄòAlgorithm Distillation (AD; Laskin et al.¬†2023)‚Äô, ‚Äòauthor‚Äô: ‚ÄòLaskin et al.‚Äô}]"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#test-chain",
    "href": "slides/04_tagging_extraction.html#test-chain",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Test chain",
    "text": "Test chain\n\nextraction_chain.invoke({\"input\": \"hi\"})\n\n\n[]"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#split-the-text",
    "href": "slides/04_tagging_extraction.html#split-the-text",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Split the text",
    "text": "Split the text\n\ntext_splitter = RecursiveCharacterTextSplitter(chunk_overlap=0)\n\n\n\nsplits = text_splitter.split_text(doc.page_content)\n\n\n\n\nlen(splits)\n\n\n14"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#create-function-to-join-the-lists",
    "href": "slides/04_tagging_extraction.html#create-function-to-join-the-lists",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Create function to join the lists",
    "text": "Create function to join the lists\n\ndef flatten(matrix):\n    flat_list = []\n    for row in matrix:\n        flat_list += row\n    return flat_list\n\n\nTest the function\n\n\n\nflatten([[1, 2], [3, 4]])\n\n\n[1, 2, 3, 4]"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#take-a-look-at-the-splits",
    "href": "slides/04_tagging_extraction.html#take-a-look-at-the-splits",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Take a look at the splits",
    "text": "Take a look at the splits\n\nThe splits are just text.\nWe need to convert them to a dictionary where the text is the input key.\n\n\n\nprint(splits[0])"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#use-runnablelambda-to-create-function",
    "href": "slides/04_tagging_extraction.html#use-runnablelambda-to-create-function",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Use RunnableLambda to create function",
    "text": "Use RunnableLambda to create function\n\nprep = RunnableLambda(\n    lambda x: [{\"input\": doc} for doc in text_splitter.split_text(x)]\n)\n\n\nTest function\n\n\n\nprep.invoke(\"hi\")\n\n\n[{‚Äòinput‚Äô: ‚Äòhi‚Äô}]"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#create-chain",
    "href": "slides/04_tagging_extraction.html#create-chain",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Create chain",
    "text": "Create chain\n\nchain = prep | extraction_chain.map() | flatten\n\n\nextraction_chain operates over a single element\nHowever, we have a list of elements\nTherefore, we call .map()"
  },
  {
    "objectID": "slides/04_tagging_extraction.html#invoke-chain-3",
    "href": "slides/04_tagging_extraction.html#invoke-chain-3",
    "title": "Tagging and Extraction Using OpenAI functions",
    "section": "Invoke chain",
    "text": "Invoke chain\n\nchain.invoke(doc.page_content)\n\n[{'title': 'AutoGPT', 'author': ''},\n {'title': 'GPT-Engineer', 'author': ''},\n {'title': 'BabyAGI', 'author': ''},\n {'title': 'Chain of thought (CoT; Wei et al. 2022)', 'author': 'Wei et al.'},\n {'title': 'Tree of Thoughts (Yao et al. 2023)', 'author': 'Yao et al.'},\n {'title': 'LLM+P (Liu et al. 2023)', 'author': 'Liu et al.'},\n {'title': 'ReAct (Yao et al. 2023)', 'author': 'Yao et al.'},\n {'title': 'Reflexion (Shinn & Labash 2023)', 'author': 'Shinn & Labash'},\n {'title': 'Reflexion framework', 'author': 'Shinn & Labash'},\n {'title': 'Chain of Hindsight', 'author': 'Liu et al. 2023'},\n {'title': 'Algorithm Distillation', 'author': 'Laskin et al. 2023'},\n {'title': 'Algorithm Distillation', 'author': 'Laskin et al. 2023'},\n {'title': 'ED (expert distillation)', 'author': ''},\n {'title': 'RL^2', 'author': 'Duan et al. 2017'},\n {'title': 'LSH: Locality-Sensitive Hashing', 'author': ''},\n {'title': 'ANNOY: Approximate Nearest Neighbors Oh Yeah', 'author': ''},\n {'title': 'HNSW: Hierarchical Navigable Small World', 'author': ''},\n {'title': 'FAISS: Facebook AI Similarity Search', 'author': ''},\n {'title': 'ScaNN: Scalable Nearest Neighbors', 'author': ''},\n {'title': 'MRKL: Modular Reasoning, Knowledge and Language',\n  'author': 'Karpas et al. 2022'},\n {'title': 'TALM: Tool Augmented Language Models',\n  'author': 'Parisi et al. 2022'},\n {'title': 'Toolformer', 'author': 'Schick et al. 2023'},\n {'title': 'HuggingGPT', 'author': 'Shen et al. 2023'},\n {'title': 'API-Bank', 'author': 'Li et al. 2023'},\n {'title': 'ChemCrow', 'author': 'Bran et al. 2023'},\n {'title': 'Boiko et al. (2023)', 'author': 'Boiko et al.'},\n {'title': 'Generative Agents Simulation', 'author': 'Park, et al. 2023'},\n {'title': 'Park et al. 2023', 'author': ''},\n {'title': 'Super Mario: How Nintendo Conquered America',\n  'author': 'Jeff Ryan'},\n {'title': 'Model-View-Controller (MVC) Explained', 'author': 'Techopedia'},\n {'title': 'Python Game Development: Creating a Snake Game',\n  'author': 'Real Python'},\n {'title': 'Paper A', 'author': 'Author A'},\n {'title': 'Paper B', 'author': 'Author B'},\n {'title': 'Paper C', 'author': 'Author C'},\n {'title': 'Chain of thought prompting elicits reasoning in large language models',\n  'author': 'Wei et al.'},\n {'title': 'Tree of Thoughts: Deliberate Problem Solving with Large Language Models',\n  'author': 'Yao et al.'},\n {'title': 'Chain of Hindsight Aligns Language Models with Feedback',\n  'author': 'Liu et al.'},\n {'title': 'LLM+P: Empowering Large Language Models with Optimal Planning Proficiency',\n  'author': 'Liu et al.'},\n {'title': 'ReAct: Synergizing reasoning and acting in language models',\n  'author': 'Yao et al.'},\n {'title': 'Reflexion: an autonomous agent with dynamic memory and self-reflection',\n  'author': 'Shinn & Labash'},\n {'title': 'In-context Reinforcement Learning with Algorithm Distillation',\n  'author': 'Laskin et al.'},\n {'title': 'MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning',\n  'author': 'Karpas et al.'},\n {'title': 'API-Bank: A Benchmark for Tool-Augmented LLMs',\n  'author': 'Li et al.'},\n {'title': 'HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace',\n  'author': 'Shen et al.'},\n {'title': 'ChemCrow: Augmenting large-language models with chemistry tools',\n  'author': 'Bran et al.'},\n {'title': 'Emergent autonomous scientific research capabilities of large language models',\n  'author': 'Boiko et al.'},\n {'title': 'Generative Agents: Interactive Simulacra of Human Behavior',\n  'author': 'Joon Sung Park, et al.'}]"
  },
  {
    "objectID": "slides/Untitled.html",
    "href": "slides/Untitled.html",
    "title": "Langchain RAG",
    "section": "",
    "text": "import os\nimport openai\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # read local .env file\nopenai.api_key = os.environ['OPENAI_API_KEY']\n\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom langchain.utils.openai_functions import convert_pydantic_to_openai_function\n\nclass Tagging(BaseModel):\n    \"\"\"Tag the piece of text with particular info.\"\"\"\n    sentiment: str = Field(description=\"sentiment of text, should be `pos`, `neg`, or `neutral`\")\n    language: str = Field(description=\"language of text (should be ISO 639-1 code)\")\n\nconvert_pydantic_to_openai_function(Tagging)\n\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.chat_models import ChatOpenAI\n\nmodel = ChatOpenAI(temperature=0)\n\ntagging_functions = [convert_pydantic_to_openai_function(Tagging)]\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"Think carefully, and then tag the text as instructed\"),\n    (\"user\", \"{input}\")\n])\n\nmodel_with_functions = model.bind(\n    functions=tagging_functions,\n    function_call={\"name\": \"Tagging\"}\n)\n\ntagging_chain = prompt | model_with_functions\n\ntagging_chain.invoke({\"input\": \"I love langchain\"})\n\ntagging_chain.invoke({\"input\": \"non mi piace questo cibo\"})\n\nfrom langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n\ntagging_chain = prompt | model_with_functions | JsonOutputFunctionsParser()\n\ntagging_chain.invoke({\"input\": \"non mi piace questo cibo\"})\n\n## Extraction\n\nExtraction is similar to tagging, but used for extracting multiple pieces of information.\n\nfrom typing import Optional\nclass Person(BaseModel):\n    \"\"\"Information about a person.\"\"\"\n    name: str = Field(description=\"person's name\")\n    age: Optional[int] = Field(description=\"person's age\")\n\nclass Information(BaseModel):\n    \"\"\"Information to extract.\"\"\"\n    people: List[Person] = Field(description=\"List of info about people\")\n\nconvert_pydantic_to_openai_function(Information)\n\nextraction_functions = [convert_pydantic_to_openai_function(Information)]\nextraction_model = model.bind(functions=extraction_functions, function_call={\"name\": \"Information\"})\n\nextraction_model.invoke(\"Joe is 30, his mom is Martha\")\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n    (\"human\", \"{input}\")\n])\n\nextraction_chain = prompt | extraction_model\n\nextraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})\n\nextraction_chain = prompt | extraction_model | JsonOutputFunctionsParser()\n\nextraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})\n\nfrom langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n\nextraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"people\")\n\nextraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})\n\n## Doing it for real\n\nWe can apply tagging to a larger body of text.\n\nFor example, let's load this blog post and extract tag information from a sub-set of the text.\n\nfrom langchain.document_loaders import WebBaseLoader\nloader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\ndocuments = loader.load()\n\ndoc = documents[0]\n\npage_content = doc.page_content[:10000]\n\nprint(page_content[:1000])\n\nclass Overview(BaseModel):\n    \"\"\"Overview of a section of text.\"\"\"\n    summary: str = Field(description=\"Provide a concise summary of the content.\")\n    language: str = Field(description=\"Provide the language that the content is written in.\")\n    keywords: str = Field(description=\"Provide keywords related to the content.\")\n\noverview_tagging_function = [\n    convert_pydantic_to_openai_function(Overview)\n]\ntagging_model = model.bind(\n    functions=overview_tagging_function,\n    function_call={\"name\":\"Overview\"}\n)\ntagging_chain = prompt | tagging_model | JsonOutputFunctionsParser()\n\ntagging_chain.invoke({\"input\": page_content})\n\nclass Paper(BaseModel):\n    \"\"\"Information about papers mentioned.\"\"\"\n    title: str\n    author: Optional[str]\n\n\nclass Info(BaseModel):\n    \"\"\"Information to extract\"\"\"\n    papers: List[Paper]\n\npaper_extraction_function = [\n    convert_pydantic_to_openai_function(Info)\n]\nextraction_model = model.bind(\n    functions=paper_extraction_function, \n    function_call={\"name\":\"Info\"}\n)\nextraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")\n\nextraction_chain.invoke({\"input\": page_content})\n\ntemplate = \"\"\"A article will be passed to you. Extract from it all papers that are mentioned by this article. \n\nDo not extract the name of the article itself. If no papers are mentioned that's fine - you don't need to extract any! Just return an empty list.\n\nDo not make up or guess ANY extra information. Only extract what exactly is in the text.\"\"\"\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", template),\n    (\"human\", \"{input}\")\n])\n\nextraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")\n\nextraction_chain.invoke({\"input\": page_content})\n\nextraction_chain.invoke({\"input\": \"hi\"})\n\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\ntext_splitter = RecursiveCharacterTextSplitter(chunk_overlap=0)\n\nsplits = text_splitter.split_text(doc.page_content)\n\nlen(splits)\n\ndef flatten(matrix):\n    flat_list = []\n    for row in matrix:\n        flat_list += row\n    return flat_list\n\nflatten([[1, 2], [3, 4]])\n\nprint(splits[0])\n\nfrom langchain.schema.runnable import RunnableLambda\n\nprep = RunnableLambda(\n    lambda x: [{\"input\": doc} for doc in text_splitter.split_text(x)]\n)\n\nprep.invoke(\"hi\")\n\nchain = prep | extraction_chain.map() | flatten\n\nchain.invoke(doc.page_content)"
  },
  {
    "objectID": "slides/06_functional_conversation.html#define-weather-tool",
    "href": "slides/06_functional_conversation.html#define-weather-tool",
    "title": "Conversational agent",
    "section": "Define weather tool",
    "text": "Define weather tool\n\n# Define the input schema\nclass OpenMeteoInput(BaseModel):\n    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n\n@tool(args_schema=OpenMeteoInput)\ndef get_current_temperature(latitude: float, longitude: float) -&gt; dict:\n    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n    \n    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n    \n    # Parameters for the request\n    params = {\n        'latitude': latitude,\n        'longitude': longitude,\n        'hourly': 'temperature_2m',\n        'forecast_days': 1,\n    }\n\n    # Make the request\n    response = requests.get(BASE_URL, params=params)\n    \n    if response.status_code == 200:\n        results = response.json()\n    else:\n        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n\n    current_utc_time = datetime.datetime.utcnow()\n    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n    temperature_list = results['hourly']['temperature_2m']\n    \n    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n    current_temperature = temperature_list[closest_time_index]\n    \n    return f'The current temperature is {current_temperature}¬∞C'"
  },
  {
    "objectID": "slides/06_functional_conversation.html#define-wikipedia-tool",
    "href": "slides/06_functional_conversation.html#define-wikipedia-tool",
    "title": "Conversational agent",
    "section": "Define Wikipedia tool",
    "text": "Define Wikipedia tool\n\n@tool\ndef search_wikipedia(query: str) -&gt; str:\n    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n    page_titles = wikipedia.search(query)\n    summaries = []\n    for page_title in page_titles[: 3]:\n        try:\n            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n        except (\n            self.wiki_client.exceptions.PageError,\n            self.wiki_client.exceptions.DisambiguationError,\n        ):\n            pass\n    if not summaries:\n        return \"No good Wikipedia Search Result was found\"\n    return \"\\n\\n\".join(summaries)"
  },
  {
    "objectID": "slides/06_functional_conversation.html#save-list-of-tools",
    "href": "slides/06_functional_conversation.html#save-list-of-tools",
    "title": "Conversational agent",
    "section": "Save list of tools",
    "text": "Save list of tools\n\ntools = [get_current_temperature, search_wikipedia]"
  },
  {
    "objectID": "slides/06_functional_conversation.html#set-up-chain",
    "href": "slides/06_functional_conversation.html#set-up-chain",
    "title": "Conversational agent",
    "section": "Set up chain",
    "text": "Set up chain\n\nfunctions = [format_tool_to_openai_function(f) for f in tools]\n\nmodel = ChatOpenAI(temperature=0).bind(functions=functions)\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are helpful but sassy assistant\"),\n    (\"user\", \"{input}\"),\n])\n\nchain = prompt | model | OpenAIFunctionsAgentOutputParser()"
  },
  {
    "objectID": "slides/06_functional_conversation.html#invoke-chain",
    "href": "slides/06_functional_conversation.html#invoke-chain",
    "title": "Conversational agent",
    "section": "Invoke chain",
    "text": "Invoke chain\n\nresult = chain.invoke({\"input\": \"what is the weather in stuttgart?\"})\n\n\n\nresult.tool\n\n\n‚Äòget_current_temperature‚Äô\n\n\n\n\nresult.tool_input\n\n\n{‚Äòlatitude‚Äô: 48.7758, ‚Äòlongitude‚Äô: 9.1829}"
  },
  {
    "objectID": "slides/06_functional_conversation.html#modify-prompt",
    "href": "slides/06_functional_conversation.html#modify-prompt",
    "title": "Conversational agent",
    "section": "Modify prompt",
    "text": "Modify prompt\n\nUse MessagesPlaceholder\n\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are helpful but sassy assistant\"),\n    (\"user\", \"{input}\"),\n    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n])"
  },
  {
    "objectID": "slides/06_functional_conversation.html#create-chain",
    "href": "slides/06_functional_conversation.html#create-chain",
    "title": "Conversational agent",
    "section": "Create chain",
    "text": "Create chain\n\nchain = prompt | model | OpenAIFunctionsAgentOutputParser()"
  },
  {
    "objectID": "slides/06_functional_conversation.html#invoke-chain-1",
    "href": "slides/06_functional_conversation.html#invoke-chain-1",
    "title": "Conversational agent",
    "section": "Invoke chain",
    "text": "Invoke chain\n\nWe use an empty list because we don‚Äôt have any input so far\n\n\n\nresult1 = chain.invoke({\n    \"input\": \"what is the weather is stuttgart?\",\n    \"agent_scratchpad\": []\n})"
  },
  {
    "objectID": "slides/06_functional_conversation.html#inspect-result1",
    "href": "slides/06_functional_conversation.html#inspect-result1",
    "title": "Conversational agent",
    "section": "Inspect result1",
    "text": "Inspect result1\n\nresult1.tool\n\n\n‚Äòget_current_temperature‚Äô\n\n\nobservation = get_current_temperature(result1.tool_input)\n\n\nobservation\n\n\n‚ÄòThe current temperature is 10.1¬∞C‚Äô\n\n\ntype(result1)\n\n\nlangchain.schema.agent.AgentActionMessageLog"
  },
  {
    "objectID": "slides/06_functional_conversation.html#show-log",
    "href": "slides/06_functional_conversation.html#show-log",
    "title": "Conversational agent",
    "section": "Show log",
    "text": "Show log\n\nresult1.message_log\n\n\n[AIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚Äòget_current_temperature‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúlatitude‚Äù: 48.7758,‚Äúlongitude‚Äù: 9.1829}‚Äô}})]"
  },
  {
    "objectID": "slides/06_functional_conversation.html#format-to-openai-functions",
    "href": "slides/06_functional_conversation.html#format-to-openai-functions",
    "title": "Conversational agent",
    "section": "Format to OpenAI functions",
    "text": "Format to OpenAI functions\n\nformat_to_openai_functions([(result1, observation), ])\n\n\n[AIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚Äòget_current_temperature‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúlatitude‚Äù: 48.7758,‚Äúlongitude‚Äù: 9.1829}‚Äô}}), FunctionMessage(content=‚ÄòThe current temperature is 10.1¬∞C‚Äô, name=‚Äòget_current_temperature‚Äô)]"
  },
  {
    "objectID": "slides/06_functional_conversation.html#update-chain",
    "href": "slides/06_functional_conversation.html#update-chain",
    "title": "Conversational agent",
    "section": "Update chain",
    "text": "Update chain\n\nresult2 = chain.invoke({\n    \"input\": \"what is the weather in stuttgart?\", \n    \"agent_scratchpad\": format_to_openai_functions([(result1, observation)])\n})\n\n\n\nresult2\n\n\nAgentFinish(return_values={‚Äòoutput‚Äô: ‚ÄòThe current temperature in Stuttgart is 10.1¬∞C.‚Äô}, log=‚ÄòThe current temperature in Stuttgart is 10.1¬∞C.‚Äô)"
  },
  {
    "objectID": "slides/06_functional_conversation.html#runnablepassthrough",
    "href": "slides/06_functional_conversation.html#runnablepassthrough",
    "title": "Conversational agent",
    "section": "RunnablePassthrough",
    "text": "RunnablePassthrough\n\nagent_chain = RunnablePassthrough.assign(\n    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n) | chain\n\n\ndef run_agent(user_input):\n    intermediate_steps = []\n    while True:\n        result = agent_chain.invoke({\n            \"input\": user_input, \n            \"intermediate_steps\": intermediate_steps\n        })\n        if isinstance(result, AgentFinish):\n            return result\n        tool = {\n            \"search_wikipedia\": search_wikipedia, \n            \"get_current_temperature\": get_current_temperature,\n        }[result.tool]\n        observation = tool.run(result.tool_input)\n        intermediate_steps.append((result, observation))"
  },
  {
    "objectID": "slides/06_functional_conversation.html#run-agent-with-weather-question",
    "href": "slides/06_functional_conversation.html#run-agent-with-weather-question",
    "title": "Conversational agent",
    "section": "Run agent with weather question",
    "text": "Run agent with weather question\n\nrun_agent(\"what is the weather in stuttgart?\")\n\n\nAgentFinish(return_values={‚Äòoutput‚Äô: ‚ÄòThe current temperature in Stuttgart is 10.1¬∞C.‚Äô}, log=‚ÄòThe current temperature in Stuttgart is 10.1¬∞C.‚Äô)"
  },
  {
    "objectID": "slides/06_functional_conversation.html#run-agent-with-general-question",
    "href": "slides/06_functional_conversation.html#run-agent-with-general-question",
    "title": "Conversational agent",
    "section": "Run agent with general question",
    "text": "Run agent with general question\n\nrun_agent(\"what is langchain?\")\n\n\nAgentFinish(return_values={‚Äòoutput‚Äô: ‚ÄòLangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework that can be used for various tasks such as document analysis and summarization, chatbots, and code analysis. LangChain helps developers leverage the power of language models in their applications.‚Äô}, log=‚ÄòLangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework that can be used for various tasks such as document analysis and summarization, chatbots, and code analysis. LangChain helps developers leverage the power of language models in their applications.‚Äô)"
  },
  {
    "objectID": "slides/06_functional_conversation.html#just-say-hi",
    "href": "slides/06_functional_conversation.html#just-say-hi",
    "title": "Conversational agent",
    "section": "Just say hi",
    "text": "Just say hi\n\nrun_agent(\"hi!\")\n\n\nAgentFinish(return_values={‚Äòoutput‚Äô: ‚ÄòHello! How can I assist you today?‚Äô}, log=‚ÄòHello! How can I assist you today?‚Äô)"
  },
  {
    "objectID": "slides/06_functional_conversation.html#define-agent-executor",
    "href": "slides/06_functional_conversation.html#define-agent-executor",
    "title": "Conversational agent",
    "section": "Define Agent Executor",
    "text": "Define Agent Executor\n\nagent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=True)"
  },
  {
    "objectID": "slides/06_functional_conversation.html#invoke-executor",
    "href": "slides/06_functional_conversation.html#invoke-executor",
    "title": "Conversational agent",
    "section": "Invoke executor",
    "text": "Invoke executor\n\nagent_executor.invoke({\"input\": \"what is langchain?\"})\n\n\nEntering new AgentExecutor chain‚Ä¶\n\nInvoking: search_wikipedia with {'query': 'langchain'}\nPage: LangChain Summary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain‚Äôs use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\nPage: Prompt engineering Summary: Prompt engineering is the process of structuring text that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.A prompt for a text-to-text model can be a query such as ‚Äúwhat is Fermat‚Äôs little theorem?‚Äù, a command such as ‚Äúwrite a poem about leaves falling‚Äù, a short statement of feedback (for example, ‚Äútoo verbose‚Äù, ‚Äútoo formal‚Äù, ‚Äúrephrase again‚Äù, ‚Äúomit this word‚Äù) or a longer statement including context, instructions, and input data. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as ‚ÄúAct as a native French speaker‚Äù. A prompt may include a few examples for a model to learn from, such as ‚Äúmaison -&gt; house, chat -&gt; cat, chien -&gt;‚Äù, an approach called few-shot learning.When communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as ‚Äúa high-quality photo of an astronaut riding a horse‚Äù or ‚ÄúLo-fi slow BPM electro chill with organic samples‚Äù. Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\nPage: Sentence embedding Summary: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token prepended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT‚Äôs sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT‚Äôs [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. Other approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. An alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks. LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework that can be used for various tasks such as document analysis and summarization, chatbots, and code analysis. LangChain helps developers leverage the power of language models in their applications.\n\nFinished chain.\n\n{‚Äòinput‚Äô: ‚Äòwhat is langchain?‚Äô, ‚Äòoutput‚Äô: ‚ÄòLangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework that can be used for various tasks such as document analysis and summarization, chatbots, and code analysis. LangChain helps developers leverage the power of language models in their applications.‚Äô}"
  },
  {
    "objectID": "slides/06_functional_conversation.html#ask-a-question",
    "href": "slides/06_functional_conversation.html#ask-a-question",
    "title": "Conversational agent",
    "section": "Ask a question",
    "text": "Ask a question\n\nagent_executor.invoke({\"input\": \"what is my name\"})"
  },
  {
    "objectID": "slides/06_functional_conversation.html#add-previous-messages-in-prompt",
    "href": "slides/06_functional_conversation.html#add-previous-messages-in-prompt",
    "title": "Conversational agent",
    "section": "Add previous messages in prompt",
    "text": "Add previous messages in prompt\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are helpful but sassy assistant\"),\n    MessagesPlaceholder(variable_name=\"chat_history\"),\n    (\"user\", \"{input}\"),\n    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n])"
  },
  {
    "objectID": "slides/06_functional_conversation.html#create-agent-chain",
    "href": "slides/06_functional_conversation.html#create-agent-chain",
    "title": "Conversational agent",
    "section": "Create agent chain",
    "text": "Create agent chain\n\nagent_chain = RunnablePassthrough.assign(\n    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n) | prompt | model | OpenAIFunctionsAgentOutputParser()"
  },
  {
    "objectID": "slides/06_functional_conversation.html#create-memory-object",
    "href": "slides/06_functional_conversation.html#create-memory-object",
    "title": "Conversational agent",
    "section": "Create memory object",
    "text": "Create memory object\n\nmemory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")"
  },
  {
    "objectID": "slides/06_functional_conversation.html#agent-executor-1",
    "href": "slides/06_functional_conversation.html#agent-executor-1",
    "title": "Conversational agent",
    "section": "Agent executor",
    "text": "Agent executor\n\nagent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=True, memory=memory)"
  },
  {
    "objectID": "slides/06_functional_conversation.html#provide-input-with-name",
    "href": "slides/06_functional_conversation.html#provide-input-with-name",
    "title": "Conversational agent",
    "section": "Provide input with name",
    "text": "Provide input with name\n\nagent_executor.invoke({\"input\": \"my name is bob\"})\n\n\nEntering new AgentExecutor chain‚Ä¶ Hello Bob! How can I assist you today?\n\n\nFinished chain.\n\n{‚Äòinput‚Äô: ‚Äòmy name is bob‚Äô, ‚Äòchat_history‚Äô: [HumanMessage(content=‚Äòmy name is bob‚Äô), AIMessage(content=‚ÄòHello Bob! How can I assist you today?‚Äô)], ‚Äòoutput‚Äô: ‚ÄòHello Bob! How can I assist you today?‚Äô}"
  },
  {
    "objectID": "slides/06_functional_conversation.html#ask-about-name",
    "href": "slides/06_functional_conversation.html#ask-about-name",
    "title": "Conversational agent",
    "section": "Ask about name",
    "text": "Ask about name\n\nagent_executor.invoke({\"input\": \"whats my name\"})\n\n\nEntering new AgentExecutor chain‚Ä¶ Your name is Bob.\n\n\nFinished chain.\n\n{‚Äòinput‚Äô: ‚Äòwhats my name‚Äô, ‚Äòchat_history‚Äô: [HumanMessage(content=‚Äòmy name is bob‚Äô), AIMessage(content=‚ÄòHello Bob! How can I assist you today?‚Äô), HumanMessage(content=‚Äòwhats my name‚Äô), AIMessage(content=‚ÄòYour name is Bob.‚Äô)], ‚Äòoutput‚Äô: ‚ÄòYour name is Bob.‚Äô}"
  },
  {
    "objectID": "slides/06_functional_conversation.html#ask-about-the-weather",
    "href": "slides/06_functional_conversation.html#ask-about-the-weather",
    "title": "Conversational agent",
    "section": "Ask about the weather",
    "text": "Ask about the weather\n\nagent_executor.invoke({\"input\": \"whats the weather in stuttgart?\"})\n\n\nEntering new AgentExecutor chain‚Ä¶\n\nInvoking: get_current_temperature with {'latitude': 48.7758, 'longitude': 9.1829}\nThe current temperature is 9.5¬∞CThe current temperature in Stuttgart is 9.5¬∞C.\n\nFinished chain.\n\n{‚Äòinput‚Äô: ‚Äòwhats the weather in stuttgart?‚Äô, ‚Äòchat_history‚Äô: [HumanMessage(content=‚Äòmy name is bob‚Äô), AIMessage(content=‚ÄòHello Bob! How can I assist you today?‚Äô), HumanMessage(content=‚Äòwhats my name‚Äô), AIMessage(content=‚ÄòYour name is Bob.‚Äô), HumanMessage(content=‚Äòwhats the weather in stuttgart?‚Äô), AIMessage(content=‚ÄòThe current temperature in Stuttgart is 9.5¬∞C.‚Äô)], ‚Äòoutput‚Äô: ‚ÄòThe current temperature in Stuttgart is 9.5¬∞C.‚Äô}"
  },
  {
    "objectID": "slides/06_functional_conversation.html#define-a-custom-function",
    "href": "slides/06_functional_conversation.html#define-a-custom-function",
    "title": "Conversational agent",
    "section": "Define a custom function",
    "text": "Define a custom function\n\n@tool\ndef create_your_own(query: str) -&gt; str:\n    \"\"\"This function can do whatever you would like once you fill it in \"\"\"\n    print(type(query))\n    return query[::-1]"
  },
  {
    "objectID": "slides/06_functional_conversation.html#create-tool-list",
    "href": "slides/06_functional_conversation.html#create-tool-list",
    "title": "Conversational agent",
    "section": "Create tool list",
    "text": "Create tool list\n\ntools = [get_current_temperature, search_wikipedia, create_your_own]"
  },
  {
    "objectID": "slides/06_functional_conversation.html#define-chatbot-function",
    "href": "slides/06_functional_conversation.html#define-chatbot-function",
    "title": "Conversational agent",
    "section": "Define Chatbot function",
    "text": "Define Chatbot function\n\nclass cbfs(param.Parameterized):\n    \n    def __init__(self, tools, **params):\n        super(cbfs, self).__init__( **params)\n        self.panels = []\n        self.functions = [format_tool_to_openai_function(f) for f in tools]\n        self.model = ChatOpenAI(temperature=0).bind(functions=self.functions)\n        self.memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n        self.prompt = ChatPromptTemplate.from_messages([\n            (\"system\", \"You are helpful but sassy assistant\"),\n            MessagesPlaceholder(variable_name=\"chat_history\"),\n            (\"user\", \"{input}\"),\n            MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n        ])\n        self.chain = RunnablePassthrough.assign(\n            agent_scratchpad = lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n        ) | self.prompt | self.model | OpenAIFunctionsAgentOutputParser()\n        self.qa = AgentExecutor(agent=self.chain, tools=tools, verbose=False, memory=self.memory)\n    \n    def convchain(self, query):\n        if not query:\n            return\n        inp.value = ''\n        result = self.qa.invoke({\"input\": query})\n        self.answer = result['output'] \n        self.panels.extend([\n            pn.Row('User:', pn.pane.Markdown(query, width=450)),\n            pn.Row('ChatBot:', pn.pane.Markdown(self.answer, width=450, styles={'background-color': '#F6F6F6'}))\n        ])\n        return pn.WidgetBox(*self.panels, scroll=True)\n\n\n    def clr_history(self,count=0):\n        self.chat_history = []\n        return"
  },
  {
    "objectID": "slides/06_functional_conversation.html#panel-ui",
    "href": "slides/06_functional_conversation.html#panel-ui",
    "title": "Conversational agent",
    "section": "Panel UI",
    "text": "Panel UI\n\ncb = cbfs(tools)\n\ninp = pn.widgets.TextInput( placeholder='Enter text here‚Ä¶')\n\nconversation = pn.bind(cb.convchain, inp) \n\ntab1 = pn.Column(\n    pn.Row(inp),\n    pn.layout.Divider(),\n    pn.panel(conversation,  loading_indicator=True, height=400),\n    pn.layout.Divider(),\n)\n\ndashboard = pn.Column(\n    pn.Row(pn.pane.Markdown('# QnA_Bot')),\n    pn.Tabs(('Conversation', tab1))\n)\ndashboard"
  },
  {
    "objectID": "slides/01_openai_functions.html#helper-function",
    "href": "slides/01_openai_functions.html#helper-function",
    "title": "OpenAI Function Calling",
    "section": "Helper function",
    "text": "Helper function"
  },
  {
    "objectID": "slides/01_openai_functions.html#weather-example",
    "href": "slides/01_openai_functions.html#weather-example",
    "title": "OpenAI Function Calling",
    "section": "Weather example",
    "text": "Weather example\n\nimport json\n\n# Example dummy function hard coded to return the same weather\n# In production, this could be your backend API or an external API\ndef get_current_weather(location, unit=\"celsius\"):\n    \"\"\"Get the current weather in a given location\"\"\"\n    weather_info = {\n        \"location\": location,\n        \"temperature\": \"16\",\n        \"unit\": unit,\n        \"forecast\": [\"sunny\", \"windy\"],\n    }\n    return json.dumps(weather_info)"
  },
  {
    "objectID": "slides/01_openai_functions.html#define-a-function",
    "href": "slides/01_openai_functions.html#define-a-function",
    "title": "OpenAI Function Calling",
    "section": "Define a function",
    "text": "Define a function\n\n# define a function\nfunctions = [\n    {\n        \"name\": \"get_current_weather\",\n        \"description\": \"Get the current weather in a given location\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"location\": {\n                    \"type\": \"string\",\n                    \"description\": \"The city and state, e.g. Stuttgart, BW\",\n                },\n                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n            },\n            \"required\": [\"location\"],\n        },\n    }\n]"
  },
  {
    "objectID": "slides/01_openai_functions.html#messages",
    "href": "slides/01_openai_functions.html#messages",
    "title": "OpenAI Function Calling",
    "section": "Messages",
    "text": "Messages\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"What's the weather like in Stuttgart?\"\n    }\n]\n\n\n\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo-0613\",\n    messages=messages,\n    functions=functions\n)"
  },
  {
    "objectID": "slides/01_openai_functions.html#print-response",
    "href": "slides/01_openai_functions.html#print-response",
    "title": "OpenAI Function Calling",
    "section": "Print response",
    "text": "Print response\n\nprint(response)\n\n{ ‚Äúid‚Äù: ‚Äúchatcmpl-8EzjVmo4zPOq7Z70XEV47HcjF3FBb‚Äù, ‚Äúobject‚Äù: ‚Äúchat.completion‚Äù, ‚Äúcreated‚Äù: 1698584585, ‚Äúmodel‚Äù: ‚Äúgpt-3.5-turbo-0613‚Äù, ‚Äúchoices‚Äù: [ { ‚Äúindex‚Äù: 0, ‚Äúmessage‚Äù: { ‚Äúrole‚Äù: ‚Äúassistant‚Äù, ‚Äúcontent‚Äù: null, ‚Äúfunction_call‚Äù: { ‚Äúname‚Äù: ‚Äúget_current_weather‚Äù, ‚Äúarguments‚Äù: ‚Äú{\"location\": \"Stuttgart\"}‚Äù } }, ‚Äúfinish_reason‚Äù: ‚Äúfunction_call‚Äù } ], ‚Äúusage‚Äù: { ‚Äúprompt_tokens‚Äù: 81, ‚Äúcompletion_tokens‚Äù: 17, ‚Äútotal_tokens‚Äù: 98 } } ## Response message\n\nresponse_message = response[\"choices\"][0][\"message\"]\n\n\n\nresponse_message\n\n&lt;OpenAIObject at 0x120dc2c30&gt; JSON: { ‚Äúrole‚Äù: ‚Äúassistant‚Äù, ‚Äúcontent‚Äù: null, ‚Äúfunction_call‚Äù: { ‚Äúname‚Äù: ‚Äúget_current_weather‚Äù, ‚Äúarguments‚Äù: ‚Äú{\"location\": \"Stuttgart\"}‚Äù } }"
  },
  {
    "objectID": "slides/01_openai_functions.html#response-message-content",
    "href": "slides/01_openai_functions.html#response-message-content",
    "title": "OpenAI Function Calling",
    "section": "Response message content",
    "text": "Response message content\n\nContent is empty\n\n\n\nresponse_message[\"content\"]\n\n\nFunction call is a dictionary\n\n\n\n\nresponse_message[\"function_call\"]\n\n\n&lt;OpenAIObject at 0x120f9dc10&gt; JSON: { ‚Äúname‚Äù: ‚Äúget_current_weather‚Äù, ‚Äúarguments‚Äù: ‚Äú{\"location\": \"Stuttgart\"}‚Äù }"
  },
  {
    "objectID": "slides/01_openai_functions.html#inspect-json",
    "href": "slides/01_openai_functions.html#inspect-json",
    "title": "OpenAI Function Calling",
    "section": "Inspect JSON",
    "text": "Inspect JSON\n\njson.loads(response_message[\"function_call\"][\"arguments\"])\n\n{‚Äòlocation‚Äô: ‚ÄòStuttgart‚Äô}\n\n\nargs = json.loads(response_message[\"function_call\"][\"arguments\"])\n\n\n\n\nget_current_weather(args)\n\n\n‚Äò{‚Äúlocation‚Äù: {‚Äúlocation‚Äù: ‚ÄúStuttgart‚Äù}, ‚Äútemperature‚Äù: ‚Äú16‚Äù, ‚Äúunit‚Äù: ‚Äúcelsius‚Äù, ‚Äúforecast‚Äù: [‚Äúsunny‚Äù, ‚Äúwindy‚Äù]}‚Äô"
  },
  {
    "objectID": "slides/01_openai_functions.html#new-message",
    "href": "slides/01_openai_functions.html#new-message",
    "title": "OpenAI Function Calling",
    "section": "New message",
    "text": "New message\n\nNew message with no relation to weather\n\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"hi!\",\n    }\n]\n\n\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo-0613\",\n    messages=messages,\n    functions=functions,\n)\n\n\nprint(response)\n\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"hi!\",\n    }\n]\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo-0613\",\n    messages=messages,\n    functions=functions,\n    function_call=\"auto\",\n)\nprint(response)\n\n{ ‚Äúid‚Äù: ‚Äúchatcmpl-8Ezl8M209h6uqOXuFrGzVwAoSjXVI‚Äù, ‚Äúobject‚Äù: ‚Äúchat.completion‚Äù, ‚Äúcreated‚Äù: 1698584686, ‚Äúmodel‚Äù: ‚Äúgpt-3.5-turbo-0613‚Äù, ‚Äúchoices‚Äù: [ { ‚Äúindex‚Äù: 0, ‚Äúmessage‚Äù: { ‚Äúrole‚Äù: ‚Äúassistant‚Äù, ‚Äúcontent‚Äù: ‚ÄúHello! How can I assist you today?‚Äù }, ‚Äúfinish_reason‚Äù: ‚Äústop‚Äù } ], ‚Äúusage‚Äù: { ‚Äúprompt_tokens‚Äù: 75, ‚Äúcompletion_tokens‚Äù: 10, ‚Äútotal_tokens‚Äù: 85 } }"
  },
  {
    "objectID": "slides/01_openai_functions.html#disable-function-usage",
    "href": "slides/01_openai_functions.html#disable-function-usage",
    "title": "OpenAI Function Calling",
    "section": "Disable function usage",
    "text": "Disable function usage\n\nDon‚Äôt use the function\n\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"hi!\",\n    }\n]\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo-0613\",\n    messages=messages,\n    functions=functions,\n    function_call=\"none\",\n)\nprint(response)"
  },
  {
    "objectID": "slides/01_openai_functions.html#force-function-usage",
    "href": "slides/01_openai_functions.html#force-function-usage",
    "title": "OpenAI Function Calling",
    "section": "Force function usage",
    "text": "Force function usage\n\nforce to use the function\n\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"hi!\",\n    }\n]\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo-0613\",\n    messages=messages,\n    functions=functions,\n    function_call={\"name\": \"get_current_weather\"},\n)\nprint(response)"
  },
  {
    "objectID": "slides/01_openai_functions.html#pass-the-reults-back-in-the-llm",
    "href": "slides/01_openai_functions.html#pass-the-reults-back-in-the-llm",
    "title": "OpenAI Function Calling",
    "section": "Pass the reults back in the LLM",
    "text": "Pass the reults back in the LLM\n\nmessages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"What's the weather like in Boston!\",\n    }\n]\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo-0613\",\n    messages=messages,\n    functions=functions,\n    function_call={\"name\": \"get_current_weather\"},\n)\nprint(response)"
  },
  {
    "objectID": "slides/01_openai_functions.html#response",
    "href": "slides/01_openai_functions.html#response",
    "title": "OpenAI Function Calling",
    "section": "Response",
    "text": "Response\n{ ‚Äúid‚Äù: ‚Äúchatcmpl-8EzqG43iC6CWCOqCQiSWxngMHJNIQ‚Äù, ‚Äúobject‚Äù: ‚Äúchat.completion‚Äù, ‚Äúcreated‚Äù: 1698585004, ‚Äúmodel‚Äù: ‚Äúgpt-3.5-turbo-0613‚Äù, ‚Äúchoices‚Äù: [ { ‚Äúindex‚Äù: 0, ‚Äúmessage‚Äù: { ‚Äúrole‚Äù: ‚Äúassistant‚Äù, ‚Äúcontent‚Äù: null, ‚Äúfunction_call‚Äù: { ‚Äúname‚Äù: ‚Äúget_current_weather‚Äù, ‚Äúarguments‚Äù: ‚Äú{\"location\": \"Boston, MA\"}‚Äù } }, ‚Äúfinish_reason‚Äù: ‚Äústop‚Äù } ], ‚Äúusage‚Äù: { ‚Äúprompt_tokens‚Äù: 88, ‚Äúcompletion_tokens‚Äù: 11, ‚Äútotal_tokens‚Äù: 99 } }"
  },
  {
    "objectID": "slides/01_openai_functions.html#append-message",
    "href": "slides/01_openai_functions.html#append-message",
    "title": "OpenAI Function Calling",
    "section": "Append message",
    "text": "Append message\nAppend to list of messages\n\nmessages.append(response[\"choices\"][0][\"message\"])\n\n\n\nargs = json.loads(response[\"choices\"][0][\"message\"]['function_call']['arguments'])\n\nobservation = get_current_weather(args)\n\n\n\n\nThis is the response of calling a funtion\n\n\nmessages.append(\n        {\n            \"role\": \"function\",\n            \"name\": \"get_current_weather\",\n            \"content\": observation,\n        }\n)"
  },
  {
    "objectID": "slides/01_openai_functions.html#response-1",
    "href": "slides/01_openai_functions.html#response-1",
    "title": "OpenAI Function Calling",
    "section": "Response",
    "text": "Response\n\nresponse = openai.ChatCompletion.create(\n    model=\"gpt-3.5-turbo-0613\",\n    messages=messages,\n)\nprint(response)\n\n{ ‚Äúid‚Äù: ‚Äúchatcmpl-8EzsXbeQiRTRNHnGV9eCzlfCZrNU2‚Äù, ‚Äúobject‚Äù: ‚Äúchat.completion‚Äù, ‚Äúcreated‚Äù: 1698585145, ‚Äúmodel‚Äù: ‚Äúgpt-3.5-turbo-0613‚Äù, ‚Äúchoices‚Äù: [ { ‚Äúindex‚Äù: 0, ‚Äúmessage‚Äù: { ‚Äúrole‚Äù: ‚Äúassistant‚Äù, ‚Äúcontent‚Äù: ‚ÄúThe current temperature in Boston is 16 degrees Celsius. The weather is sunny and windy.‚Äù }, ‚Äúfinish_reason‚Äù: ‚Äústop‚Äù } ], ‚Äúusage‚Äù: { ‚Äúprompt_tokens‚Äù: 77, ‚Äúcompletion_tokens‚Äù: 18, ‚Äútotal_tokens‚Äù: 95 } }"
  },
  {
    "objectID": "slides/03_function_calling.html#basics",
    "href": "slides/03_function_calling.html#basics",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Basics",
    "text": "Basics\n\nPydantic data classes are a blend of Python‚Äôs data classes with the validation power of Pydantic.\nThey offer a concise way to define data structures while ensuring that the data adheres to specified types and constraints."
  },
  {
    "objectID": "slides/03_function_calling.html#create-class-with-standard-python",
    "href": "slides/03_function_calling.html#create-class-with-standard-python",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Create class with standard Python",
    "text": "Create class with standard Python\n\nclass User:\n    def __init__(self, name: str, age: int, email: str):\n        self.name = name\n        self.age = age\n        self.email = email"
  },
  {
    "objectID": "slides/03_function_calling.html#creata-an-instance",
    "href": "slides/03_function_calling.html#creata-an-instance",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Creata an instance",
    "text": "Creata an instance\n\nfoo = User(name=\"Joe\",age=32, email=\"joe@gmail.com\")\n\n\n\nfoo.name\n\n\n‚ÄòJoe‚Äô\n\n\n\n\nfoo = User(name=\"Joe\",age=\"bar\", email=\"joe@gmail.com\")\n\n\n\n\nfoo.age\n\n\n‚Äòbar‚Äô"
  },
  {
    "objectID": "slides/03_function_calling.html#create-class-with-pydantic",
    "href": "slides/03_function_calling.html#create-class-with-pydantic",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Create class with Pydantic",
    "text": "Create class with Pydantic\n\nclass pUser(BaseModel):\n    name: str\n    age: int\n    email: str"
  },
  {
    "objectID": "slides/03_function_calling.html#create-instance",
    "href": "slides/03_function_calling.html#create-instance",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Create instance",
    "text": "Create instance\n\nfoo_p = pUser(name=\"Jane\", age=32, email=\"jane@gmail.com\")\n\n\nfoo_p.name\n\n\n‚ÄòJane‚Äô\n\n\nfoo_p = pUser(name=\"Jane\", age=\"bar\", email=\"jane@gmail.com\")\n\n\nValidationError: 1 validation error for pUser age value is not a valid integer (type=type_error.integer)"
  },
  {
    "objectID": "slides/03_function_calling.html#nest-data-structures",
    "href": "slides/03_function_calling.html#nest-data-structures",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Nest data structures",
    "text": "Nest data structures\n\nDefine class type which includes another object (nest objects)\n\n\n\nclass Class(BaseModel):\n    students: List[pUser]\n\n\n\n\nobj = Class(\n    students=[pUser(name=\"Jane\", age=32, email=\"jane@gmail.com\")]\n)\n\n\n\n\nobj\n\n\nClass(students=[pUser(name=‚ÄòJane‚Äô, age=32, email=‚Äòjane@gmail.com‚Äô)])"
  },
  {
    "objectID": "slides/03_function_calling.html#weather-search-function",
    "href": "slides/03_function_calling.html#weather-search-function",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Weather search function",
    "text": "Weather search function\n\nDocstring is required\n\n\n\nclass WeatherSearch(BaseModel):\n    \"\"\"Call this with an airport code to get the weather at that airport\"\"\"\n    airport_code: str = Field(description=\"airport code to get weather for\")\n\n\nPass in class type\n\n\n\n\nweather_function = convert_pydantic_to_openai_function(WeatherSearch)"
  },
  {
    "objectID": "slides/03_function_calling.html#inspect-class-type",
    "href": "slides/03_function_calling.html#inspect-class-type",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Inspect class type",
    "text": "Inspect class type\n\nweather_function\n\n{‚Äòname‚Äô: ‚ÄòWeatherSearch‚Äô, ‚Äòdescription‚Äô: ‚ÄòCall this with an airport code to get the weather at that airport‚Äô, ‚Äòparameters‚Äô: {‚Äòtitle‚Äô: ‚ÄòWeatherSearch‚Äô, ‚Äòdescription‚Äô: ‚ÄòCall this with an airport code to get the weather at that airport‚Äô, ‚Äòtype‚Äô: ‚Äòobject‚Äô, ‚Äòproperties‚Äô: {‚Äòairport_code‚Äô: {‚Äòtitle‚Äô: ‚ÄòAirport Code‚Äô, ‚Äòdescription‚Äô: ‚Äòairport code to get weather for‚Äô, ‚Äòtype‚Äô: ‚Äòstring‚Äô}}, ‚Äòrequired‚Äô: [‚Äòairport_code‚Äô]}}"
  },
  {
    "objectID": "slides/03_function_calling.html#use-model-directly",
    "href": "slides/03_function_calling.html#use-model-directly",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Use model directly",
    "text": "Use model directly\n\nmodel = ChatOpenAI()\n\n\nmodel.invoke(\"what is the weather in SF today?\", functions=[weather_function])\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚ÄòWeatherSearch‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúairport_code‚Äù: ‚ÄúSFO‚Äù}‚Äô}})"
  },
  {
    "objectID": "slides/03_function_calling.html#use-bind",
    "href": "slides/03_function_calling.html#use-bind",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Use bind",
    "text": "Use bind\n\nmodel_with_function = model.bind(functions=[weather_function])\n\n\n\nmodel_with_function.invoke(\"what is the weather in sf?\")\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚ÄòWeatherSearch‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúairport_code‚Äù: ‚ÄúSFO‚Äù}‚Äô}})"
  },
  {
    "objectID": "slides/03_function_calling.html#forcing-it-to-use-a-function",
    "href": "slides/03_function_calling.html#forcing-it-to-use-a-function",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Forcing it to use a function",
    "text": "Forcing it to use a function\n\nmodel_with_forced_function = model.bind(functions=[weather_function], function_call={\"name\":\"WeatherSearch\"})\n\n\n\nmodel_with_forced_function.invoke(\"what is the weather in sf?\")\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚ÄòWeatherSearch‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúairport_code‚Äù: ‚ÄúSFO‚Äù}‚Äô}})\n\n\n\n\nmodel_with_forced_function.invoke(\"hi!\")\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚ÄòWeatherSearch‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúairport_code‚Äù: ‚ÄúSFO‚Äù}‚Äô}})"
  },
  {
    "objectID": "slides/03_function_calling.html#prompt-template",
    "href": "slides/03_function_calling.html#prompt-template",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Prompt template",
    "text": "Prompt template\nWe can use this model bound to function in a chain as we normally would\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a helpful assistant\"),\n    (\"user\", \"{input}\")\n])"
  },
  {
    "objectID": "slides/03_function_calling.html#chain",
    "href": "slides/03_function_calling.html#chain",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Chain",
    "text": "Chain\n\nchain = prompt | model_with_function\n\n\n\nchain.invoke({\"input\": \"what is the weather in sf?\"})\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚ÄòWeatherSearch‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúairport_code‚Äù: ‚ÄúSFO‚Äù}‚Äô}})"
  },
  {
    "objectID": "slides/03_function_calling.html#using-multiple-functions",
    "href": "slides/03_function_calling.html#using-multiple-functions",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Using multiple functions",
    "text": "Using multiple functions"
  },
  {
    "objectID": "slides/03_function_calling.html#create-artistsearch-function",
    "href": "slides/03_function_calling.html#create-artistsearch-function",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Create ArtistSearch function",
    "text": "Create ArtistSearch function\nEven better, we can pass a set of function and let the LLM decide which to use based on the question context.\n\nclass ArtistSearch(BaseModel):\n    \"\"\"Call this to get the names of songs by a particular artist\"\"\"\n    artist_name: str = Field(description=\"name of artist to look up\")\n    n: int = Field(description=\"number of results\")\n\n\n\nfunctions = [\n    convert_pydantic_to_openai_function(WeatherSearch),\n    convert_pydantic_to_openai_function(ArtistSearch),\n]\n\n\n\n\nmodel_with_functions = model.bind(functions=functions)"
  },
  {
    "objectID": "slides/03_function_calling.html#invoke-functions",
    "href": "slides/03_function_calling.html#invoke-functions",
    "title": "OpenAI Function Calling In LangChain",
    "section": "Invoke functions",
    "text": "Invoke functions\n\nmodel_with_functions.invoke(\"what is the weather in sf?\")\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚ÄòWeatherSearch‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúairport_code‚Äù: ‚ÄúSFO‚Äù}‚Äô}})\n\n\nmodel_with_functions.invoke(\"what are three songs by taylor swift?\")\n\n\nAIMessage(content=‚Äô‚Äò, additional_kwargs={‚Äôfunction_call‚Äô: {‚Äòname‚Äô: ‚ÄòArtistSearch‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúartist_name‚Äù: ‚Äútaylor swift‚Äù,‚Äún‚Äù: 3}‚Äô}})\n\n\nmodel_with_functions.invoke(\"hi!\")\n\n\nAIMessage(content=‚ÄòHello! How can I assist you today?‚Äô)"
  }
]